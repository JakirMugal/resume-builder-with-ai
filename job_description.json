{"data-scientist-across-pan-india-at-capgemini-engineering-4228162369.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-across-pan-india-at-capgemini-engineering-4228162369.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-across-pan-india-at-capgemini-engineering-4228162369?position=1&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=oyBUDRDchO7gA4%2Bk4Ld9GA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nPosition Title: Data Scientist\nCompany Overview: Capgemini Engineering is a global leader in engineering services, bringing together a worldwide team of engineers, scientists, and architects to assist the most innovative companies in unleashing their potential.\nPosition Overview: We are seeking a skilled Data Scientist with expertise in Cognite Data Fusion, data modelling, Unified Namespace (UNS), ontologies, and the identification of data products and datasets. The ideal candidate will have a strong background in developing and implementing data science projects, analyzing large and complex data sets, and driving data-driven decision-making across the organization\nKey Responsibilities:\nSolution Development: Design, implement, and deploy scalable data solutions utilizing Cognite Data Fusion, focusing on data modeling, UNS, and ontologies to address industry-specific challenges.\u200b\nData Analysis: Analyze large and complex data sets to identify trends, insights, and opportunities, supporting solution development and business strategies.\u200b\nCollaboration: Collaborate with cross-functional teams to understand data needs and translate them into data science solutions, ensuring seamless integration and operationalization of digital solutions across various domains.\nClient Engagement: Engage with clients to understand their business objectives, lead discovery workshops, and provide expert guidance on data-driven strategies and potential challenges.\u200b\nVisualization: Develop dashboards and visualizations using tools such as Power BI, Grafana, or web development frameworks like Plotly Dash and Streamlit to effectively communicate data insights.\u200b\nMentorship: Provide guidance and mentorship to junior team members, promoting best practices in data science and software development.\u200b\nQualifications:\nEducational Background: Master\u2019s or PhD degree in a quantitative field.\u200b\nExperience: Minimum of 2 years of experience in data science, with a strong background in developing analytical solutions within domains such as pharma, oil and gas, manufacturing, or power & utilities.\u200b\nTechnical Skills: Proficiency in Python and its data ecosystem (pandas, numpy), machine learning libraries (scikit-learn, keras), and experience with SQL.\u200b\nVisualization Tools: Experience with data visualization tools like Power BI, Grafana, Tableau, or web development frameworks such as Plotly Dash and Streamlit.\u200b\nSoftware Practices: Strong understanding of software development practices, including version control (e.g., Git), automated testing, and documentation.\u200b\nCloud Platforms: Experience with cloud services such as GCP, Azure, or AWS is advantageous.\u200b\nDomain Knowledge: Familiarity with industrial data management concepts, including Unified Namespace (UNS), ontologies, and data product identification.\u200b\nCommunication Skills: Excellent communication and collaboration skills, with the ability to work with cross-functional teams and stakeholders.\u200b\nLeadership: Demonstrated ability to lead projects and mentor junior team members.\u200b\nPreferred Qualifications:\nIndustry Expertise: Experience serving as a domain expert on internal or customer projects within relevant industries.\u200b\nCloud Deployment: Experience deploying models and solutions in production environments using cloud infrastructure.\u200b\nContinuous Learning: Willingness to stay updated with the latest developments in data science and related technologies.\u200b\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Capgemini Engineering", "position": "Data Scientist- Across PAN India", "location": "Bengaluru, Karnataka, India"}, "data-scientist-at-valiance-solutions-4075570637.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-at-valiance-solutions-4075570637.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-at-valiance-solutions-4075570637?position=2&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=oi1RcqG5xH6SGb%2BuTEsgPw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout Us:\nAt Valiance, we empower businesses with AI-driven insights and data analytics solutions. Specializing in demand forecasting within retail Industry very specific to \nApparel and Footwear \n domains, we leverage standardized ML models to deliver accurate forecasting outcomes to our clients. We are looking for a skilled Data Scientist who can interpret and improve these models to drive real-world business results.\nRole Overview:\nThe Data Scientist will be responsible for applying our pre-trained demand forecasting models to generate actionable insights and highly accurate forecasting outcomes. This role involves thorough data analysis, identifying trends and anomalies, interpreting results, and communicating findings effectively to a non-technical business audience. The ideal candidate is less focused on creating algorithms and more oriented towards solving business challenges and providing insights that make a tangible impact.\nKey Responsibilities:\nData Analysis:\n Conduct in-depth data analysis to identify trends, patterns, and anomalies in demand/Timeseries forecasting for Retail Industry very specific to Apparel and Footwear (must have)\nModel Utilization:\n Leverage existing pre-trained forecasting models, optimizing their performance by incorporating a nuanced understanding of data points and improving model outcomes based on data insights.\nInterpretation & Communication:\n Interpret model results and explain outcomes in simple, actionable terms for business stakeholders, ensuring clarity and relevance.\nInsights Generation:\n Develop insights that guide business decisions, aiming for highly accurate forecasting outcomes to meet business requirements.\nCollaboration:\n Work closely with cross-functional teams, including business stakeholders and analysts, to ensure forecasting outputs align with business objectives and provide real-world value.\nContinuous Improvement:\n Identify opportunities to improve model performance through better data usage and fine-tuning, rather than new model development.\nRequired Skills & Qualifications:\nExperience:\n \n3-6 years of experience\n in data science or a related field, specifically in \nDemand/Timeseries forecasting for Retail Industry very specific to Apparel and Footwear (must have)\nTechnical Proficiency:\n Strong skills in data analysis, data visualization, and working with pre-trained ML models. Proficiency in Python, and SQL is preferred.\nBusiness Focus:\n Strong orientation towards solving business problems rather than a pure focus on machine learning algorithms.\nCommunication Skills:\n Ability to clearly communicate insights and forecast results to non-technical stakeholders in simple, understandable language.\nProblem Solving:\n Demonstrated ability to interpret data, uncover actionable insights, and suggest practical solutions for business needs.\nDetail-Oriented:\n Thorough attention to detail, ensuring accuracy in forecasting and relevance of insights.\nEducational Background:\n Bachelor\u2019s or Master\u2019s degree in Data Science, Statistics, Computer Science, or a related field.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Valiance Solutions", "position": "Data Scientist", "location": "Bengaluru, Karnataka, India"}, "ai-ml-dl-specialist-at-adroit-innovative-solutions-inc-4278565118.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\ai-ml-dl-specialist-at-adroit-innovative-solutions-inc-4278565118.html", "link": "https://in.linkedin.com/jobs/view/ai-ml-dl-specialist-at-adroit-innovative-solutions-inc-4278565118?position=3&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=9esHi3dGi9mHkuk7RiiQgQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nRole : \nAI/ML/DL Specialist\nExp Level : 0-2 Years\nWork Mode : Remote\nNotice Period : Immediate / 15 Days\nRole Summary:\nWe\u2019re seeking a highly motivated and experienced \nAI/ML/DL Specialist\n with a strong foundation in \ncontextual learning\n and \nlanguage model development\n. You\u2019ll play a key role in building and training domain-specific models that can understand context, infer meaning, and provide intelligent recommendations \u2014 including the development of \nsmall language models\n for niche applications.\nKey Responsibilities:\nDesign and develop contextual AI/ML/DL models for real-world, policy-driven applications\nBuild, train, and fine-tune domain-specific small language models (SLMs)\nWork closely with data engineers, domain experts, and policy consultants to identify data sources and training strategies\nDeploy and optimize models for performance, scalability, and accuracy\nContribute to the vision and architecture of our AI product roadmap\nRequired Skills & Qualifications:\n\u2705 Proven experience (0-2 years) in AI/ML/DL model development\n\u2705 Expertise in contextual learning models, including transformer architectures\n\u2705 Hands-on experience with building and fine-tuning \nsmall language models\n (e.g., using HuggingFace, PyTorch, TensorFlow)\n\u2705 Solid programming skills (Python, PyTorch, TensorFlow, etc.)\n\u2705 Understanding of model deployment, scaling, and inference optimization\n\u2705 Ability to work in a fast-paced startup or consulting environment\n\u2705 Strong communication and collaboration skills\nDesirable:\n\u2795 Familiarity with open-source LLM tools, tokenization methods, and low-resource domain adaptation\n\u2795 Experience working with government or public-sector datasets\n\u2795 Passion for applying AI to real-world social or governance challenges\nDesirable:\n\u2795 Familiarity with open-source LLM tools, tokenization methods, and low-resource domain adaptation\n\u2795 Experience working with government or public-sector datasets\n\u2795 Passion for applying AI to real-world social or governance challenges\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Adroit Innovative Solutions Inc", "position": "AI/ML/DL Specialist", "location": "India"}, "data-scientist-at-dexian-india-4264355859.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-at-dexian-india-4264355859.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-at-dexian-india-4264355859?position=4&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=x4c9Atm3bGUuYr0w%2Br34sA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWe are seeking a Data Scientist with strong experience in \ndeveloping and implementing RAG (Retrieval-Augmented Generation) ontology\n, specifically in \nAzure environments\n.\n\ud83d\udccc Key Responsibilities:\nDesign, develop, and implement RAG-based ontology inside Azure.\nReconcile and map policies, laws, and regulations using advanced tech frameworks.\nCollaborate with local junior developers (from academic institutions).\nDeliver full-time contributions aligned with \nUS working hours (first half)\n.\nOperate in an \nagile\n, fast-moving, and innovation-focused environment.\n\ud83c\udfaf Must-Haves:\nStrong technical expertise\n in RAG architecture and Azure.\nAbility to \nprovide domain-specific answers and guidance (e.g., in healthcare policy)\n without relying on AI assistance.\nComfortable taking \nrisks and iterating quickly (\"fail forward\")\n in a startup-like, agile setting.\nA \nself-starter\n who thrives with minimal supervision and drives results independently.\nClear communicator, with a focus on collaboration and problem-solving.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Dexian India", "position": "Data Scientist", "location": "India"}, "data-scientist-at-recro-4271310370.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-at-recro-4271310370.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-at-recro-4271310370?position=5&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=rUkePVWV3bBGRGKsjx4o2w%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJob Title: Machine Learning Engineer / Data Scientist\nJob Summary:\nWe are looking for a skilled Machine Learning Engineer / Data Scientist to design and deploy end-to-end ML solutions. The ideal candidate will have a strong foundation in statistics, machine learning, Python programming, and experience working with large datasets in real-world production environments.\nKey Responsibilities:\nTranslate business problems into data science solutions.\nBuild and deploy complete ML pipelines: data ingestion, preprocessing, modeling, evaluation, and monitoring.\nApply statistical methods and core ML algorithms (regression, classification, clustering).\nWork with neural networks, including CNNs, RNNs, transformers.\nHandle large datasets using Python (NumPy, Pandas, Scikit-learn) and SQL.\nOptimize and tune models; implement clean, efficient, and scalable code.\nCollaborate with cross-functional teams and communicate findings effectively.\nRequirements:\nProficient in Python and object-oriented programming.\nStrong knowledge of statistics, ML fundamentals, and model evaluation.\nExperience with model deployment (REST APIs, batch inference) and monitoring.\nFamiliarity with data structures, algorithm design, and large-scale data processing.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Recro", "position": "Data Scientist", "location": "India"}, "machine-learning-engineer-at-interview-kickstart-4267255580.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\machine-learning-engineer-at-interview-kickstart-4267255580.html", "link": "https://in.linkedin.com/jobs/view/machine-learning-engineer-at-interview-kickstart-4267255580?position=6&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=BjLKbAqXTqEMgK9T0PMa7g%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWho We Are:\nInterviews can be hard, especially at top tech companies like Google, Facebook, and Netflix. Many candidates fall short simply because they aren't adequately prepared. That's where we come in. Our acclaimed courses specialize in interview preparation and transitioning into high-demand tech fields such as AI, ML, and Data Science. At Interview Kickstart, current and former hiring managers have guided over 17,000 tech professionals through transformative career journeys, ensuring their success in landing coveted positions. Think of us as \"the everything store\" for career transitions and interview skill development.\nHow Do We Do That, You Ask?\nWe have a structured approach to interview success, which includes:\nCareer Accelerator Course\nComprehensive end-to-end courses and platform\nA roster of over 600+ instructors from leading Silicon Valley companies like Google, Facebook, Amazon, and Netflix\nA holistic approach that includes live classes, mock interviews, personalized coaching, resume refinement, career strategies, and invaluable referrals\nWhat's more exciting is that we are completely remote and hiring the best people we can find regardless of geography.\nRole Overview:\nAs a Machine Learning Engineer at Interview Kickstart, you will play a crucial role in developing and deploying cutting-edge AI/ML solutions that enhance our platform and improve the learning experience for our students. You will work closely with data scientists, engineers, and product managers to build and scale robust and impactful machine learning models.\nWhat will excite us:\n3.5+ years of full-time experience as an ML engineer at tier-1 product-based companies\nHands-on experience fine-tuning open-source large language models (LLMs) and successfully deploying and maintaining them in scalable production environments on cloud platforms (e.g., AWS, Azure, GCP)\nHands-on experience building statistical and machine learning models\nProven expertise in traditional machine learning methods (e.g., regression, classification, clustering, tree-based models) and deep learning techniques (e.g., neural networks, CNNs, RNNs)\nProficiency in Python\nGood to have :\nExcellent communication skills, with the ability to present insights clearly to both technical and non-technical audiences\nA deep understanding of core concepts in statistics, probability, linear algebra, and calculus\nStrong quantitative abilities, typically supported by an advanced degree (masters or PhD) in fields like Machine Learning, Statistics, or Mathematics\nContributions to open-source ML projects\nWhat will you be doing? :\nCollaborate closely with stakeholders to understand business challenges deeply and translate these challenges into well-defined machine learning problems and actionable project requirements to drive business growth and enhance learner experiences\nLeverage your expertise in statistical modeling, machine learning, and generative AI/LLMs to research and design optimal solutions for the identified machine learning problems\nWork closely with fellow developers to build and iterate optimal solutions for the identified machine learning problems\nTake ownership of deploying the developed machine learning solutions, including fine-tuned LLMs, into scalable production environments (on cloud platforms like AWS, Azure, GCP) and ensure these deployed solutions are effective\nStaying informed about recent developments in AI/ML, including key publications, best practices, evaluation methodologies, technology stacks, and relevant tools\nWhat would excite you?\nComplete ownership\nExperiment, fail and learn\nHigh pedigree, high calibre team\nContribute to every area of our business. Have a real impact on your work\nTop-of-the-line compensation\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Interview Kickstart", "position": "Machine Learning Engineer", "location": "India"}, "research-scientist-%E2%80%93-ai-ml-at-ascendeum-4265400511.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\research-scientist-%E2%80%93-ai-ml-at-ascendeum-4265400511.html", "link": "https://in.linkedin.com/jobs/view/research-scientist-%E2%80%93-ai-ml-at-ascendeum-4265400511?position=7&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=GHGq11UhLm7J2PiTV%2F3eGg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAscendeum is looking for mathematicians, with extensive hands-on experience in the field of data science, who can analyze large data sets efficiently to generate actionable business intelligence that drives peak performance for our clients.\nAbout Us:\nWe provide AdTech strategy consulting to leading internet websites and apps hosting over 200 million monthly audiences worldwide. Since 2015, our consultants and engineers have consistently delivered intelligent solutions that enable enterprise-level websites and apps to maximize their digital advertising returns.\nJob Responsibilities:\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data.\nAnalyze large amounts of information to discover trends and patterns\nHelping develop reports and analysis.\nPresent information using data visualisation techniques.\nAssessing tests, implementing new or upgraded software, and assisting with strategic decisions on new systems.\nEvaluating changes and updates to source production systems.\nDevelop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks.\nProviding technical expertise in data storage structures, data mining, and data cleansing.\nPropose solutions and strategies to business challenges\nDesired Skills and Experience:\nRelevant 2+ years of experience in Data Analysis\nComplete understanding of Operations Research, Data Modelling, ML, and AI concepts.\nKnowledge of Python is mandatory, familiarity with MySQL, SQL, Scala, Java or C++ is an asset\nExperience using visualization tools (e.g. Jupyter Notebook) and data frameworks (e.g. Hadoop)\nAnalytical mind and business acumen\nStrong math skills (e.g. statistics, algebra)\nProblem-solving aptitude\nExcellent communication and presentation skills.\nBachelor\u2019s / Master's Degree in Computer Science, Engineering, Data Science or other quantitative or relevant field is preferred\nThank you for your interest in joining Ascendeum.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Ascendeum", "position": "Research Scientist \u2013 AI/ML", "location": "India"}, "data-scientist-people-analytics-at-motive-4257177833.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-people-analytics-at-motive-4257177833.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-people-analytics-at-motive-4257177833?position=8&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=FBcqM6ASurvdQhPaoJ3zVQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWho We Are\nMotive empowers the people who run physical operations with tools to make their work safer, more productive, and more profitable. For the first time ever, safety, operations and finance teams can manage their drivers, vehicles, equipment, and fleet related spend in a single system. Combined with industry leading AI, the Motive platform gives you complete visibility and control, and significantly reduces manual workloads by automating and simplifying tasks.\nMotive serves more than 100,000 customers \u2013 from Fortune 500 enterprises to small businesses \u2013 across a wide range of industries, including transportation and logistics, construction, energy, field service, manufacturing, agriculture, food and beverage, retail, and the public sector.\nVisit gomotive.com to learn more.\nAt Motive, our People Analytics team sits at the intersection of data science and talent strategy, transforming how we understand and enhance organizational performance. As a Data Scientist on our rapidly growing team, you'll leverage advanced analytics to tackle our most pressing talent challenges and drive measurable business impact.\nRole Description\nYou'll pioneer the application of data science to human capital, building sophisticated models and research that decode organizational behavior and shape Motive's talent strategy. Your work will span critical areas including:\nPredicting and enhancing talent acquisition, development, and retention\nQuantifying and elevating employee experience\nOptimizing team performance \nMaximizing productivity\nRethinking how we measure talent\nHuman capital problems require particular attention to sample size impacts, covariance, selection bias, modeling choices, and other issues that can be the difference between highly meaningful & impactful results, and noise. In this role, you will leverage structured problem solving approaches and data science skills to identify and deliver high impact solutions, as well as develop unique data science skills and human-capital expertise.\nThe Ideal Candidate Is\nPassionate about human capital: You are excited by the value we can add to our company and our employees, and are inspired to help make a large positive impact\nInnovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.\nCreative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You\u2019re not afraid to share a new idea.\nTechnical. You\u2019re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.\nStatistically-minded. You\u2019ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with network analysis, clustering, classification, time series, and sentiment analysis.\nRequired Qualifications\nBachelor's degree in Data Science, Statistics, Economics, or related quantitative field\nBackground in organizational psychology or behavioral economics\n3+ years of experience applying advanced analytics in people analytics, HR, or workforce planning\nExpert proficiency in Python or R, and SQL\nProven track record of building and deploying machine learning models\nExperience with statistical analysis, experimental design, and causal inference\nStrong project management skills with demonstrated ability to lead complex analytical initiatives\nExcellent communication skills - ability to translate complex analyses into actionable insights for diverse stakeholders\nPreferred Qualifications\nMaster\u2019s or PhD in a quantitative field or equivalent practical experience\nExperience with Organizational Network Analysis\nExperience in visualization tools (e.g., Tableau, PowerBI)\nExperience with natural language processing and unstructured data analysis\nTrack record of publishing or presenting analytical work\nFamiliarity with HR systems and people data structures\nCreating a diverse and inclusive workplace is one of Motive's core values. We are an equal opportunity employer and welcome people of different backgrounds, experiences, abilities and perspectives. \nPlease review our Candidate Privacy Notice here .\nUK Candidate Privacy Notice here.\nThe applicant must be authorized to receive and access those commodities and technologies controlled under U.S. Export Administration Regulations. It is Motive's policy to require that employees be authorized to receive access to Motive products and technology.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Motive", "position": "Data Scientist, People Analytics", "location": "India"}, "ai-engineer-at-idea-elan-4259182911.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\ai-engineer-at-idea-elan-4259182911.html", "link": "https://in.linkedin.com/jobs/view/ai-engineer-at-idea-elan-4259182911?position=9&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=5FHeA8CzbrXTw%2Fk15OFMng%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJob Description:\n We are seeking a skilled AI Engineer with 2-4 years of experience to design, develop, and deploy AI/ML solutions, with a strong emphasis on Generative AI, NLP, Retrieval-Augmented Generation (RAG), and Time Series Forecasting. The ideal candidate will have hands-on experience with LangGraph and other Generative AI frameworks to build cutting-edge AI applications.\nKey Responsibilities\nDevelop and deploy AI/ML models with a focus on NLP, Generative AI, RAG, and Time Series Forecasting workflows.\nEngineer and refine prompts to optimize performance for large language models (LLMs) and generative AI applications.\nImplement and maintain data preprocessing pipelines, including data cleansing, feature engineering, embedding generation, and transformation for time series data.\nDevelop end-to-end solutions integrating LLMs with VectorDB (e.g., Weaviate, Pinecone, FAISS) for document retrieval, semantic search, and contextual query answering.\nUtilize LangGraph and other Generative AI frameworks to build structured workflows for LLM-based applications.\nTrain and fine-tune machine learning models, including LLMs, to optimize performance for various use cases.\nAnalyze and interpret complex datasets, including time series data, ensuring scalable and efficient AI model deployment.\nCollaborate with cross-functional teams to integrate AI/ML models into existing systems and workflows.\nEnsure models are robust, scalable, and adhere to best practices in ethical AI development.\nConduct testing, performance benchmarking, and iterative refinements of AI models and pipelines.\nStay updated with the latest advancements in AI/ML, NLP, and cloud technologies and recommend integration strategies for emerging tools and techniques.\nCreate technical documentation and presentations to effectively communicate AI concepts to stakeholders.\nRequired Skills\nKey Skills and Qualifications:\nAI/ML Expertise: Proven experience in developing, fine-tuning, and deploying AI/ML models, focusing on NLP, Generative AI, and Time Series Forecasting.\nPrompt Engineering: Proficiency in designing, testing, and optimizing prompts for LLMs.\nData Analysis: Strong ability to process and interpret large and complex datasets, including time series data, for AI model training and validation.\nProgramming: Proficiency in Python and experience with AI/ML frameworks like TensorFlow, PyTorch, and scikit-learn.\nNLP Techniques: Understanding of tokenization, embeddings, transformer-based models (e.g., BERT, GPT, LLaMA), and RAG workflows.\nVector Databases: Experience with Weaviate, Pinecone, FAISS, or similar VectorDBs for document retrieval and storage.\nLangGraph & GenAI Frameworks: Hands-on experience with LangGraph, LangChain, HuggingFace Transformers, OpenAI API, and other Generative AI tools.\nCloud Deployment: Familiarity with deploying AI solutions on AWS, GCP, or Azure.\nTime Series Forecasting: Experience with ARIMA, LSTM, Prophet, and other forecasting techniques.\nModel Training & Fine-Tuning: Ability to train and fine-tune machine learning models, including large language models (LLMs), to enhance performance and accuracy.\nProblem-Solving & Collaboration: Strong analytical, problem-solving, and teamwork skills to work effectively in a cross-functional environment.\nPreferred Skills\nExperience in implementing RAG workflows and integrating generative AI with retrieval-based systems.\nFamiliarity with ethical AI principles and compliance frameworks.\nKnowledge of additional programming languages such as JavaScript or SQL.\nProficiency in MLOps practices for automating AI/ML pipelines and lifecycle management.\nExperience in developing AI-driven applications for real-world industry use cases.\nSkills: retrieval-augmented generation (rag),neuro-linguistic programming (nlp),data analysis,collaboration,programming,forecasting,prompt engineering,pytorch,cloud deployment,generative ai frameworks,programming in python,time series forecasting,langgraph & genai frameworks,vector databases (weaviate, pinecone, faiss),problem-solving & collaboration,langgraph & genai frameworks (langchain, huggingface transformers, openai api),ai ml,gen ai,vector databases,time series forecasting (arima, lstm, prophet),model training & fine-tuning,scikit-learn,problem-solving,tensorflow,langgraph,cloud deployment (aws, gcp, azure),nlp techniques,programming (python),mlops,ai/ml expertise\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Idea Elan", "position": "AI Engineer", "location": "India"}, "senior-data-scientist-at-recro-4271586232.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\senior-data-scientist-at-recro-4271586232.html", "link": "https://in.linkedin.com/jobs/view/senior-data-scientist-at-recro-4271586232?position=10&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=fizHS84GgdFZ7EnZZGf4aA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nRole & Responsibility:\nExperience working closely with other data scientists, data engineers software engineers, data managers and business partners.\nCan build scalable, re-usable, impactful data science products, usually containing statistical or machine learning algorithms, in collaboration with data engineers and software engineers.\nCan carry out data analyses to yield actionable business insights.\nHands-on experience \n(typically 5+ years)\n designing, planning, prototyping, productionizing, maintaining and documenting reliable and scalable data science products in complex environments.\nApplied knowledge of data science tools and approaches across all data lifecycle stages.\nThorough understanding of underlying mathematical foundations of statistics and machine learning.\nDevelopment experience in one or more object-oriented programming languages (e.g. Python, Go, Java, C++)\nAdvanced SQL knowledge.\nKnowledge of experimental design and analysis.\nCustomer-centric and pragmatic mindset. Focus on value delivery and swift execution, while maintaining attention to detail.\n \nIn addition to the above, the following skills also need to be checked:\n \nClassical ML (Supervised/Unsupervised learning things like regression, clustering, etc.)\nDeep Learning (if any area needed it's likely to be limited to fine-tuning a model, not creating one from scratch).\nOptimisation (linear, non-linear, etc.)\nLLM/RAGs\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Recro", "position": "Senior Data Scientist", "location": "India"}, "learning-support-specialist-ml-ai-data-science-and-data-engineering-at-emeritus-4259404928.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\learning-support-specialist-ml-ai-data-science-and-data-engineering-at-emeritus-4259404928.html", "link": "https://in.linkedin.com/jobs/view/learning-support-specialist-ml-ai-data-science-and-data-engineering-at-emeritus-4259404928?position=11&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=XPUqcdeYeTn1cnUVifLSHA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout Emeritus:\nEmeritus is committed to teaching the skills of the future by making high-quality education accessible and affordable to individuals, companies, and governments around the world. It does this by collaborating with more than 50 top-tier universities across the United States, Europe, Latin America, Southeast Asia, India and China.\nEmeritus\u2019 short courses, degree programs, professional certificates, and senior executive programs help individuals learn new skills and transform their lives, companies and organizations. Its unique model of state-of-the-art technology, curriculum innovation, and hands-on instruction from senior faculty, mentors and coaches has educated more than 250,000 individuals across 80+ countries.\nFounded in 2015, Emeritus, part of Eruditus Group, has more than 2,000 employees globally and offices in Mumbai, New Delhi, Shanghai, Singapore, Palo Alto, Mexico City, New York, Boston, London, and Dubai. Following its $650 million Series E funding round in August 2021, the Company is valued at $3.2 billion, and is backed by Accel, SoftBank Vision Fund 2, the Chan Zuckerberg Initiative, Leeds Illuminate, Prosus Ventures, Sequoia Capital India, and Bertelsmann.\nAbout the Role:\nThe Learning Support Specialist is a subject matter expert and largely impacts the student experience by guiding students through their learning journey.\nCandidates must have industry experience, demonstrated knowledge of the course subject area, and strong interpersonal skills. This is a full-time, remote role.\nThe purpose of this position is to provide assistance and aid learners enrolled in programs within the fields of machine learning and AI, data engineering, data science, and data analytics. The successful candidate will have proven experience as a data engineer and/or data scientist. The candidate must have excellent time management skills and the desire to work in a fast-paced educational tech environment where supplementing the educational journey of learners is priority. We are looking for a professional who does not mind a busy schedule and wants to provide excellent internal and external customer service. \nRoles and Responsibilities:\nMonitor and respond to all student inquiries via the learning management system and learner support software, using compassion and understanding for the student learning journey within 24 hours or less of submission\nRely on industry knowledge to quickly and clearly guide students through complex assignments and questions\nProvide prompt feedback that includes pointed questions that will help guide students towards correct answers and allows them to build problem-solving skills\nWork with students who are both new to the subject matter, as well as those with experience or who are further along in their careers\nSuggest course improvements to assigned Program Delivery Manager (PDM) and Designer to ensure content is communicated clearly, accurately, and effectively in videos, assignments and collateral materials\nCommunicate and collaborate with the Emeritus team on a regular basis to enhance course delivery and to solve unexpected course challenges\nSkills and Qualifications:\n5+ years of extensive work experience in the field of data engineering, data science, or data analytics \nProfessional and/or academic experience in machine learning and artificial intelligence\nProficiency in JavaScript, Python, and the use of GitHub\nExperience using data visualization tools (i.e. Tableau)\nExperience using Microsoft Azure \nAdvanced academic background in mathematics, particularly statistics, calculus, and linear algebra\nExcellent verbal and written communication and interpersonal skills with an ability to listen effectively, respond appropriately, and maintain a mutual comfort level while working with a diverse student population\nExperience using Canvas or other related learning management system\nPreferred Qualifications:\nExperience using Slack and Teams, as communication tools\nExperience working with support/service software or ticketing system\nExperience with using bug tracking and feedback tools\nEmeritus provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\nIn press:\nhttps://www.insidehighered.com/blogs/learning-innovation/why-chan-zuckerberg-backed-113-million-investment-eruditus-big-deal\nhttps://techcrunch.com/2020/08/31/chan-zuckerberg-initiative-backs-indian-education-startup-eruditus-in-113-million-fundraise/\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Emeritus", "position": "Learning Support Specialist - ML&AI, Data Science and Data Engineering", "location": "India"}, "data-scientist-at-hirenza-4279537149.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-at-hirenza-4279537149.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-at-hirenza-4279537149?position=12&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=%2BMHDSNK8nsShTUGMl%2BAmxA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout The Company\nProcter & Gamble (P&G) was founded over 180 years ago as a simple soap and candle company. Today, we're the world's largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but significant ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation, and citizenship. The insight, innovation, and passion of hardworking teams have helped us grow into a global enterprise that is governed responsibly and ethically, committed to transparency, supporting good causes, and protecting the environment. Our company culture fosters a sense of pride and purpose, encouraging employees to contribute meaningfully to society while advancing their careers.\nAbout The Role\nThe Product Supply Data Scientist role offers an exceptional opportunity to work on groundbreaking upstream improvements related to manufacturing and processing of our leading products. This position involves leveraging intelligent, connected technologies to drive the Fourth Industrial Revolution within our operations. The primary goal is to enhance system capabilities, safety, and efficiency while reducing costs and promoting sustainability. As a key member of the team, you will be instrumental in developing innovative data-driven solutions that optimize production processes, improve product quality, and support P&G\u2019s commitment to responsible manufacturing.\nQualifications\nTo excel in this role, candidates should possess a strong background in data science, engineering, or related fields, with proven experience in manufacturing or process optimization. A bachelor\u2019s degree in Engineering, Data Science, Computer Science, or a related discipline is required; a master\u2019s or higher degree is preferred. Candidates must demonstrate proficiency in data analysis, predictive modeling, and machine learning techniques, along with hands-on experience with data pipelines, analytics tools, and programming languages such as Python or R. Strong communication skills, the ability to work collaboratively across diverse teams, and a proactive approach to problem-solving are essential. Experience with Industry 4.0 technologies, IoT, and digital transformation initiatives will be considered advantageous.\nResponsibilities\nProvide technical leadership in supporting operational unit innovation projects, ensuring alignment with strategic objectives.\nAct as a key enabler in leading and delivering results against manufacturing challenges by applying advanced data science methodologies.\nCollaborate with innovation teams to explore new platforms, machine control systems, data processing techniques, and analytics solutions, fostering capability development in others.\nDevelop and plan analytic projects in response to business needs, utilizing data science tools to address complex process issues across regions.\nCreate and implement new predictive and prescriptive modeling methods to build robust, fault-tolerant process control strategies aimed at reducing operational effort and enhancing product quality.\nWork closely with process and equipment authorities, as well as application developers, to identify relevant data for analysis and ensure its effective utilization.\nPartner with process and equipment owners, along with ITOT teams, to develop and evolve data models for analytical capabilities, owning data model maintenance and enhancements for the hub site.\nDesign, develop, and maintain key data pipelines across selected global sites to enable continuous analytics and process improvements.\nContribute to defining work processes for deploying and maintaining predictive analytics architectures, modeling standards, alarming systems, and reporting methodologies.\nConduct external research to identify emerging trends and standards in analytical modeling, supporting P&G\u2019s smart manufacturing initiatives.\nDiagnose and resolve issues related to prognostics model performance, ensuring reliability and accuracy of predictive insights.\nLeverage reliability engineering principles combined with data science to develop innovative solutions aimed at reducing operational losses and improving overall efficiency.\nBenefits\nProcter & Gamble offers a comprehensive benefits package designed to support our employees\u2019 well-being and professional growth. This includes competitive compensation, health insurance, retirement plans, and paid time off. Employees have access to ongoing training and development programs, mentorship opportunities, and a dynamic work environment that encourages innovation and collaboration. P&G promotes work-life balance through flexible working arrangements and initiatives that foster personal and professional fulfillment. Additionally, employees are part of a global community committed to sustainability, diversity, and social responsibility, making a meaningful impact both within the company and in the wider society.\nEqual Opportunity\nProcter & Gamble is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based on race, ethnicity, gender, age, sexual orientation, disability, religion, or any other protected characteristic. Our hiring decisions are based solely on qualifications, experience, and the ability to contribute to our company's success. We believe that diverse perspectives foster innovation and drive our continued growth and success.\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Hirenza", "position": "Data Scientist", "location": "India"}, "python-developer-sde-2-at-greythr-4264074519.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-developer-sde-2-at-greythr-4264074519.html", "link": "https://in.linkedin.com/jobs/view/python-developer-sde-2-at-greythr-4264074519?position=13&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=gsXOf5%2BBJsVH%2Bd7WbLhcKQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nResponsibilities\n\u2022 Lead the design, development, and deployment of critical backend features using Python and Django\n\u2022 Design and implement scalable and efficient database solutions using PostgreSQL\nCollaborate effectively with cross-functional teams (design, product, QA) to deliver high-quality software on time and within budget\n\u2022 Write clean, maintainable, well-documented, and testable code\n\u2022 Conduct code reviews and mentor junior engineers on best practices\n\u2022 Proactively identify and implement improvements to the codebase\n\u2022 Stay up-to-date on the latest technologies and best practices in backend development and cloud computing\n\u2022 (Plus) Leverage Google Cloud Platform (GCP) services to build, deploy, and manage scalable and reliable systems.\nQualifications\n\u2022 Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent experience)\n\u2022 3+ years of experience in software development\n\u2022 In-depth expertise in Python and Django\n\u2022 Solid understanding of object-oriented programming (OOP) concepts and design patterns\n\u2022 Proven experience with relational databases (PostgreSQL preferred)\n\u2022 Experience with building and maintaining APIs\n\u2022 Strong problem-solving and analytical skills\n\u2022 Excellent communication, collaboration, and leadership skills\n\u2022 A passion for building high-quality software and a continuous learner\nBenefits\n\u2022 Competitive salary and benefits package\n\u2022 Opportunity to work on challenging and impactful projects\n\u2022 Collaborative and supportive work environment\n\u2022 Continuous learning and development opportunities\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "greytHR", "position": "Python Developer - SDE-2", "location": "India"}, "associate-data-scientist-at-ascendeum-4265405159.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\associate-data-scientist-at-ascendeum-4265405159.html", "link": "https://in.linkedin.com/jobs/view/associate-data-scientist-at-ascendeum-4265405159?position=14&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=z4huDlJdN1Xm0vYG2JAUGQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAscendeum is looking for mathematicians, with extensive hands-on experience in the field of data science, who can analyze large data sets efficiently to generate actionable business intelligence that drives peak performance for our clients.\nAbout Us:\nWe provide AdTech strategy consulting to leading internet websites and apps hosting over 200 million monthly audiences worldwide. Since 2015, our consultants and engineers have consistently delivered intelligent solutions that enable enterprise-level websites and apps to maximize their digital advertising returns.\nJob Responsibilities:\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data.\nAnalyze large amounts of information to discover trends and patterns\nHelping develop reports and analysis.\nPresent information using data visualisation techniques.\nAssessing tests, implementing new or upgraded software, and assisting with strategic decisions on new systems.\nEvaluating changes and updates to source production systems.\nDevelop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks.\nProviding technical expertise in data storage structures, data mining, and data cleansing.\nPropose solutions and strategies to business challenges\nDesired Skills and Experience:\nRelevant 2+ years of experience in Data Analysis\nComplete understanding of Operations Research, Data Modelling, ML, and AI concepts.\nKnowledge of Python is mandatory, familiarity with MySQL, SQL, Scala, Java or C++ is an asset\nExperience using visualization tools (e.g. Jupyter Notebook) and data frameworks (e.g. Hadoop)\nAnalytical mind and business acumen\nStrong math skills (e.g. statistics, algebra)\nProblem-solving aptitude\nExcellent communication and presentation skills.\nBachelor\u2019s / Master's Degree in Computer Science, Engineering, Data Science or other quantitative or relevant field is preferred\nThank you for your interest in joining Ascendeum.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Ascendeum", "position": "Associate Data Scientist", "location": "India"}, "software-engineer-python-react-at-dexian-india-4273061347.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-python-react-at-dexian-india-4273061347.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-python-react-at-dexian-india-4273061347?position=15&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=kypL8EuMcXYpg7HpUMXfEA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJob Description: \nSenior Full Stack Developer\nPosition Overview: We are seeking a highly skilled Full Stack Developer to join our dynamic team within Global Trading. The ideal candidate will possess a robust understanding of both front-end and back-end development, with a strong emphasis on creating and maintaining scalable, high-performance applications. This role requires a professional who can seamlessly integrate into our team, contributing to the development of innovative solutions that drive our trading operations.\nTo be eligible for this role, you must be able to demonstrate:\n\u2022 Strong communication and interpersonal skills\n\u2022 Ability to collaborate effectively with internal and external customers\n\u2022 Innovative and analytical thinking\n\u2022 Ability to manage workload under time pressure and changing priorities\n\u2022 Adaptability and willingness to learn new technologies and methodologies.\nRequired Skills and Qualifications:\n\u2022 Technical Proficiency:\n\u2022 \nExpert Front-end React Framework & Backend Python Experience\n\u2022 Proficient in front-end technologies such as HTML, CSS, Strong back-end development skills, or similar languages.\n\u2022 Proficient GIT, & CI/CD experience.\n\u2022 Develop and maintain web applications using modern frameworks and technologies\n\u2022 Help maintain code quality, organization, and automation\n\u2022 Experience with relational database management systems.\n\u2022 Familiarity with cloud services (AWS, Azure, or Google Cloud \u2013 Primarily Azure).\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Dexian India", "position": "Software Engineer (Python & React)", "location": "Pune, Maharashtra, India"}, "artificial-intelligence-engineer-at-hyqoo-4264456976.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\artificial-intelligence-engineer-at-hyqoo-4264456976.html", "link": "https://in.linkedin.com/jobs/view/artificial-intelligence-engineer-at-hyqoo-4264456976?position=16&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=wzkUN2sAR6MfI53efN5QmA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nTitle - AI Engineer \nType - Contract \nLocation - Remote\n \nRoles and Responsibilities:\n- Design and implement AI solutions using LLMs for tasks such as summarization, question answering, and document understanding.\n- Build and optimize retrieval-augmented generation (RAG) pipelines by combining OCR and LLMs for unstructured document processing.\n- Integrate LLMs and OCR tools, such as Azure Document Intelligence and Tesseract, into scalable applications.\n- Preprocess scanned and digital documents using OCR to extract structured and semi-structured text for LLM input.\n- Perform prompt engineering and fine-tuning of LLMs to enhance accuracy and task-specific performance.\n- Evaluate and monitor LLM+OCR system outputs for quality, bias, and hallucination risks.\n- Collaborate with cross-functional teams to deliver AI solutions tailored to domain-specific needs.\n- Stay updated on the latest developments in foundation models, Agentic AI, and OCR technologies.\nQualifications\n:\n- Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, or a related field.\n- 4+ years of experience in AI/ML, with a focus on LLMs and prompt engineering.\n- Proven ability to work independently, demonstrating initiative, ownership, and accountability across all phases of solution development.\n- Practical understanding of SAFe Agile methodologies, with experience delivering AI/ML solutions in cross-functional Agile teams.\nTools and Technologies:\n- Hands-on experience with LLM frameworks such as LangChain and Semantic Kernel.\n- Strong understanding of vector search, embedding models, and semantic retrieval (e.g., FAISS, Pinecone, Azure Cognitive Search).\n- Proficiency in Python, with experience integrating APIs, function calling, regular expressions, and handling LLM outputs.\n- Deep expertise in prompt engineering, including few-shot prompting, prompt tuning, prompt chaining, and optimization techniques for task-specific accuracy and cost control.\n- Solid knowledge of RAG architectures and agent design patterns (e.g., tool use, memory, planning).\n- Experience with OCR technologies (e.g., Tesseract, Azure Document Intelligence) for document understanding and information extraction from scanned or image-based content.\n- Familiarity with LLM platforms and tools like Azure OpenAI, LLMOps.\n- Experience deploying LLM-based applications in cloud environments, with attention to performance, reliability, and scalability.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Hyqoo", "position": "Artificial Intelligence Engineer", "location": "India"}, "ai-developer-at-elegant-enterprise-wide-solutions-inc-4263507628.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\ai-developer-at-elegant-enterprise-wide-solutions-inc-4263507628.html", "link": "https://in.linkedin.com/jobs/view/ai-developer-at-elegant-enterprise-wide-solutions-inc-4263507628?position=17&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=EENQPxB6%2BE2VR8LEWdIZ2g%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJob Title: AI Developer \u2013 Recruitment Process Automation\nLocation:\n Remote\n \nExperience:\n 2\u20134 years\n \nJob Type:\n Full-Time | Remote\nAbout Us:\n At Elegant Enterprise-Wide Solutions, we\u2019re transforming how staffing works by embracing smart automation. We're hiring an \nAI Developer\n to build intelligent tools that streamline and automate our core staffing operations.\nResponsibilities:\nDesign and implement AI/ML solutions to automate recruitment and staffing workflows.\nCollaborate with operations and HR teams to understand use cases and pain points.\nBuild and train models for resume parsing, candidate matching, and document generation.\nCreate and refine effective prompts to drive accurate outputs from generative AI tools (e.g., ChatGPT, Claude).\nEnsure integration of AI tools with internal systems like CRMs, ATS, and proposal platforms.\nContinuously improve the accuracy, speed, and reliability of all automation solutions.\nRequirements:\n2\u20134 years of experience in AI/ML development or automation projects.\nStrong Python skills with hands-on knowledge of libraries such as Scikit-learn, spaCy, or NLTK.\nExperience with natural language processing (NLP) and resume parsing.\nAbility to craft effective AI prompts for automating content-based tasks.\nFamiliarity with recruitment workflows, HR tech tools, or staffing platforms.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Elegant Enterprise-Wide Solutions, Inc.", "position": "AI Developer", "location": "India"}, "artificial-intelligence-engineer-at-true-tech-professionals-4277999857.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\artificial-intelligence-engineer-at-true-tech-professionals-4277999857.html", "link": "https://in.linkedin.com/jobs/view/artificial-intelligence-engineer-at-true-tech-professionals-4277999857?position=18&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=Tk8q4Nek4Xcs31OtCTRUZQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \n\ud83d\udce2 \nWe're Hiring \u2013 AI Backend Developer for Live Unspiked (RAG + Botpress)\n\ud83d\ude80 \nJoin a Mission-Driven HealthTech Team \u2013 Live Unspiked\nWe're looking for an experienced \nAI Backend Developer (Freelancer or Compact Agency)\n to help us build and maintain the AI infrastructure for our diabetes-focused coaching platform.\n\ud83e\uddec \nAbout Live Unspiked:\nWe\u2019re building a multi-channel AI coach (Mobile App + WhatsApp) powered by \nRetrieval-Augmented Generation (RAG)\n. The platform guides users through health questions, symptom reporting, meal reviews, and wellness tips, using curated knowledge, scientific content, and smart integrations.\n\ud83c\udfaf \nScope of Work:\n\u2705 Set up and manage \nBotpress\n (Cloud or Self-hosted)\n\u2705 Integrate \nVector DB\n (Supabase / Weaviate / Pinecone)\n\u2705 Build embedding pipelines for structured + unstructured data (OpenAI / Cohere)\n\u2705 Develop middleware connecting Botpress \u2194 Vector DB (Node.js / Firebase Functions)\n\u2705 Implement backend logic: user sessions, subscriptions, feedback logging\n\u2705 Enable integration with Flutter App and WhatsApp (360Dialog / Interakt)\n\ud83d\udee0\ufe0f \nTech Stack Preferences:\nBotpress (Pro features)\nNode.js or Firebase Functions\nSupabase / Weaviate / Pinecone\nEmbedding APIs (OpenAI / Cohere)\nSecure API Auth layer (token-based)\nHosting: Vercel, DigitalOcean, or AWS\n\ud83d\udca1 \nNice to Have:\nExperience with LangChain, LlamaIndex, or Rasa\nFamiliarity with GDPR/data privacy standards\nFirebase or Supabase Auth experience\nHealthcare or chatbot background\n\ud83d\udcbc \nIdeal Profile:\nPrevious experience building RAG/chatbot systems\nSolid backend dev skills in Node.js / Python\nCan deliver independently with clear milestones (2\u20134 weeks)\nStrong communication + Git practices\n\ud83d\udcec \nHow to Apply:\n Please DM or comment with:\nPortfolio / GitHub with relevant projects\nTimeline & availability\nPreferred stack & tools\nHourly or milestone-based rate\nLet\u2019s make diabetes management smarter, one message at a time \ud83d\udca1\n #freelance #backenddeveloper #botpress #openai #supabase #RAG #vectorsearch #aihealthcoach #LiveUnspiked #healthtech #hiring\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "True Tech Professionals", "position": "Artificial Intelligence Engineer", "location": "India"}, "python-developer-remote-at-altraize-4177412286.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-developer-remote-at-altraize-4177412286.html", "link": "https://in.linkedin.com/jobs/view/python-developer-remote-at-altraize-4177412286?position=19&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=GQWNefLCAzuvMvx7TEht9Q%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          This is a permanently remote job.\nHiring Senior Python Developers to work on AI technology. This opportunity is tailored for professionals who thrive on developing innovative solutions and who aspire to be at the forefront of AI advancements.\nRequired Skills\nWrite effective Python code to tackle complex issues\nUse business sense and analytical abilities to glean valuable insights from public databases \nClearly express the reasoning and logic when writing code in Jupyter notebooks or other suitable mediums\nExtensive experience working with Python \nProficiency with the language's syntax and conventions\nPrevious experience tackling algorithmic problems\nNice to have some prior Software Quality Assurance and Test Planning experience\nExcellent spoken and written English communication skills\nRequired Skills for TWA: The ideal candidates should be able to\nClearly explain their strategies for problem-solving.\nDesign practical solutions in code.\nDevelop test cases to validate their solutions.\nDebug and refine their solutions for improvement.\nQualifications\n3+ years of professional software development with demonstrable back-end implementation skills\nEnd-to-end experience in building massively scalable & resilient cloud-native applications\nExpert in Python programming skills\nShould have atleast 2+ yrs of experience in Technical Writing\nShould have exp in API development\nShould have exp in JSON\nExposure to AWS/Azure/GCP environment is a bonus\nStrong Software development fundamentals, architecture, algorithms, and problem-solving skills\nExcellent communication, strong organizational skills and attention to detail.\nSkills: python,nosql,aiml,artificial intelligence,api,json\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Altraize", "position": "Python Developer, Remote", "location": "India"}, "machine-learning-engineer-at-goml-4275071237.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\machine-learning-engineer-at-goml-4275071237.html", "link": "https://in.linkedin.com/jobs/view/machine-learning-engineer-at-goml-4275071237?position=20&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=E%2FqdhsI75ovNUEPhDX3yug%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nLooking for a culture to thrive & build a rewarding career for yourself, join the core team of young hustlers building the next generation of Machine Learning platform & services. You will develop training and deployment pipelines for machine learning, implement model compression algorithms, and productionize machine learning research solving challenging business problems.\nKey Responsibilities:\nDesign and develop generative AI models using techniques like RAG, transformers, and other relevant approaches.\nFine-tune pre-trained LLMs for specific tasks and domains.\nConduct research on new techniques for improving the performance and capabilities of generative AI models.\nApply software engineering rigor and best practices to machine learning /Generative AI pipelines.\nEvaluate and analyse the performance of ML/generative AI models.\nStay up to date on the latest advancements in generative AI research.\nFacilitate the development and deployment of proof-of-concept Generative AI systems.\nQualifications:\nBachelor\u2019s/Master\u2019s degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n3-5 years of experience in generative AI or related fields.\nExperience in building data pipelines, deploying ML/GenAI models in production, and monitoring and maintaining their performance.\nStrong programming skills in Python.\nFamiliarity with RAG and other techniques for building generative models.\nExtensive experience with Git, Docker and a good understanding of Linux for managing servers.\nExperience with cloud-based ecosystems, especially AWS ML/GenAI services.\nExposure to ML/GenAI frameworks and tools.\nExcellent communication and collaboration skills.\nAbility to work independently and in a team-oriented environment.\nMethodical and meticulous towards work and planning.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "goML", "position": "Machine Learning Engineer", "location": "India"}, "data-analyst-data-scientist-at-weekday-ai-yc-w21-4264836804.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-analyst-data-scientist-at-weekday-ai-yc-w21-4264836804.html", "link": "https://in.linkedin.com/jobs/view/data-analyst-data-scientist-at-weekday-ai-yc-w21-4264836804?position=21&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=yXYize0bhoa107aOkdjj2A%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nThis role is for one of the Weekday's clients\nSalary range: Rs 300000 - Rs 1200000 (ie INR 3-12 LPA)\nMin Experience: 1 years\nLocation: Remote (India)\nJobType: full-time\nWe're looking for a passionate and detail-oriented Data Analyst / Data Scientist to join our growing analytics team. This role is perfect for someone who thrives on solving complex problems using data, loves diving deep into datasets, and has a strong command of analytical tools and programming languages.\nAs a Data Analyst / Data Scientist, you will play a crucial role in helping teams make data-driven decisions by uncovering actionable insights from structured and unstructured data. You'll work closely with stakeholders across departments\u2014such as product, marketing, and operations\u2014to understand their challenges and deliver meaningful analysis and visualizations that guide strategy and execution.\nRequirements\nKey Responsibilities:\n Perform exploratory data analysis to identify trends, patterns, and opportunities within large datasets. \n Build and maintain dashboards and reports using Tableau to visualize KPIs, performance metrics, and other analytical outputs. \n Write efficient, well-structured SQL queries to extract, manipulate, and analyze data from various databases. \n Use Python to develop scripts and workflows for data cleaning, transformation, and predictive modeling. \n Collaborate with cross-functional teams to define data requirements and deliver insights to support business decisions. \n Interpret data and communicate results clearly and effectively to both technical and non-technical stakeholders. \n Participate in the development and improvement of data models, pipelines, and quality checks. \n Stay up-to-date with industry trends, best practices, and new technologies in analytics and data science. \nRequirements:\n Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, Engineering, or a related field. \n 1-5 years of experience in a data analyst or data scientist role, preferably in a fast-paced or startup environment. \n Strong proficiency in SQL and Python for data manipulation and analysis. \n Experience building dashboards and visualizations using Tableau (or similar tools such as Power BI or Looker). \n Solid understanding of statistical methods and ability to apply them to real-world business problems. \n Strong analytical and problem-solving skills with attention to detail and accuracy. \n Excellent communication and collaboration skills, with the ability to present findings in a clear and concise manner. \nNice to Have:\n Exposure to machine learning techniques and libraries (e.g., scikit-learn, XGBoost, etc.). \n Experience working with cloud-based data platforms (AWS, GCP, or Azure). \n Familiarity with version control tools like Git and workflow automation tools like Airflow\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Weekday AI (YC W21)", "position": "Data Analyst / Data Scientist", "location": "India"}, "python-developer-at-tigi-hr-4277504449.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-developer-at-tigi-hr-4277504449.html", "link": "https://in.linkedin.com/jobs/view/python-developer-at-tigi-hr-4277504449?position=22&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=0p3tQ694IlZJV6s%2BjYlryw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJob Title:\n Full Stack Engineer \u2013 Python / React\nExperience Level:\n 4+ Years\nType: \nRemote\nOverview:\nWe\u2019re looking for a skilled full stack developer with strong experience in \nPython\n and \nReactJS\n, who thrives in collaborative, test-driven environments.\nResponsibilities:\nWrite tests before development to ensure robust, maintainable code\nDevelop clean, readable, and consistent code with predictable outcomes\nDeploy frequent, incremental updates to production\nWork in pairs to enhance code quality and knowledge sharing\nParticipate in peer code reviews for continuous improvement\nCollaborate with product teams to rapidly deliver features and enhancements\nOwn full stack responsibilities including infrastructure and DevOps workflows\nEmbrace continuous learning and skill development\nRequired Skills:\nProficiency in \nReactJS\n, \nJavaScript\n, and \nObject-Oriented Programming\n3+ years of experience with \nPython\n (or equivalent OO language)\nStrong command of \nSQL databases\n and \nGit-based collaboration\nExperience working in Agile, cross-functional teams\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "TIGI HR", "position": "Python Developer", "location": "India"}, "ai-engineer-at-elevation-capital-4277540420.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\ai-engineer-at-elevation-capital-4277540420.html", "link": "https://in.linkedin.com/jobs/view/ai-engineer-at-elevation-capital-4277540420?position=23&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=cnnl4B7Wkj0goFO%2FQxjbCg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nRole description: This role is with one of our prominent portfolio companies.\nAbout Us\nWe are a San Francisco based startup building next-generation Voice AI products that redefine how humans interact with machines from smart voice assistants to automated customer conversations, voice-driven tools, and more.\nWe are at the intersection of speech technology, large language models, and real-time systems, backed by leading investors and supported by domain experts. We\u2019re now building our founding engineering team in India to shape the core product experience.\nWhat You'll Do\nBuild and deploy real-time voice-based AI applications using ASR (Automatic Speech Recognition), TTS (Text-to-Speech), and LLMs.\nWork on latency-sensitive systems to enable near real-time conversations.\nDesign and implement prompt-chaining, memory, and tool integration for LLM-powered voice agents.\nSet up and manage scalable infra for voice/audio processing and AI model serving.\nWork closely with the founding team on product shaping, roadmap planning, and technical strategy.\nContinuously experiment with and evaluate new models, APIs, and speech/LLM techniques.\nWho You Are\n3-8 years of experience in AI/ML, deep learning, or backend-heavy engineering roles.\nSolid hands-on experience with speech technologies (ASR, TTS, diarization, etc.).\nComfortable working with Python, PyTorch, Hugging Face, OpenAI, or similar frameworks.\nExperience deploying real-time systems (Docker, Kubernetes, AWS/GCP).\nStrong problem-solving skills with a product-first mindset.\nSelf-starter who thrives in high-ownership, fast-paced environments.\nExcellent written and verbal communication\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Elevation Capital", "position": "AI Engineer", "location": "India"}, "machine-learning-researcher-at-ascendeum-4273411453.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\machine-learning-researcher-at-ascendeum-4273411453.html", "link": "https://in.linkedin.com/jobs/view/machine-learning-researcher-at-ascendeum-4273411453?position=24&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=4TwU9JChkMP2sr0sAjavqQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAscendeum is looking for mathematicians, with extensive hands-on experience in the field of data science, who can analyze large data sets efficiently to generate actionable business intelligence that drives peak performance for our clients.\nAbout Us:\nWe provide AdTech strategy consulting to leading internet websites and apps hosting over 200 million monthly audiences worldwide. Since 2015, our consultants and engineers have consistently delivered intelligent solutions that enable enterprise-level websites and apps to maximize their digital advertising returns.\nJob Responsibilities:\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data.\nAnalyze large amounts of information to discover trends and patterns\nHelping develop reports and analysis.\nPresent information using data visualisation techniques.\nAssessing tests, implementing new or upgraded software, and assisting with strategic decisions on new systems.\nEvaluating changes and updates to source production systems.\nDevelop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks.\nProviding technical expertise in data storage structures, data mining, and data cleansing.\nPropose solutions and strategies to business challenges\nDesired Skills and Experience:\nRelevant 2+ years of experience in Data Analysis\nComplete understanding of Operations Research, Data Modelling, ML, and AI concepts.\nKnowledge of Python is mandatory, familiarity with MySQL, SQL, Scala, Java or C++ is an asset\nExperience using visualization tools (e.g. Jupyter Notebook) and data frameworks (e.g. Hadoop)\nAnalytical mind and business acumen\nStrong math skills (e.g. statistics, algebra)\nProblem-solving aptitude\nExcellent communication and presentation skills.\nBachelor\u2019s / Master's Degree in Computer Science, Engineering, Data Science or other quantitative or relevant field is preferred\nThank you for your interest in joining Ascendeum.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Ascendeum", "position": "Machine Learning Researcher", "location": "India"}, "python-developer-at-onefin-4257193441.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-developer-at-onefin-4257193441.html", "link": "https://in.linkedin.com/jobs/view/python-developer-at-onefin-4257193441?position=25&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=SLxaGnV73EjyVm10zvopow%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nResponsibilities\nDesign and implement backend infrastructure and APIs. \nWrite high quality code that is robust, readable and scales. \nPossess the drive to dive deep. thrive and progress even in ambiguous situations. \nEncourage and support knowledge sharing within teams and external groups. \nTroubleshoot & debug applications. \nAdopt problem solving as a way of life - always go to the root cause. \nCollaborate with the team to discuss and implement ideas. \nBuild responsive, robust and optimised applications. \nRequirements\nPassionate about building backend systems. \nDesire to explore new ideas, open to other ideas as well. \nLove for writing clean, beautiful, readable and testable code. \nExperience in designing extensible DRY code. \nOur stack is based on Django, Python3 Celery, Angular and Postgres. \nWe expect you to have a good understanding of Python. It's even better if you are familiar with some of Git. Django, Celery, Redis and Unix Shell. \nSkills:- Django, Flask, Python, Amazon Web Services (AWS) and Celery\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "OneFin", "position": "Python Developer", "location": "India"}, "executive-data-scientist-at-ascendeum-4273408579.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\executive-data-scientist-at-ascendeum-4273408579.html", "link": "https://in.linkedin.com/jobs/view/executive-data-scientist-at-ascendeum-4273408579?position=26&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=9r%2FIJT03Sm0XvQhaqVUwWg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAscendeum is looking for mathematicians, with extensive hands-on experience in the field of data science, who can analyze large data sets efficiently to generate actionable business intelligence that drives peak performance for our clients.\nAbout Us:\nWe provide AdTech strategy consulting to leading internet websites and apps hosting over 200 million monthly audiences worldwide. Since 2015, our consultants and engineers have consistently delivered intelligent solutions that enable enterprise-level websites and apps to maximize their digital advertising returns.\nJob Responsibilities:\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data.\nAnalyze large amounts of information to discover trends and patterns\nHelping develop reports and analysis.\nPresent information using data visualisation techniques.\nAssessing tests, implementing new or upgraded software, and assisting with strategic decisions on new systems.\nEvaluating changes and updates to source production systems.\nDevelop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks.\nProviding technical expertise in data storage structures, data mining, and data cleansing.\nPropose solutions and strategies to business challenges\nDesired Skills and Experience:\nRelevant 4+ years of experience in Data Analysis\nComplete understanding of Operations Research, Data Modelling, ML, and AI concepts.\nKnowledge of Python is mandatory, familiarity with MySQL, SQL, Scala, Java or C++ is an asset\nExperience using visualization tools (e.g. Jupyter Notebook) and data frameworks (e.g. Hadoop)\nAnalytical mind and business acumen\nStrong math skills (e.g. statistics, algebra)\nProblem-solving aptitude\nExcellent communication and presentation skills.\nBachelor\u2019s / Master's Degree in Computer Science, Engineering, Data Science or other quantitative or relevant field is preferred\nThank you for your interest in joining Ascendeum.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Ascendeum", "position": "Executive Data Scientist", "location": "India"}, "applied-ai-engineer-india-remote-at-wixjob-4270060681.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\applied-ai-engineer-india-remote-at-wixjob-4270060681.html", "link": "https://in.linkedin.com/jobs/view/applied-ai-engineer-india-remote-at-wixjob-4270060681?position=27&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=mAzK48AGSiJ0eHpIjlnevA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAs an Applied AI Engineer, you'll work at the intersection of machine learning research, product engineering, and customer success.\nAbout the Role\nYou\u2019ll be responsible for refining human datasets and transforming them into model-ready signals. You\u2019ll also translate real-world insights into product and infrastructure features that meaningfully improve the platform. In addition, you\u2019ll run tight feedback loops across the Ops and Engineering teams to ensure clients get the maximum value from Mercor by building tooling and prototypes.\nResponsibilities\nRefining human datasets and transforming them into model-ready signals.\nTranslating real-world insights into product and infrastructure features.\nRunning tight feedback loops across the Ops and Engineering teams.\nBuilding tooling and prototypes to maximize client value.\nQualifications\nPrevious founding or startup experience.\nRequired Skills\nFluency in React, Next.js, and Python.\nExperience designing schemas for SQL and NoSQL databases.\nExperience with Airflow or similar orchestration ETL tools.\nExperience deploying LLMs or other models in production, including evaluation pipelines.\nExperience with Systems Integration across recruitment systems, payments systems, CRMs, and data warehouses.\nInterest in evals, benchmarks, and annotation tooling.\nAttention to detail and eagerness to learn.\nPay range and compensation package\nBase cash comp from $40K-$100K.\nPerformance bonuses up to 40% of base comp.\n$1k referral bonuses available.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "WixJob", "position": "Applied AI Engineer (India-Remote)", "location": "India"}, "python-react-developer-at-dexian-india-4272828738.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-react-developer-at-dexian-india-4272828738.html", "link": "https://in.linkedin.com/jobs/view/python-react-developer-at-dexian-india-4272828738?position=28&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=Ks7nkkAcmm4SIyQIwjmDDA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nOverview:\nDescription: Senior Full Stack Developer \nPosition Overview: We are seeking a highly skilled Full Stack Developer to join our dynamic team within Global Trading at ExxonMobil. The ideal candidate will possess a robust understanding of both front-end and back-end development, with a strong emphasis on creating and maintaining scalable, high-performance applications. This role requires a professional who can seamlessly integrate into our team, contributing to the development of innovative solutions that drive our trading operations.\nTo be eligible for this role, you must be able to demonstrate:\n \u2022 Strong communication and interpersonal skills\n \u2022 Ability to collaborate effectively with internal and external customers\n \u2022 Innovative and analytical thinking\n \u2022 Ability to manage workload under time pressure and changing priorities\n \u2022 Adaptability and willingness to learn new technologies and methodologies\n Required Skills and Qualifications:\n\u2022 Technical Proficiency:\n \u2022 Expert Front-end React Framework & Backend Python Experience\n \u2022 Proficient in front-end technologies such as HTML, CSS, Strong back-end development skills, or similar languages.\n \u2022 Proficient GIT, & CI/CD experience.\n \u2022 Develop and maintain web applications using modern frameworks and technologies\n \u2022 Help maintain code quality, organization, and automation\n \u2022 Experience with relational database management systems.\n \u2022 Familiarity with cloud services (AWS, Azure, or Google Cloud \u2013 Primarily Azure).\n \n \u2022 Industry Knowledge:\n \u2022 Experience in the oil and gas industry, particularly within trading operations, is highly desirable.\n \u2022 Understanding of market data, trading systems, and financial instruments related to oil and gas.\n \n Preferred Qualifications:\n \u2022 Certifications in relevant technologies or methodologies.\n \u2022 Proven experience in building, operating, and supporting robust and performant databases and data pipelines.\n \u2022 Experience with Databricks and Snowflake\n \u2022 Solid understanding of web performance optimization, security, and best practices\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Dexian India", "position": "Python React Developer", "location": "India"}, "python-developer-at-datastack-technologies-4278062997.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-developer-at-datastack-technologies-4278062997.html", "link": "https://in.linkedin.com/jobs/view/python-developer-at-datastack-technologies-4278062997?position=29&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=V108rZuidETN6LAwpujDTg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout The Company:\nDatastack Technologies pioneers advanced technology solutions, blending innovative technology with data to transform the industry. We specialize in creating customized data analytics solutions and sophisticated enterprise applications at the forefront of technology. Our focus is on engineering systems that not only serve functional purposes but also revolutionize operational effectiveness for our clients, delivering measurable results.\nAbout the Role:\nWe're seeking an experienced Python developer with strong SQLAlchemy and pydantic expertise to join our backend team. In this role, you'll design, implement, and optimize database interactions for mission-critical applications.\nKey Responsibilities:\nDevelop and maintain Python database interfaces using SQLAlchemy ORM\nDesign and optimize complex database queries for case management functionality\nImplement secure permission systems to protect sensitive client information\nCreate reporting and analytics features for program performance measurement\nBuild data quality tools, including duplicate detection and validation systems\nWork with legacy database structures and implement modern best practices\nCollaborate with cross-functional teams to understand business requirements\nRequired Skills & Experience:\n4+ years of Python development experience\nStrong proficiency with SQLAlchemy ORM and SQL\nExperience with database design and optimization\nUnderstanding of permission and security models for sensitive data\nKnowledge of data quality techniques (fuzzy matching, deduplication)\nAbility to analyze complex database schemas and relationships\nExperience with relational databases (SQL Server, PostgreSQL, SQLite)\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Datastack Technologies", "position": "Python Developer", "location": "India"}, "python-full-stack-developer-at-altraize-4177184412.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-full-stack-developer-at-altraize-4177184412.html", "link": "https://in.linkedin.com/jobs/view/python-full-stack-developer-at-altraize-4177184412?position=30&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=mcXS4zXcyUprvQSAtOf9RQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          THIS IS A FULLY REMOTE JOB\nHiring Fullstack Engineer with a strong focus on backend development to join our growing team. In this role, you will be responsible for designing, developing, and maintaining high-performance software applications. Your expertise in Python and JavaScript (JS) will be crucial in building scalable and reliable backend systems.\nRequired Skills\n3+ years of professional experience in Python\nStrong SQL expertise with hands-on experience in database design, optimization, and management.\n2+ years of experience with Nest JS or other backend frameworks.\nFamiliarity with AWS/GCP is a plus.\nAbility to work independently as well as collaboratively within a team.\nStrong problem-solving skills with a focus on delivering high-quality code.\nNice to Have :Familiarity with front-end technologies (React or Angular) is a plus.\nFamiliarity with Python for scripting data analysis is a plus.\nExcellent spoken and written English communication skills\nIdeal Candidate Profile\n3+ years of overall experience\nEager to learn and grow within the company, with a proactive approach to personal and professional development.\nReliable and consistent in delivering high-quality work.\nStrong communication skills and a collaborative mindset.\nSkills: code,python,software,communication skills,full stack development,javascript\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Altraize", "position": "Python Full Stack Developer", "location": "India"}, "front-end-developers-ai-training-remote-at-braintrust-4220208768.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\front-end-developers-ai-training-remote-at-braintrust-4220208768.html", "link": "https://in.linkedin.com/jobs/view/front-end-developers-ai-training-remote-at-braintrust-4220208768?position=31&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=BFu9uSLc5L2iqDZs4EpjKg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nRequirements\n Swift, Python, Java, Go, Verilog, Javascript, C++, or C# coding experience required\nThis is a great opportunity to supplement your income while looking for longer or more full-time work, all while contributing to the development of new AI models using your domain expertise!\nOur client has hired over 1,000 Braintrust talent and intends to hire hundreds more!\nMany Braintrust coders earn over $12,000 per month!\nYou\u2019ll have the flexibility to work as much or as little as you choose - 20hrs/week is suggested, but not a limit. Start working in as little as 48 hours. Your final hourly rate will be chosen by Outlier AI and determined by your location.\nWhat to expect:\n If qualified, you\u2019ll be invited to complete a brief questionnaire that takes 3-5 minutes. If you successfully pass the questionnaire, you\u2019ll be approved and able to begin work ASAP.\nRequired qualifications:\nProficiency working one of the following languages: Swift, Python, Java, Go, Verilog, Javascript, C++, or C#\nComplete fluency in the English language is required. You should be able to describe code and abstract information in a clear way.\nPreferred qualifications:\nBachelor's and/or Master's degree in Computer Science or equivalent. Students are welcome.\nNote\n: Outlier AI is partnering with Remotasks for this opportunity\nWhat You\u2019ll Be Working On\nOur client has partnered with organizations to train AI large language models, helping cutting-edge generative AI models write better code. \nExample projects might include:\nEvaluating the quality of AI-generated code, including human-readable summaries of your rationale\nSolve coding problems, writing functional and efficient code\nOptimize code to run at maximum efficiency\nWriting robust test cases to confirm code works efficiently and effectively\nWriting human-readable summaries of coding problems\nWriting explanations of how code can solve problems and evaluate various solution approaches\nNo previous experience with AI necessary! \nYou will receive detailed instructions on what is expected of you after you complete the application and verification process.\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Braintrust", "position": "Front End Developers - AI Training [Remote]", "location": "India"}, "software-engineer-machine-learning-at-motive-4264402019.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-machine-learning-at-motive-4264402019.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-machine-learning-at-motive-4264402019?position=32&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=RPgvCbXAW5NabZits%2Beuow%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWho We Are\nMotive empowers the people who run physical operations with tools to make their work safer, more productive, and more profitable. For the first time ever, safety, operations and finance teams can manage their drivers, vehicles, equipment, and fleet related spend in a single system. Combined with industry leading AI, the Motive platform gives you complete visibility and control, and significantly reduces manual workloads by automating and simplifying tasks.\nMotive serves more than 100,000 customers \u2013 from Fortune 500 enterprises to small businesses \u2013 across a wide range of industries, including transportation and logistics, construction, energy, field service, manufacturing, agriculture, food and beverage, retail, and the public sector.\nVisit gomotive.com to learn more.\nAbout The Role\nAs a Software engineer - Machine Learning, you will be a part of a passionate team whose mission is to bring intelligence to the world\u2019s trucks. The team is focused on building technology to understand driving behavior, identify risk factors, and intelligently suggest coachable events that not only improve the fleet safety and potentially save millions of dollars but also contribute to making the roads safer. You will have a unique opportunity to work with a high-caliber and fast-paced team which consists of experienced researchers and engineers in Computer Vision, Machine Learning, Deep Learning, and Robotics with a track record of previous products and top-tier publications.\nYou will play a critical role in building and improving a technology that will be used by millions of trucks. In this role, you will design and implement complex machine-learning systems. You will have the opportunity to build and/or improve ML/computer vision systems. Identify where models and algorithms are failing, debug issues, propose solutions, implement, and deploy them on millions of trucks. You will also get exposure to large-scale ML infra and scaling that facilitates large amounts of data to train, test, and validate computer vision systems.\nWhat You\u2019ll Do\nEvaluate and improve the performance of existing models and algorithms already in production\nPrototype and implement ML modules for complex AI features\nBuild and optimize CV/ML algorithms for real-time performance so they can run on our embedded platform, i.e., the next-gen AI dashcam\nWrite proficient Python and C++ code to build and improve CV algorithms, ML services, training, model compression, and porting pipelines\nCollaborate with cross-functional teams such as Embedded, Backend, Frontend, Hardware, QA, and the broader AI team to ensure the development of robust and sustainable AI systems\nBuild automated deployment, validation, and active learning pipelines.\nWhat We\u2019re Looking For\nBachelor\u2019s Degree in Computer Science, Electrical Engineering, or related field. A Master\u2019s degree is a plus. \n5+ years of machine learning and/or data science experience\nSolid mathematical foundation in Deep Learning, Machine Learning, and optimization approaches.\nStrong experience in Python or C++\nExperience in the following tools and technologies is a plus. AWS (SageMaker, Lambda, EC2, S3, RDS), CI/CD, Terraform, Docker, and Kubernetes.\nPrior experience with optimizing and deploying ML models on embedded devices is a strong plus\nCreating a diverse and inclusive workplace is one of Motive's core values. We are an equal opportunity employer and welcome people of different backgrounds, experiences, abilities and perspectives. \nPlease review our Candidate Privacy Notice here .\nUK Candidate Privacy Notice here.\nThe applicant must be authorized to receive and access those commodities and technologies controlled under U.S. Export Administration Regulations. It is Motive's policy to require that employees be authorized to receive access to Motive products and technology.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Motive", "position": "Software Engineer, Machine Learning", "location": "India"}, "software-engineer-machine-learning-at-motive-4268347933.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-machine-learning-at-motive-4268347933.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-machine-learning-at-motive-4268347933?position=33&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=lAcrIlTcQ%2FNFGAHRpVuqeg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWho We Are\nMotive empowers the people who run physical operations with tools to make their work safer, more productive, and more profitable. For the first time ever, safety, operations and finance teams can manage their drivers, vehicles, equipment, and fleet related spend in a single system. Combined with industry leading AI, the Motive platform gives you complete visibility and control, and significantly reduces manual workloads by automating and simplifying tasks.\nMotive serves more than 100,000 customers \u2013 from Fortune 500 enterprises to small businesses \u2013 across a wide range of industries, including transportation and logistics, construction, energy, field service, manufacturing, agriculture, food and beverage, retail, and the public sector.\nVisit gomotive.com to learn more.\nAbout The Role\nAs a Software engineer - Machine Learning, you will be a part of a passionate team whose mission is to bring intelligence to the world\u2019s trucks. The team is focused on building technology to understand driving behavior, identify risk factors, and intelligently suggest coachable events that not only improve the fleet safety and potentially save millions of dollars but also contribute to making the roads safer. You will have a unique opportunity to work with a high-caliber and fast-paced team which consists of experienced researchers and engineers in Computer Vision, Machine Learning, Deep Learning, and Robotics with a track record of previous products and top-tier publications.\nYou will play a critical role in building and improving a technology that will be used by millions of trucks. In this role, you will design and implement complex machine-learning systems. You will have the opportunity to build and/or improve ML/computer vision systems. Identify where models and algorithms are failing, debug issues, propose solutions, implement, and deploy them on millions of trucks. You will also get exposure to large-scale ML infra and scaling that facilitates large amounts of data to train, test, and validate computer vision systems.\nWhat You\u2019ll Do\nEvaluate and improve the performance of existing models and algorithms already in production\nPrototype and implement ML modules for complex AI features\nBuild and optimize CV/ML algorithms for real-time performance so they can run on our embedded platform, i.e., the next-gen AI dashcam\nWrite proficient Python and C++ code to build and improve CV algorithms, ML services, training, model compression, and porting pipelines\nCollaborate with cross-functional teams such as Embedded, Backend, Frontend, Hardware, QA, and the broader AI team to ensure the development of robust and sustainable AI systems\nBuild automated deployment, validation, and active learning pipelines.\nWhat We\u2019re Looking For\nBachelor\u2019s Degree in Computer Science, Electrical Engineering, or related field. A Master\u2019s degree is a plus. \n5+ years of machine learning and/or data science experience\nSolid mathematical foundation in Deep Learning, Machine Learning, and optimization approaches.\nStrong experience in Python or C++\nExperience in the following tools and technologies is a plus. AWS (SageMaker, Lambda, EC2, S3, RDS), CI/CD, Terraform, Docker, and Kubernetes.\nPrior experience with optimizing and deploying ML models on embedded devices is a strong plus\nCreating a diverse and inclusive workplace is one of Motive's core values. We are an equal opportunity employer and welcome people of different backgrounds, experiences, abilities and perspectives. \nPlease review our Candidate Privacy Notice here .\nUK Candidate Privacy Notice here.\nThe applicant must be authorized to receive and access those commodities and technologies controlled under U.S. Export Administration Regulations. It is Motive's policy to require that employees be authorized to receive access to Motive products and technology.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Motive", "position": "Software Engineer - Machine Learning", "location": "India"}, "python-fullstack-developer-at-awign-4271810088.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-fullstack-developer-at-awign-4271810088.html", "link": "https://in.linkedin.com/jobs/view/python-fullstack-developer-at-awign-4271810088?position=34&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=Fbe9CzSNDgOo1DWdhMKesg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nTitle: React Fullstack Developer\nLocation: Bangalore, Hyderabad (Hybrid)\nTimings: Full Time (As per company timings)\nShift Timings: 5.30 AM IST to 2.30 PM IST\nNotice Period : (Immediate Joiner - Only)\nKey Responsibilities\n\u00d8  Architect and build responsive and performant UIs using ReactJS, TypeScript/JavaScript\n\u00d8  Design and implement component-based architectures using Redux, Context API, or React Query\n\u00d8  Collaborate closely with design and product teams to translate wireframes and mockups into high-quality code\n\u00d8  Implement frontend testing strategies using Jest, React Testing Library, or similar\n\u00d8  Optimize applications for speed, accessibility, and cross-browser compatibility\n\u00d8  Design, build, and maintain RESTful APIs and/or GraphQL endpoints using Django, Flask, or FastAPI\n\u00d8  Develop scalable backend services with focus on modularity, reusability, and testability\n\u00d8  Manage integrations with third-party APIs, services, and databases (PostgreSQL, MySQL, MongoDB)\n\u00d8  Implement authentication and authorization frameworks (OAuth2, JWT, etc.)\n\u00d8  Monitor and enhance application performance and scalability\n\u00d8  Contribute to sprint planning, backlog grooming, and retrospectives\n\u00d8  Maintain technical documentation for internal and external consumption\n \nRequired Qualifications\n\u00d8  6+ years of hands-on experience in full-stack development, with strong focus on ReactJS and Python\n\u00d8  Expertise in building and consuming RESTful APIs\n\u00d8  Solid experience in ReactJS, Redux/Context API, Hooks, and functional components\n\u00d8  Proficiency with Python web frameworks like Flask, FastAPI, or Django\n\u00d8  Strong understanding of relational and non-relational databases (e.g., PostgreSQL, MySQL, MongoDB)\n\u00d8  Good experience with Docker, Git, and modern CI/CD workflows\n\u00d8  Familiarity with system design, microservices, caching strategies, and asynchronous processing\n\u00d8  Excellent communication and leadership skills\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Awign", "position": "Python Fullstack Developer", "location": "Bangalore North Rural, Karnataka, India"}, "ai-growth-hacker-%E2%80%93-smb-client-acquisition-at-bayinfotech-4277224294.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\ai-growth-hacker-%E2%80%93-smb-client-acquisition-at-bayinfotech-4277224294.html", "link": "https://in.linkedin.com/jobs/view/ai-growth-hacker-%E2%80%93-smb-client-acquisition-at-bayinfotech-4277224294?position=35&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=SsPS1iMe2wb5SioTXFYHHQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nMission\n Win a steady stream of small- and medium-sized businesses that need \nbespoke\n AI chatbots or workflow automations\u2014then turn them into long-term, high-value clients.\nWhat You\u2019ll Do\nPinpoint ideal clients\n \u2013 Identify industries and pain points where a custom bot or automation delivers quick ROI; scrape and enrich prospect lists.\nSpark interest fast\n \u2013 Run low-cost, high-impact campaigns (personalized LinkedIn DMs, quick demo videos, micro-tools on Product Hunt/AppSumo) that showcase our \nservice\n capabilities.\nConvert & onboard\n \u2013 Build one-page landing sites, targeted email sequences, and 30-minute consultation offers that move prospects to signed SOWs.\nShow value early\n \u2013 Package \u201cpilot\u201d deliverables (e.g., single FAQ bot or one automated Zap) that prove ROI in 2\u20134 weeks and open upsell doors.\nAutomate your own funnel\n \u2013 Use ChatGPT prompts, Zapier/Make, Clay, Phantombuster, and basic JS/Python snippets to research, personalize outreach, and report on results.\nTrack & optimize\n \u2013 Own dashboards for leads, conversion rates, CAC, and revenue; kill or scale experiments every sprint.\nMust-Haves\n3+ yrs driving growth or demand-gen for B2B tech or agency services\u2014especially project-based or consultative offerings.\nComfortable with SaaS/growth stack (HubSpot/Apollo/Clearbit, Webflow, GA4, LinkedIn Sales Nav).\nHands-on with no-code/low-code automation tools and can tweak basic JavaScript/Python when needed.\nPortfolio of campaigns that generated $500k+ in service revenue from SMBs.\nData-obsessed, experiment-driven, and scrappy.\nPerks\n Remote-first, performance bonuses tied to booked revenue, budget for favorite growth tools, and a front-row seat building BayInfotech\u2019s AI consultancy from the ground up.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "BayInfotech", "position": "AI Growth Hacker \u2013 SMB Client Acquisition", "location": "India"}, "data-scientist-i-at-agco-corporation-4205966935.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-i-at-agco-corporation-4205966935.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-i-at-agco-corporation-4205966935?position=36&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=CELKN3XkcSyszm3J7q4Emw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          Do you want to help solve the world's most pressing challenges? Feeding the world's growing population and slowing climate change are two of the world's greatest challenges. AGCO is a part of the solution! Join us to make your contribution.\nAGCO is looking to hire candidates for the position of Data Scientist l. This position is responsible for the development and execution of data science and analytics use cases at AGCO. The Data Scientist executes the research, modeling design, implementation, and supports the deployment of full-stack scalable AI solutions to critical business opportunities.\n\u202f\nYour Impact \nInsight Identification: Collaborate with the AI Delivery Owner and key business stakeholders to identify and prioritize actionable and impactful insights across various core business areas, driving informed decision-making. \nMethodology Selection: Determine the most appropriate AI/ML techniques for addressing different classes of business problems and assess the feasibility of analytics use cases through proof-of-concept (POC) studies. \nOpportunity Translation: Translate business opportunities, needs, or hypotheses from partners into actionable tasks, effectively converting business requirements into mathematical and computational steps to deliver insights. \nSolution Development: Develop analytics solutions that align with business goals, ensuring statistical integrity and implementing accuracy tracking and lifecycle management techniques. \nChange Advocacy: Act as a change agent by engaging with business stakeholders and the data science community to educate, raise awareness, and build support for world-class data and analytics practices. \nYour Experience And Qualifications\nBachelor\u2019s degree with 4+ years of overall IT experience \n3+ years in Advanced analytics tools (Python, R, SAS, SQL etc.) to carry out statistical and machine learning analysis. \nUse big data computing frameworks for processing of large data volumes (AWS Sagemaker, EMR, Databricks and other) \nFamiliar with cloud technologies for model development and deployment. \nYour Benefits\nGLOBAL DIVERSITY \u2013 Diversity means many things to us, different brands, cultures, nationalities, genders, generations \u2013 even variety in our roles. You make us unique!\n\u202f\nENTERPRISING SPIRIT- Every role adds value. We're committed to helping you develop and grow to realize your potential.\n\u202f\nPOSITIVE IMPACT \u2013 Make it personal and help us feed the world.\n\u202f\nINNOVATIVE TECHNOLOGIES - You can combine your love for technology with manufacturing excellence \u2013 and work alongside teams of people worldwide who share your enthusiasm.\n\u202f\nMAKE THE MOST OF YOU \u2013 Benefits include health care and wellness plans and flexible and virtual work option\u2026\u2026\u2026.\nYour Workplace\nWe value inclusion and recognize the innovation a diverse workforce delivers to our farmers. Through our recruitment efforts, we are committed to building a team that includes a variety of experiences, backgrounds, cultures and perspectives.\nJoin us as we bring agriculture into the future and apply now! \nPlease note that this job posting is not designed to cover or contain a comprehensive listing of all required activities, duties, responsibilities, or benefits and may change at any time with or without notice.\n\u202f\nAGCO is proud to be an Equal Opportunity Employer\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "AGCO Corporation", "position": "Data Scientist I", "location": "Pune, Maharashtra, India"}, "senior-machine-learning-engineer-at-goml-4275069363.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\senior-machine-learning-engineer-at-goml-4275069363.html", "link": "https://in.linkedin.com/jobs/view/senior-machine-learning-engineer-at-goml-4275069363?position=37&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=nGZ8%2BhPZRG0DpS5SeA%2Bkqw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nLooking for a culture to thrive & build a rewarding career for yourself, join the core team of young hustlers building the next generation of Machine Learning platform & services. You will develop training and deployment pipelines for machine learning, implement model compression algorithms, and productionize machine learning research solving challenging business problems.\nKey Responsibilities:\nDesign and develop generative AI models using techniques like RAG, transformers, and other relevant approaches.\nFine-tune pre-trained LLMs for specific tasks and domains.\nConduct research on new techniques for improving the performance and capabilities of generative AI models.\nApply software engineering rigor and best practices to machine learning /Generative AI pipelines.\nEvaluate and analyse the performance of ML/generative AI models.\nStay up to date on the latest advancements in generative AI research.\nFacilitate the development and deployment of proof-of-concept Generative AI systems.\nQualifications:\nBachelor\u2019s/Master\u2019s degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n5+ years of experience in generative AI or related fields.\nExperience in building data pipelines, deploying ML/GenAI models in production, and monitoring and maintaining their performance.\nStrong programming skills in Python.\nFamiliarity with RAG and other techniques for building generative models.\nExtensive experience with Git, Docker and a good understanding of Linux for managing servers.\nExperience with cloud-based ecosystems, especially AWS ML/GenAI services.\nExposure to ML/GenAI frameworks and tools.\nExcellent communication and collaboration skills.\nAbility to work independently and in a team-oriented environment.\nMethodical and meticulous towards work and planning.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "goML", "position": "Senior Machine Learning Engineer", "location": "India"}, "quality-assurance-automation-engineer-at-recro-4263348668.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\quality-assurance-automation-engineer-at-recro-4263348668.html", "link": "https://in.linkedin.com/jobs/view/quality-assurance-automation-engineer-at-recro-4263348668?position=38&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=PYhjXjXA9v%2B3I73%2FXjoEvw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \n!! FOR IMMEDIATE JOINERS AND THOSE SERVING NOTICE ONLY !! (Won't be of any use to you if you still apply.)\nLocation: Noida (Remote)\nExperience: 3+ yrs of full time\nNotice Period: IMMEDIATE JOINERS ONLY\nRequirement\n:\nWe are looking for a QA Automation Engineer with expertise and hands-on experience with \nUI Testing and API Testing.\nExpertise in \nJava, Javascript, Selenium, Rest Assured, TestNG,\n etc\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Recro", "position": "Quality Assurance Automation Engineer", "location": "Noida, Uttar Pradesh, India"}, "swift-coders-ai-training-remote-at-braintrust-4233232867.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\swift-coders-ai-training-remote-at-braintrust-4233232867.html", "link": "https://in.linkedin.com/jobs/view/swift-coders-ai-training-remote-at-braintrust-4233232867?position=39&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=2wVlmycYzNa0ssIaVz6Yxw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \n* Swift, Python, Java, Go, Verilog, Typescript, Javascript, C++, or C# coding experience required\nThis is a great opportunity to supplement your income while looking for longer or more full-time work, all while contributing to the development of new AI models using your domain expertise!\nOur client has hired over 1,000 Braintrust talent and intends to hire hundreds more!\nMany Braintrust coders earn over $12,000 per month!\nYou\u2019ll have the flexibility to work as much or as little as you choose - 20hrs/week is suggested, but not a limit. Start working in as little as 48 hours. Your final hourly rate will be chosen by Outlier AI and determined by your location.\nWhat to expect:\n If qualified, you\u2019ll be invited to complete a brief questionnaire that takes 3-5 minutes. If you successfully pass the questionnaire, you\u2019ll be approved and able to begin work ASAP.\nRequired qualifications:\nProficiency working one of the following languages: Swift, Python, Java, Go, Verilog, Typescript, Javascript, C++, or C#\nComplete fluency in the English language is required. You should be able to describe code and abstract information in a clear way.\nPreferred qualifications:\nBachelor's and/or Master's degree in Computer Science or equivalent. Students are welcome.\nNote\n: Outlier AI is partnering with Remotasks for this opportunity\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Braintrust", "position": "Swift Coders - AI Training [Remote]", "location": "India"}, "ai-engineer-chatbot-at-hire22-ai-4278907819.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\ai-engineer-chatbot-at-hire22-ai-4278907819.html", "link": "https://in.linkedin.com/jobs/view/ai-engineer-chatbot-at-hire22-ai-4278907819?position=40&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=CsV1GEbWiL%2FkkX%2BW73V9yw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nOne of our client is seeking a \nChatbot Engineer\n with \n3-5 Years of experience\n to design and build the next generation of Conversational AI/NLP products, with a focus on Python and related frameworks, and experience in chatbot development. This is an exciting job role that involves building a long-term career in Conversational AI/NLP and Deep Learning & opportunity to join one of the fastest growing Conversational AI companies in US/Silicon Valley.\nJob Description\nStrong skillset in python related frameworks/tools, and other back-end applications.\nExperience in designing and building Chatbots / Voicebots- are preferred.\nDesigning, developing, and managing data structures and database management systems.\nMaintaining and upgrading existing products and features.\nKey Requirements\nMin 3 years of experience working on NLP or Conversational AI products like Rasa NLU/projects\nAt least 3 years of experience with Python and related frameworks and components\nAt least 3 years of hands-on experience with data structures and database design.\nUnderstanding and experience in working on Machine Learning algorithms and Data Science projects.\nStrong analytical skills and ability to understand concepts quickly.\nExperience in working with cross-border and cross-functional teams.\nGood communication skills and ability to multi-task.\nProven experience in high-level programming languages, like conversational platforms, Python, software development methodologies, and in building complex web systems.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Hire22.ai", "position": "AI Engineer (Chatbot)", "location": "India"}, "swift-coders-ai-training-remote-hindi-speakers-encouraged-at-braintrust-4233242911.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\swift-coders-ai-training-remote-hindi-speakers-encouraged-at-braintrust-4233242911.html", "link": "https://in.linkedin.com/jobs/view/swift-coders-ai-training-remote-hindi-speakers-encouraged-at-braintrust-4233242911?position=41&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=gpPg5oo8EbbqhoVunzYalw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \n* Swift, Python, Java, Go, Verilog, Typescript, Javascript, C++, or C# coding experience required\nThis is a great opportunity to supplement your income while looking for longer or more full-time work, all while contributing to the development of new AI models using your domain expertise!\nOur client has hired over 1,000 Braintrust talent and intends to hire hundreds more!\nMany Braintrust coders earn over $12,000 per month!\nYou\u2019ll have the flexibility to work as much or as little as you choose - 20hrs/week is suggested, but not a limit. Start working in as little as 48 hours. Your final hourly rate will be chosen by Outlier AI and determined by your location.\nWhat to expect:\n If qualified, you\u2019ll be invited to complete a brief questionnaire that takes 3-5 minutes. If you successfully pass the questionnaire, you\u2019ll be approved and able to begin work ASAP.\nRequired qualifications:\nProficiency working one of the following languages: Swift, Python, Java, Go, Verilog, Typescript, Javascript, C++, or C#\nComplete fluency in the English language is required. You should be able to describe code and abstract information in a clear way.\nPreferred qualifications:\nBachelor's and/or Master's degree in Computer Science or equivalent. Students are welcome.\nNote\n: Outlier AI is partnering with Remotasks for this opportunity\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Braintrust", "position": "Swift Coders - AI Training [Remote] (Hindi Speakers Encouraged)", "location": "India"}, "senior-python-software-engineer-voice-ai-at-checkmate-4267059360.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\senior-python-software-engineer-voice-ai-at-checkmate-4267059360.html", "link": "https://in.linkedin.com/jobs/view/senior-python-software-engineer-voice-ai-at-checkmate-4267059360?position=42&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=gYVKfH3ksGZCaqvqH51YMQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          This role offers the opportunity to create new products from the ground up, significantly influence product direction and the engineering roadmap, participate in building our voice team culture, and ultimately shape the future of restaurant technology. Your efforts will enhance customer interactions, ensuring a seamless and enjoyable experience.\nRequirements\nBackend Development: Design, implement, and maintain scalable backend systems to support real-time audio processing and streaming\nAudio Systems Engineering: Develop and optimize real-time audio pipelines for voice interaction, integrating algorithms for speech enhancement, noise reduction, and multi-channel processing\nPython Development: Write efficient, maintainable Python code for backend services, real-time audio processing tools, and system integrations\nCollaborative Problem-Solving: Work with cross-functional teams, including AI/ML engineers and product managers, to ensure seamless integration of audio and backend systems\nCode Excellence: Write clean, maintainable code, debug issues efficiently, and optimize for performance and reliability\nInnovation: Explore and implement cutting-edge technologies in audio processing and backend engineering to future-proof our systems\nBenefits\nBachelor's degree or higher in software engineering or other relevant education with 5+ years of industry experience in computer science or engineering\nExperience with real-time streaming protocols, multi-threaded programming, and performance optimization, particularly in audio applications is a plus\nExperience with implementing and optimizing DSP algorithms such as filtering, echo cancellation, voice activity detection, source separation, and noise suppression for real-time audio systems\nExperience with developing building backend systems and integrations in Python\nPassion for exploring emerging technologies and applying them to solve real-world problems\nGood problem-solving skills and ability to work independently and in a team\nStrong communication skills for explaining technical ideas to various audiences\nUnderstanding of conversational English and experience with voice programs/products\nAvailability to work during US hours at least till 5 pm ET is essential for this role\nCandidates must have their own system/work setup for remote work\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Checkmate", "position": "Senior Python Software Engineer (Voice AI)", "location": "India"}, "backend-developer-python-intern-at-shiryam-technologies-4257190806.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\backend-developer-python-intern-at-shiryam-technologies-4257190806.html", "link": "https://in.linkedin.com/jobs/view/backend-developer-python-intern-at-shiryam-technologies-4257190806?position=43&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=3KzOcdH5exH7gAzh33rIBg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          We are looking for a Python Web Developer Intern responsible for managing the interchange of data between the server and the users. Your primary focus will be the development of all server-side logic, ensuring high performance and responsiveness to requests from the front-end.\nPerks Of Working With Us\nCompetitive stipend\nRemote option available\nCertificate and Letter of recommendation\nSlack/Asana focussed environment\nCool managers\nMeme focussed communication\nOpportunity to convert to work full-time\nSkills\nIn-depth knowledge in Python, with knowledge of at least one Python web framework \nFamiliarity with some ORM (Object Relational Mapper) libraries\nAble to integrate multiple data sources and databases into one system\nGood understanding of server-side templating languages\nBasic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3\nUnderstanding of accessibility and security compliance\nStrong analytical skills and problem solving aptitude\nAttentive to details\nAvailable for 6 months\nSkills:- Django and Flask\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Shiryam Technologies", "position": "Backend Developer (Python Intern)", "location": "India"}, "backend-developer-java-python-at-weekday-ai-yc-w21-4276678579.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\backend-developer-java-python-at-weekday-ai-yc-w21-4276678579.html", "link": "https://in.linkedin.com/jobs/view/backend-developer-java-python-at-weekday-ai-yc-w21-4276678579?position=44&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=hXEoDDMrzG7EPmzjU2iBzg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nThis role is for one of the Weekday's clients\nMin Experience: 3 years\nLocation: Remote (India), Bengaluru\nJobType: full-time\nWe are seeking a talented \nBackend Developer\n with strong expertise in \nPython\n and \nJava\n to join our engineering team. This role involves developing scalable backend services, integration solutions, and AI-driven features that power intelligent applications.\nRequirements\nKey Responsibilities:\n Design, develop, and maintain robust backend systems using Java and Python. \n Build and improve integration frameworks for cloud-based and on-premise environments. \n Develop optimized RESTful APIs and backend logic to support scalable systems. \n Work collaboratively in Agile teams alongside product managers, QA engineers, and developers. \n Review code, ensure best practices, and mentor junior team members. \n Investigate and resolve production issues to maintain system reliability. \n Develop autonomous AI agents with intelligent decision-making capabilities. \n Integrate large language models (LLMs) to enhance application intelligence and user experiences. \nRequired Skills & Qualifications:\n 3 to 5 years of professional experience with Java and Python in backend development. \n Strong knowledge of object-oriented programming (OOP) and design patterns. \n Experience building RESTful APIs and working with microservices architectures. \n Familiarity with multithreading, concurrency, and system performance optimization. \n Exposure to cloud platforms such as AWS or Microsoft Azure is an advantage. \n Proficient with tools like Git, Maven, Jenkins, and Docker. \n Hands-on experience with LLM frameworks like LangChain or LangGraph is preferred. \n Strong analytical thinking and debugging skills. \n Excellent verbal and written communication skills with a collaborative mindset.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Weekday AI (YC W21)", "position": "Backend Developer (Java & Python)", "location": "Bengaluru, Karnataka, India"}, "senior-python-developer-at-checkmate-4271406229.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\senior-python-developer-at-checkmate-4271406229.html", "link": "https://in.linkedin.com/jobs/view/senior-python-developer-at-checkmate-4271406229?position=45&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=a0%2FZeGVLFKGZzPP%2Fv8AGpQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nIntegrating with APIs provided by the backend team to provide seamless connections between our applications\n Integrating with external APIs directly\n Expanding the capabilities of our REST APIs: building new endpoints using the OpenAPI specification\n Building new backend functionalities to help expand the feature set of our customer- facing products\n Improving the end-user experience by reducing the latency of API endpoints using all tools available (SQL queries, indices, caching, background tasks, Datadog APM, etc.)\n Tracking down and fixing bugs encountered by end users\n Refactoring parts of the application that require modernizing\n Expanding the scope and coverage of the automated test suite\nRequirements\n Very strong written and verbal communication skills\n 5-10 years as a Python Developer\n Experience with Flask or Django, with a strong preference for Flask experience\n A thorough understanding of working directly with databases and writing custom SQL queries\n Experience working on a consumer-facing application with high-performance requirements\n Experience integrating with external APIs for things like payments and other non-core features\n Experience working on an e-commerce application, preferably in the restaurant or retail industry\n Knowledge of and experience with CRM and/or loyalty & marketing applications, either directly or indirectly by integrating with such systems\n Hands-on experience with Celery, Redis, Docker, Linux, and AWS is a plus\n Experience working with an established code base and taking ownership of certain parts of the code base (if you have only worked on projects built from scratch, this role is not for you)\n Ability to work independently with minimal supervision: you should be a self-starter who doesn't require constant oversight to stay on task and enjoys solving problems largely on your own\n BSc in Computer Science, Engineering, or relevant field\n The employee needs to be available until at least 5 p.m. US Eastern Time. Since we hire from across the world, it is important for our employees to coordinate and be present in real time\n Candidates must have their own system/work setup for remote work\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Checkmate", "position": "Senior Python Developer", "location": "Mumbai Metropolitan Region"}, "search-engineer-at-lucidworks-4275972759.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\search-engineer-at-lucidworks-4275972759.html", "link": "https://in.linkedin.com/jobs/view/search-engineer-at-lucidworks-4275972759?position=46&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=ytkgy97AV7cuyBnbWaXUqA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nLucidworks is leading digital transformation for some of the world's biggest retailers, financial services firms, manufacturers, and B2B commerce organizations. We believe that the core to a great digital experience starts with search and browse. Our Deep Learning technology captures user behavior and utilizes machine learning to connect people with the products, content, and information they need. Brands including American Airlines, Lenovo, Red Hat, and Cisco Systems rely on Lucidworks' suite of products to power commerce, customer service, and workplace applications that delight customers and empower employees. Lucidworks believes in the power of diversity and inclusion to help us do our best work. We are an Equal Opportunity employer and welcome talent across a full range of backgrounds, orientation, origin, and identity in an inclusive and non-discriminatory way.\nAbout the Team\nThe technical support team leverages their extensive experience supporting large-scale Solr clusters and the Lucene/Solr ecosystem. Their day might include troubleshooting errors and attempting to fix or develop workarounds, diagnosing network and environmental issues, learning your customer's infrastructure and technologies, as well as reproducing bugs and opening Jira tickets for the engineering team. Their primary tasks are break/fix scenarios where the diagnostics quickly bring network assets back online and prevent future problems--which has a huge impact on our customers\u2019 business.\nAbout the Role\nAs a Search Engineer in Technical Support, you will play a critical role in helping our clients achieve success with our products. You will be responsible for assisting clients directly in resolving any technical issues they encounter, as well as answering questions about the product and feature functionality. You will work closely with internal teams such as Engineering and Customer Success to resolve a variety of issues, including product defects, performance issues, and feature requests.\nThis role requires excellent problem-solving skills and attention to detail, strong communication abilities, and a deep understanding of search technology. Additionally, this role requires the ability to work independently and as part of a team, and being comfortable working with both technical and non-technical stakeholders. The successful candidate will demonstrate a passion for delivering an outstanding customer experience, balancing technical expertise with empathy for the customer\u2019s needs.\nThis role is open to candidates in India. The role expected to participate in weekend on-call rotations.\nResponsibilities\nField incoming questions, help users configure Lucidworks Fusion and its components, and help them to understand how to use the features of the product\nTroubleshoot complex search issues in and around Lucene/Solr\nDocument solutions into knowledge base articles for use by our customer base in our knowledge center\nIdentify opportunities to provide customers with additional value through follow-on products and/or services\nCommunicate high-value use cases and customer feedback to our Product Development and Engineering teams\nCollaborate across teams internally to diagnose and resolve critical issues\nParticipating in a 24/7/365 on-call rotation, which includes weekends and holidays shifts\nSkills & Qualifications\n3+ years of hands-on experience with Lucene/Solr or other search technologies is \nrequired\nBS or higher in Engineering or Computer Science is preferred\n3+ years professional experience in a customer facing level 2-3 tech support role\nExperience with technical support CRM systems (Salesforce, Zendesk etc.)\nAbility to clearly communicate with customers by email and phone\nProficiency with Java and one or more common scripting languages (Python, Perl, Ruby, etc.)\nProficiency with Unix/Linux systems (command line navigation, file system permissions, system logs and administration, scripting, networking, etc.)\nExposure to other related open source projects (Mahout, Hadoop, Tika, etc.) and commercial search technologies\nEnterprise Search, eCommerce, and/or Business Intelligence experience\nKnowledge of data science and machine learning concepts\nExperience with cloud computing platforms (GCP, Azure, AWS, etc.) and Kubernetes\nStartup experience is preferred\nOur Stack\nApache Lucene/Solr, ZooKeeper, Spark, Pulsar, Kafka, Grafana\nJava, Python, Linux, Kubernetes\nZendesk, Jira\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Lucidworks", "position": "Search Engineer", "location": "India"}, "application-engineer-at-vericut-4268459061.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\application-engineer-at-vericut-4268459061.html", "link": "https://in.linkedin.com/jobs/view/application-engineer-at-vericut-4268459061?position=47&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=90GVfyLOOviBDNbatQPaAg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nPosition Overview:\nWe are seeking a highly skilled and self-motivated Application Engineer \u2013 Vericut Solutions to provide expert technical support, training, and demonstrations for Vericut software suite, including Virtual Machine Configurations (VMCs). This role requires strong CAM and CNC machining knowledge, excellent customer-facing skills, and the ability to work closely with both customers and internal stakeholders to optimize software implementation and usage. The ideal candidate will thrive in a dynamic environment, possess strong communication skills, and be able to travel for onsite support, demos, and joint programs with partners such as Sandvik. This position will be remotely based in Pune, India.\nKey Responsibilities:\nProvide comprehensive onsite and remote support for Vericut software, including configuration of Virtual Machine Configurations (VMCs)\nConduct in-depth product demonstrations tailored to specific customer challenges, showcasing Vericut and Force as optimal solutions\nTravel independently to customer sites for demos, training, and support as required\nAssist customers in maximizing the ROI of their software investment through expert consultation and training\nEngage with customer teams including plant engineers, R&D personnel, and senior management to build long-term relationships\nProvide exceptional customer experience and insights into how Vericut fits into various manufacturing and software ecosystems.\nCollaborate proactively with internal Sandvik teams and external partners on joint initiatives, lead generation, and technical programs.\nDeliver training sessions for internal and external partners to enhance product knowledge and capabilities.\nMaintain accurate pre-sales and customer engagement records in Salesforce (CRM).\nRequirements:\nMinimum 3 years of hands-on experience operating 5-axis Vertical Machining Centers (VMCs) and Turn-Mill machines.\nProven experience with 5-axis CAM programming using tools such as Siemens NX, CATIA, Mastercam, or similar platforms.\nPractical experience in CNC part programming for controls including Siemens, Heidenhain, Mazatrol, and Fanuc.\nPrior experience with Vericut software is a strong advantage.\nStrong problem-solving, troubleshooting, and analytical skills.\nExcellent communication and interpersonal abilities.\nProactive, self-starting attitude with the ability to work both independently and as part of a collaborative team.\nSolid project management and organizational skills.\nAll hiring practices, employment terms, and conditions will be conducted in accordance with the applicable local labor laws and regulations of the specific hiring location. Any variations in employment terms, including benefits, working hours, and legal requirements, will reflect the legal standards and customary practices of the region in which the employee is hired.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Vericut", "position": "Application Engineer", "location": "Pune, Maharashtra, India"}, "front-end-developer-expertise-for-ai-training-at-outlier-4269671349.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\front-end-developer-expertise-for-ai-training-at-outlier-4269671349.html", "link": "https://in.linkedin.com/jobs/view/front-end-developer-expertise-for-ai-training-at-outlier-4269671349?position=48&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=vVeOpGePqCM31XJPVdNnpQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          Outlier helps the world\u2019s most innovative companies improve their AI models by providing human feedback. Are you a world-class front-end developer or web designer who wants to help shape the future of AI?\nWe collaborate with leading AI organizations to train large language models\u2014teaching them how to design and code like the best front-end engineers and designers in the world. Our projects focus on helping generative AI improve its understanding of front-end technologies, UI/UX principles, and modern web standards.\nThis is a rare opportunity to put your coding and design skills to work in training cutting-edge AI systems\u2014no prior experience with AI is required.\nAbout The Opportunity\nOutlier is looking for exceptional front-end developers and designers to help train generative AI models.\nThis freelance role is fully remote and offers flexible hours\u2014you can work whenever works best for you.\nYou may contribute your expertise by\u2026\nCreating and answering questions about front-end development and web design to help train AI models\nReviewing and evaluating code generated by AI in JavaScript, React, and other modern front-end frameworks\nAssessing UI/UX quality, accessibility, and design choices made by AI-generated code\nOffering expert-level feedback on what makes a user interface intuitive, functional, and beautiful\nWe\u2019re looking for people with\u2026\nStrong technical skills in HTML, CSS, JavaScript, and frameworks like React, Next.js, Vue, or similar\nAn eye for world-class design\u2014deep understanding of UI/UX principles, responsive design, and interaction patterns\nExperience building polished, accessible, and production-ready web interfaces\nA background in computer science, web development, or digital design (degree not required if experience is exceptional)\nOutstanding attention to detail and ability to communicate clearly about visual and code quality\nPayment\nCurrently, pay rates for core project work range from USD $13.50 to $27.50 per hour.\nRates vary based on expertise, skills assessment, location, project need, and other factors. For example, higher rates may be offered to PhDs. For non-core work, such as during initial project onboarding or project overtime phases, lower rates may apply. Certain projects offer incentive payments. Please review the payment terms for each project.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Outlier", "position": "Front-End Developer Expertise for AI Training", "location": "India"}, "big-data-developer-at-kresta-softech-private-limited-4272141830.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\big-data-developer-at-kresta-softech-private-limited-4272141830.html", "link": "https://in.linkedin.com/jobs/view/big-data-developer-at-kresta-softech-private-limited-4272141830?position=49&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=CRDrn3JZSxanP9bhHYryfA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nRole Highlights:\nPosition: Big Data Engineer\nExperience:\n 4+ years\nLocation:\n All India-Remote, Hyderabad- Hybrid\nNotice Period:\n Immediate/7 days joiners mandate\nJob Overview:\nMust have skills- Big Data, Scala, AWS and Python or Java\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Kresta Softech Private Limited", "position": "Big Data Developer", "location": "India"}, "platform-engineer-at-niksun-4255561683.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\platform-engineer-at-niksun-4255561683.html", "link": "https://in.linkedin.com/jobs/view/platform-engineer-at-niksun-4255561683?position=50&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=1nqZmcFyC1VtcAGuTkrjVw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nOS Engineer/Platform Engineer\nRemote, India \nNIKSUN is the recognized worldwide leader in making the Unknown Known, by using the next generation technology that revolutionizes the way networks and services are secured, protected, and managed. The company develops and deploys a complete range of award-winning forensics, compliance, security surveillance and performance management solutions for applications ranging from core infrastructures to edge and branch environments.\nResponsibilities\n:\nWork with other OS Engineers to design, develop, test, and maintain custom kernel and kernel modules\nKnowledge of Linux for remote machine set up & lab machine management \nDevelop portable code base: Application, libraries, tools between various *nix variants\nAutomate build and test environment\nIn-depth code Analysis, code review of in-house code and 3rd party code\nImprove software stack, tooling, processes.\nTroubleshoot incidents across infrastructure, network, storage, levels of stack.\nDocument findings, procedures for repetitive tasks and use them for automation.\nEvaluating new hardware servers, NICs\nAdd support for new hardware, NIC, Storage controllers, JBODs\nDevelop custom command Shell\nCustom ISO installer development\nRequirements:\n1-3 years of Linux device driver development experience\n1-3 years of application development experience in Linux environments\nThorough understanding of Linux kernel internals especially memory management, filesystem, irq, DMA, IOMMU, Networking etc.\nProficient coding skills in one of the C, C++\nHands-on coding skills in one of the scripting language Bash, Python, Perl\nExperience using and maintaining various build environments (auto make, CMAKE, Clang) and version control systems (GIT, CVS, SVN)\nExperience using various kernel and process debugging, profiling tools (Val grind, Gdb, kdb, perf etc.)\nRequired Skills and Traits:\nCan-do and will-do attitude\nGood written and oral communication skills\nTeamwork and collaboration\nShare knowledge and mentor team members\nNice to have Skills:\nPacket data-path acceleration framework knowledge (DPDK, netmap, PF_PACKET etc.)\nknowledge of Golang, Rust\nPCI device driver knowledge\nYou know about docker, Kubernetes, cgroups, namespace\nYou\u2019ve worked on an application that runs on virtual environment\nExtra points if have committed to Linux kernel\nProfessional Requirements:\nBachelor\u2019s degree in computer science or computer engineering\n1-3 years of experience in the fields of site reliability, platform engineering / DevSecOps\nQualified applicants will receive consideration for employment without regard to age, race, creed, color, religion, sex, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, or protected veteran status\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "NIKSUN", "position": "Platform Engineer", "location": "India"}, "junior-site-reliability-engineer-at-jove-4273783458.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\junior-site-reliability-engineer-at-jove-4273783458.html", "link": "https://in.linkedin.com/jobs/view/junior-site-reliability-engineer-at-jove-4273783458?position=51&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=WdTjZU4GaHuJu5p1wNvMaQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJoVE is the world-leading producer and provider of science video solutions with the mission to improve scientific research and education. Millions of scientists, educators and students use JoVE for their research, teaching and learning. Our institutional clients comprise over 1,000 universities, colleges, and biopharma companies, including such leaders as Harvard, MIT, Yale, and Stanford. As a rapidly growing company, with offices in the USA, UK, Australia, and India servicing clients in over 60 countries, we are seeking talented and ambitious individuals to join our company.60 countries, we are seeking talented individuals to join our company.\nThe Role\nWe are looking for a Junior Site Reliability Engineer who will be part of our centralized Site Reliability Team. You will play an integral role in leading the deployment of highly scalable systems, optimization, documentation, and support of the infrastructure components of JoVE\u2019s software products hosted on AWS. Cloud Infrastructure and Operations are critical in enabling JoVE to provide users with our technology offerings.\nResponsibilities: \nDesign, build, test, and deploy cloud-native applications and microservices using IaC tools like Terraform and Crossplane.\nMaintain availability, latency, performance, efficiency, monitoring/observability, emergency response, capacity planning, setting and maintaining SLOs, SLIs, and Error Budgets, and creating dashboards.\nPlan for automation to reduce toil and increase development velocity.\nPerform application-specific production support, incident management, change management, problem management, RCAs, and service restoration as needed.\nActively look for opportunities to improve the availability and performance of the system by applying the learnings from monitoring and observation.\nCollaborate with software development teams in the release management process to shape the future roadmap and establish strong operational readiness across teams.\nSpearhead implementation of reliability and observability tools (like Groundcover, Prometheus, Grafana, etc.)\nSupport Infrastructure squad On-call practice and participate in 24x7 on-call rotations.\nRequirements:\n2+ years of professional experience as a Software Engineer and Site Reliability Engineer (SRE).\nExtensive in-depth experience with cloud-based provisioning, monitoring, troubleshooting, and related SRE and DevOps technologies, in addition to networking knowledge.\nMUST have working experience with AWS infrastructure. \nMUST understand AWS VPC, subnets, Network ACLs, Security Groups, IAM Role, EKS.\nMUST have experience of using Crossplane\nMUST have working knowledge of GitOps, FluxCD, or ArgoCD \nExperience configuring Kubernetes RBAC Authorization, Ingress controller, ServiceAccount, and AWS role annotations.\nBasic experience with monitoring, and observability systems such as DataDog, Prometheus, Grafana, Kibana, CloudWatch.\nAbility to triage and resolve incidents and lead incident investigations.\nExperience working in a 24/7 on-call, highly transactional, or streaming production environment.\nExperience with Kubernetes Operators is a plus.\nWhy Join JoVE?\nWhen working with JoVE, you can expect compensation packages competitively placed within the local market.\nYou will make a direct impact in accelerating science research and in improving student learning in science education.\nOpportunity to work with global teams and in an environment that promotes innovation and collaboration.\nOur strong promotion from within culture draws a clear path to advance your career with us.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "JoVE", "position": "Junior Site Reliability Engineer", "location": "India"}, "founding-engineer-at-weekday-ai-yc-w21-4266732348.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\founding-engineer-at-weekday-ai-yc-w21-4266732348.html", "link": "https://in.linkedin.com/jobs/view/founding-engineer-at-weekday-ai-yc-w21-4266732348?position=52&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=FS1a09gaLDSmfo4EHTfrOA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          This role is for one of Weekday's clients\nSalary range: Rs 4000000 - Rs 6500000 (ie INR 40-65 LPA)\nMin Experience: 3 years\nLocation: Remote (India)\nJobType: full-time\nRequirements\nAs a \nFounding Engineer\n you will play a pivotal role in shaping our flagship product. You will be responsible for designing and building a sandboxed coding agent capable of executing real-world automated tasks. This role emphasizes practical construction of robust systems with a strong focus on architecture, security, scalability, and product vision. You will have the opportunity to work in a collaborative, agile startup environment where your code, ideas, and product insights directly impact the development of the product.\nResponsibilities\n Develop a sandboxed coding agent that can execute shell commands, and Python/TypeScript code\n Implement file manipulation and GUI control using technologies such as xdot\n Design and integrate mechanisms for context persistence beyond token limits using file-based storage, pruning, etc\n Deploy the agent within a Docker container featuring a display server, noVNC, and Jupyter\n Orchestrate tasks through /schedule and /status endpoints operating in Firecracker VMs\n Bonus: Enhance the system by adding Kubernetes or Nomad support for horizontal scaling\nQualifications\n Strong coding skills in Python, TypeScript, and shell scripting\n Experience with containerization and Docker, including setting up and managing container environments\n Familiarity with virtualization techniques, particularly using Firecracker VMs\n Understanding of system architecture, security, and scalability principles\n Hands-on experience in building automation tools or similar real-world systems\n Self-starter mindset with the ability to build, iterate, and ship products quickly\n Product thinking and problem-solving skills to evaluate and improve system performance\n No formal degree required: We value practical skills and measurable results over academic credentials\nPreferred Skills\nKnowledge of Kubernetes or Nomad for horizontal scaling\nExperience with GUI automation tools and technologies like xdot\nFamiliarity with Jupyter environments and display server configurations\nPrevious experience with developing API endpoints for task orchestration\nExperience\nWhile specific years of experience are not mandated, candidates should have a track record of building and shipping real-world systems and demonstrate the capability to work effectively in a startup environment\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Weekday AI (YC W21)", "position": "Founding Engineer", "location": "India"}, "data-engineer-web-scraping-at-alternative-path-4268965583.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-engineer-web-scraping-at-alternative-path-4268965583.html", "link": "https://in.linkedin.com/jobs/view/data-engineer-web-scraping-at-alternative-path-4268965583?position=53&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=hfa%2B7tXDt3pX%2BrOjLTqcJQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAlternative Path is seeking skilled software developers to collaborate on client projects with an asset management firm. In this role, you will collaborate with individuals across various company departments to shape and innovate new products and features for our platform, enhancing existing ones. You will have a large degree of independence and trust, but you won't be isolated; the support of the Engineering team leads, the Product team leads, and every other technology team member is behind you. This is an opportunity to join a team-first meritocracy and help grow an entrepreneurial group inside Alternative Path. You will be asked to contribute, given ownership, and will be expected to make your voice heard.\nRole Summary:\nPerforming Web Scraping using various scraping techniques and then utilizing Python\u2019s Pandas library for data cleaning and manipulation. Then ingesting the data into a Database/Warehouse, and scheduling the scrapers using Airflow or other tools\nRole Overview\nThe Web Scraping Team at Alternative Path is seeking a creative and detail-oriented developer to contribute to client projects. The team develops essential applications, datasets, and alerts for various teams within the client's organization, supporting their daily investment decisions. The mission is to maintain operational excellence by delivering high-quality proprietary datasets, timely notifications, and exceptional service. We are seeking someone who is self-motivated, self-sufficient, with a passion for tinkering and a love for automation.\nIn your role, you will:\n\u27a2 Collaborate with analysts to understand and anticipate requirements.\n\u27a2 Design, implement, and maintain Web scrapers for a wide variety of alternative datasets.\n\u27a2 Perform Data Cleaning, Exploration, Transformation etc. of scraped data.\n\u27a2 Collaborate with cross-functional teams to understand data requirements and implement efficient data processing workflows.\n\u27a2 Author QC checks to validate data availability and integrity.\n\u27a2 Maintain alerting systems and investigate time-sensitive data incidents to ensure smooth day-to-day operations.\n\u27a2 Design and implement products and tools to enhance the Web scraping Platform.\nQualifications\nMust have\n\u27a2 Bachelor's/master\u2019s degree in computer science or in any related field\n\u27a2 2-4 years of software development experience\n\u27a2 Strong Python and SQL/Database skills\n\u27a2 Strong expertise in using the Pandas library (Python) is a must\n\u27a2 Experience with web technologies (HTML/JS, APIs, etc.)\n\u27a2 Proven work experience in working with large data sets for Data cleaning, Data transformation, Data manipulation, and Data replacements.\n\u27a2 Excellent verbal and written communication skills\n\u27a2 Aptitude for designing infrastructure, data products, and tools for Data Scientists\nPreferred\n\u27a2 Familiarity with scraping and common scraping tools (Selenium, scrapy, Fiddler, Postman, xpath) \u27a2 Experience containerizing workloads with Docker (Kubernetes a plus)\n\u27a2 Experience with build automation (Jenkins, Gitlab CI/CD) \u27a2 Experience with AWS technologies like S3, RDS, SNS, SQS, Lambda, etc.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Alternative Path", "position": "Data Engineer - Web Scraping", "location": "India"}, "react-native-developer-at-vayuz-technologies-4148628204.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\react-native-developer-at-vayuz-technologies-4148628204.html", "link": "https://in.linkedin.com/jobs/view/react-native-developer-at-vayuz-technologies-4148628204?position=54&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=vJA0aGAO8uzxy2SrDhQnPw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nResponsibilities Include\n Designing, developing & deploying the product\n Work as part of a team to build React Native iOS / Android applications\n Architect, build and maintain excellent React Native applications with clean code\n Translating wireframes and PSD designs into functional responsive apps, Implement pixel perfect UI's that match designs\n Binding UI elements to JavaScript object models, work with native modules when required\n Creating RESTful services with Node.js\n Developing scalable web architectures\n Working in a cross-functional team to deliver a complete user experience\n Creating unit and integration tests to ensure the quality of code\n Being responsive to change requests and feature requests\n Writing code that is cross-platform and cross-device compatible\n Co-ordinating end-to-end implementation\n Release applications to iOS and Google Play stores\nSkills:- React Native and NodeJS (Node.js)\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "VAYUZ Technologies", "position": "React Native Developer", "location": "Noida, Uttar Pradesh, India"}, "software-engineer-at-schedley-com-4271146349.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-at-schedley-com-4271146349.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-at-schedley-com-4271146349?position=55&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=6CEHjcr5L5hUVIuLBC6htA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nThe ideal candidate will be responsible for developing high-quality applications. They will also be responsible for designing and implementing testable and scalable code. \n \nResponsibilities\nDevelop quality software and web applications\nAnalyze and maintain existing software applications\nDesign highly scalable, testable code\nDiscover and fix programming bugs\nQualifications\nBachelor's degree or equivalent experience in Computer Science or related field\nDevelopment experience with programming languages\nSQL database or relational database skills\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Schedley.com", "position": "Software Engineer", "location": "India"}, "junior-full-stack-engineer-at-dexian-india-4277198569.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\junior-full-stack-engineer-at-dexian-india-4277198569.html", "link": "https://in.linkedin.com/jobs/view/junior-full-stack-engineer-at-dexian-india-4277198569?position=56&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=saFwFnAomFg5OWWHQvZV7g%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWe are looking for Java Full stack engineer with 3-4 years of experience.\nMandatory skills: Java, Angular, Spring boot, Microservice, GCP PostgreSQL, CICD pipeline\nNice to have: AI Experience.\nKindly share your resume to prakash.manivannan@dexian.com with below details and mention relevant experience with required skill set \nCTC:\nExpected CTC: \nServing notice: Y/N\nLast Working Day Notice:\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Dexian India", "position": "Junior Full Stack Engineer", "location": "India"}, "simulation-triage-engineer-at-imerit-technology-4267949310.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\simulation-triage-engineer-at-imerit-technology-4267949310.html", "link": "https://in.linkedin.com/jobs/view/simulation-triage-engineer-at-imerit-technology-4267949310?position=57&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=lQWHXPlncqq8Ny3cNSAm8A%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nPosition: \n & Simulation Tirage Engineer\nWork Location: \nWork from Office / Remote\nType:\n Full-time\nShift:\n Flexible to work in shifts, including night shifts on client request\nCommunication Skills Requirement: \nMinimum CEFR B2 level of English\nTechnical Skills Requirement: \nLiDAR L3\nAbout the Role (Position Summary)\nThis role requires a strong combination of technical expertise in AV sensor data (especially LiDAR and camera), meticulous attention to annotation quality, and hands-on experience in simulation data triage. The ideal candidate will work on identifying errors, inconsistencies, and gaps in annotated datasets and simulation scenes, supporting the retraining and validation cycles of autonomous vehicle (AV) systems.\nEducation Qualifications\nBachelor's degree in Engineering, Computer Applications, Data Science, or related technical discipline.\nExperience\n3\u20137 years of experience in annotation, simulation validation, or auditing roles with increasing leadership responsibility. \nStrong background in LiDAR and sensor data (2D/3D bounding boxes, polygons, cuboids, segmentation).\nExperience in simulation scenario review and tirage pipelines (e.g., triaging data for model retraining).\nPrior exposure to client interaction and cross-functional coordination (e.g., with engineering and QA teams).\nHands-on experience working in tool-based labeling pipelines and simulation-driven testing environments.\nExperience working with annotation tools and QA checklists based on project-specific SOPs.\nCapacity of data analysis towards identifying consistent gaps\nDesired Qualifications and Experience\n(if any)\nAuditor-Specific Soft Skills\nExceptional attention to detail:\n Ability to notice minute annotation errors, shape irregularities, and alignment mismatches.\nStrong visual-spatial reasoning:\n Capability to interpret 3D point clouds and assess object depth, perspective, occlusion, and context.\nCritical thinking:\n Skill in evaluating edge cases and understanding when annotations fail to represent real-world driving scenarios accurately. Strong ability of pattern recognition\nAnnotation guideline interpretation:\n Ability to deeply understand, question, and apply detailed project-specific SOPs and edge-case rules.\nBias awareness:\n Understand and flag biases in annotation or scene interpretation (e.g., object labeling errors due to weather, occlusion, or human assumptions).\nClear written communication:\n Document audit findings, feedback, and edge cases in structured and unambiguous formats.\nConsistency under repetition:\n Maintain high focus and precision while reviewing large datasets with repetitive structures.\nCuriosity and domain awareness:\n Stay engaged with AV trends, annotation standards (e.g., KITTI, nuScenes), and common model failure patterns.\nCollaboration mindset:\n Willingness to work closely with fellow auditors, QA teams, and simulation engineers to improve annotation and tirage workflows.\nTechnical Skill Requirements\nAnnotation Auditing & Data QA\nAnnotate and/or Audit 2D/3D sensor data annotations to ensure they meet the project\u2019s accuracy, completeness, and consistency requirements.\nIdentify common error types and provide actionable feedback.\nSimulation Tirage\nEvaluate simulation data for complexity, relevance, and anomalies.\nTag and classify scenes based on criticality for model training or validation pipelines.\nClear understanding of road sign and rules from a driver's perspective with capacity of (given) situation analysis\nRules of the Road Expertise: Familiarity with standard traffic behavior, signage, signaling, right-of-way principles, and vehicle interactions under typical U.S. driving conditions.\nMUTCD Knowledge: Working knowledge of the Manual on Uniform Traffic Control Devices (MUTCD), especially as it applies to lane markings, signage, and signal interpretation across varied roadway types.\nPassenger Comfort Sensitivity: Ability to assess scenarios from the perspective of a rider, identifying discomfort or unsafe behaviors that may not violate technical rules but still degrade the end-user experience.\nDriver Duty of Care Perspective: Ability to evaluate edge cases and ambiguous situations through the lens of a responsible human driver, balancing legality with caution and accountability in mixed-traffic environments.\nTool & Workflow Expertise\nOperate advanced tools such as Labelbox, Scale AI, Supervisely, CVAT, CARLA, or in-house labeling systems.\nSuggest refinements in annotation and tirage flows to reduce ambiguity and improve cycle efficiency.\nDocumentation & Reporting\nMaintain issue logs and generate structured audit reports.\nProvide detailed scene-level comments to support iterative data improvements.\nResponsibilities (not limited to)\nConduct systematic reviews of AV sensor annotations using defined QA guidelines.\nPerform simulation scene triage to identify edge-case scenarios and misclassified outcomes.\nTag errors, provide audit-level feedback, and ensure data is looped back for correction or retraining.\nCollaborate with QA reviewers, annotation operators, and simulation engineers.\nContribute to refinement of SOPs and visual reference materials based on audit insights.\nStay current with industry annotation standards and simulation evaluation protocols.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "iMerit Technology", "position": "Simulation Triage Engineer", "location": "India"}, "software-engineering-specialist-human-data-at-xai-4262541457.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineering-specialist-human-data-at-xai-4262541457.html", "link": "https://in.linkedin.com/jobs/view/software-engineering-specialist-human-data-at-xai-4262541457?position=58&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=MWnj0UetFlD2AZcGTZ4XUA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout xAI\nxAI's mission is to create AI systems that can accurately understand the universe and aid humanity in its pursuit of knowledge.\nOur team is small, highly motivated, and focused on engineering excellence. This organization is for individuals who appreciate challenging themselves and thrive on curiosity.\nWe operate with a flat organizational structure. All employees are expected to be hands-on and to contribute directly to the company's mission. Leadership is given to those who show initiative and consistently deliver excellence. Work ethic and strong prioritization skills are important.\nAll engineers and researchers are expected to have strong communication skills. They should be able to concisely and accurately share knowledge with their teammates.\nAbout the Role\nAs a Software Engineering Specialist on the Human Data team, you will be responsible for creating cutting-edge data to facilitate the training of large language models. Collaborating closely with technical staff, you will contribute to datasets for model training, benchmarking, and overall advancement.\nThe Software Engineering Specialist - Human Data\n role is a full-time remote position. Part-time may be offered on a case-by-case basis but full-time is strongly preferred (please see the bottom of this job description for more details).\nResponsibilities\nAI model training initiatives by curating code examples, offering precise solutions, and meticulous corrections in Python, JavaScript (including ReactJS), C/C++, and Java.\nEvaluate and refine AI-generated code, ensuring it adheres to industry standards for efficiency, scalability, and reliability.\nCollaborate with cross-functional teams to enhance AI-driven coding solutions, ensuring they meet enterprise-level quality and performance benchmarks.\nKey Qualifications\nAdvanced proficiency in English, both verbal and written.\nStrong experience in either Python or JavaScript, with a solid foundation in software development practices. Please note that for those with experience in only JavaScript, experience with ReactJS is preferred but not required. Knowledge of other languages is a strong plus.Strong grasp of computer science fundamentals like data structures, algorithms, and debugging skills.\nA minimum of 2 years of hands-on industry experience with a proven track record in software development and/or public proof of work (such as on GitHub).\nExtensive experience with a wide array of tools and systems such as Databases, SQL, Kubernetes, Spark, Kafka, gRPC, and AWS.\nPreferred Qualifications\nThe ideal candidate for this role is adaptable, possesses strong logical reasoning skills, is detail-oriented, and thrives in a fast-paced work environment.\nEvidence of meaningful contributions to open source projects or high reputation on platforms like Stack Overflow or evidence of strong performance in programming competitions.\nEnthusiasm to collaboratively build the best truth-seeking AI out there!\nAdditional Requirements\nDemonstrates a strong capacity to quickly adapt by learning new skills and unlearning outdated ones, thriving in dynamic and changing environments.\nFor those who will be working from a personal device, please note your computer must be capable of running Windows 10 or macOS BigSur 11.0 or later.\nLocation, Hourly, and Other Expectations\n \nThis position is fully remote.\nWe are unable to provide visa sponsorship.\nIf you are based in the US, please note we are unable to hire in the states of Wyoming and Illinois at this time.\nYou must own and have reliable access to a smartphone.\nPlease indicate your interest in either full-time, part-time, or either in the application. Note that:\nFull-Time (40 hours per week): Full-time schedules are 9-5:30pm in your local time zone. The first week will be 9-5:30pm PST for onboarding.\nPart-Time (20-29 hours per week): While hours are flexible around your schedule, you must be committed to working at least 20 hours per week (with at least 10 of these hours worked on weekdays) and no more than 29 hours per week.\nCompensation and Benefits\nThe pay for this role may range from $55/hour - $65/hour. \nYour actual pay will be determined on a case-by-case basis and may vary based on the following considerations: job-related knowledge and skills, education, and experience.\nFor full-time roles, specific benefits vary by country, depending on your country of residence you may have access to medical benefits. We do not offer benefits for part-time roles.\nxAI is an equal opportunity employer and does not unlawfully discriminate based on race, color, religion, ethnicity, ancestry, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, age, disability, medical conditions, genetic information, marital status, military or veteran status, or any other applicable legally protected characteristics. \nQualified applicants with arrest or conviction records will be considered for employment in accordance with all applicable federal, state, and local laws, including the San Francisco Fair Chance Ordinance, Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. \nFor Los Angeles County (unincorporated) Candidates:\nxAI reasonably believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: \nAccess to information technology systems and confidential information, including proprietary and trade secret information, and/or user data;\nInteracting with internal and/or external clients and colleagues; and\nExercising sound judgment.\nCalifornia Consumer Privacy Act (CCPA) Notice\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "xAI", "position": "Software Engineering Specialist - Human Data", "location": "Telangana, India"}, "software-engineer-backend-development-at-smallcase-4267667521.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-backend-development-at-smallcase-4267667521.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-backend-development-at-smallcase-4267667521?position=59&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=L7Db8N%2F7dAXah%2BryslV%2BAw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout The Role\nYou\u2019ll work with world-class engineers, designers, and finance experts to create intuitive and scalable investment platforms. As a Software Development Engineer, you\u2019ll contribute to high-impact projects, write clean and efficient code, and learn what it takes to deliver a delightful investing experience to millions.\nWhat You\u2019ll Do\nDesign and develop databases for real-time, high availability financial data \nWill be working with MongoDB, Redis, Javascript, Node.js \nArchitect and build the backend for corresponding web service (Nodejs and related frameworks) \nCreate microservices and tools, manage servers (AWS), create reports etc. \nWe\u2019re Looking for\nMust to have 1 -3 years of Software Development experience \nStrong systems, architecture and database fundamentals \nPrior experience with Javascript (Node.js), MongoDB \nWeb development concepts - basics of REST APIs, server architecture \nInterest in building things from scratch and be a decision maker here \nEligibility\nLooking for hands-on backend experience in a real product environment \nAbout Smallcase\nAt smallcase, we are changing how India invests. smallcase is a leading provider of investment products & platforms to over 10 million Indians. We're a young, driven team of 250+ headquartered in Bangalore. smallcase was founded in July 2015 by three IIT Kharagpur graduates, Vasanth Kamath, Anugrah Shrivastava and Rohan Gupta.\nsmallcase has been focused on offering innovative investing experiences & technology. Our platforms are used by over 300 of India's largest financial brands and most respected institutions. We are backed by world-class investors including top-tier funds, institutions and operators from the capital markets space who believe in our mission of enabling better financial futures for every Indian.\nLife at smallcase\nWe are not just building a business, we are making a long-lasting impact both in the wealth & assets landscape with our unique technology & expanding ecosystem. Over the last 9 years, our team, products, and platforms have grown and so have our ambitions.\nInnovation remains at the heart of what we do. Our other core values are transparency, integrity & long-term thinking. Our key asset has always been our people, and we empower individuals to build and do some of the best work in their lifetimes at smallcase. Flexibility, ownership and constant feedback loops are some of the ways we keep evolving the working environment.\nSkills: node.js,redis,mongodb,architecture,building,software,rest apis,restapi,software development,aws,javascript,microservices\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "smallcase", "position": "Software Engineer - Backend Development", "location": "India"}, "reactjs-developer-at-kopykitab-digibook-technologies-pvt-ltd-4257190810.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\reactjs-developer-at-kopykitab-digibook-technologies-pvt-ltd-4257190810.html", "link": "https://in.linkedin.com/jobs/view/reactjs-developer-at-kopykitab-digibook-technologies-pvt-ltd-4257190810?position=60&pageNum=0&refId=EEtkE6R2TDPKmdLFIty1qA%3D%3D&trackingId=%2Bim9h9LGZupRqJeYk78vzg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nReact.js Developer Responsibilities\n \nMeeting with the development team to discuss user interface ideas and applications.\nReviewing application requirements and interface designs.\nIdentifying web-based user interactions.\nDeveloping and implementing highly responsive user interface components using react concepts.\nWriting application interface codes using JavaScript following react.js workflows.\nTroubleshooting interface software and debugging application codes.\nDeveloping and implementing front-end architecture to support user interface concepts.\nMonitoring and improving front-end performance.\nDocumenting application changes and developing updates.\neact.js Developer Requirements:\nBachelor\u2019s degree in computer science, information technology, or a similar field.\nPrevious experience working as a react.js developer.\nIn-depth knowledge of JavaScript, CSS, HTML, and front-end languages.\nKnowledge of REACT tools including React.js, Webpack, Enzyme, Redux, and Flux.\nExperience with user interface design.\nKnowledge of performance testing frameworks including Mocha and Jest.\nExperience with browser-based debugging and performance testing software.\nExcellent troubleshooting skills.\nGood project management skills.\n Skills:- Javascript and Redux/Flux\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "company": "Kopykitab - Digibook Technologies Pvt. Ltd", "position": "Reactjs Developer", "location": "India"}}
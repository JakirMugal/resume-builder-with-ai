{"data-scientist-across-pan-india-at-capgemini-engineering-4228162369.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-across-pan-india-at-capgemini-engineering-4228162369.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-across-pan-india-at-capgemini-engineering-4228162369?position=1&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=Le8VvTQTbGGY6y2rf%2F0Y1g%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nPosition Title: Data Scientist\nCompany Overview: Capgemini Engineering is a global leader in engineering services, bringing together a worldwide team of engineers, scientists, and architects to assist the most innovative companies in unleashing their potential.\nPosition Overview: We are seeking a skilled Data Scientist with expertise in Cognite Data Fusion, data modelling, Unified Namespace (UNS), ontologies, and the identification of data products and datasets. The ideal candidate will have a strong background in developing and implementing data science projects, analyzing large and complex data sets, and driving data-driven decision-making across the organization\nKey Responsibilities:\nSolution Development: Design, implement, and deploy scalable data solutions utilizing Cognite Data Fusion, focusing on data modeling, UNS, and ontologies to address industry-specific challenges.\u200b\nData Analysis: Analyze large and complex data sets to identify trends, insights, and opportunities, supporting solution development and business strategies.\u200b\nCollaboration: Collaborate with cross-functional teams to understand data needs and translate them into data science solutions, ensuring seamless integration and operationalization of digital solutions across various domains.\nClient Engagement: Engage with clients to understand their business objectives, lead discovery workshops, and provide expert guidance on data-driven strategies and potential challenges.\u200b\nVisualization: Develop dashboards and visualizations using tools such as Power BI, Grafana, or web development frameworks like Plotly Dash and Streamlit to effectively communicate data insights.\u200b\nMentorship: Provide guidance and mentorship to junior team members, promoting best practices in data science and software development.\u200b\nQualifications:\nEducational Background: Master\u2019s or PhD degree in a quantitative field.\u200b\nExperience: Minimum of 2 years of experience in data science, with a strong background in developing analytical solutions within domains such as pharma, oil and gas, manufacturing, or power & utilities.\u200b\nTechnical Skills: Proficiency in Python and its data ecosystem (pandas, numpy), machine learning libraries (scikit-learn, keras), and experience with SQL.\u200b\nVisualization Tools: Experience with data visualization tools like Power BI, Grafana, Tableau, or web development frameworks such as Plotly Dash and Streamlit.\u200b\nSoftware Practices: Strong understanding of software development practices, including version control (e.g., Git), automated testing, and documentation.\u200b\nCloud Platforms: Experience with cloud services such as GCP, Azure, or AWS is advantageous.\u200b\nDomain Knowledge: Familiarity with industrial data management concepts, including Unified Namespace (UNS), ontologies, and data product identification.\u200b\nCommunication Skills: Excellent communication and collaboration skills, with the ability to work with cross-functional teams and stakeholders.\u200b\nLeadership: Demonstrated ability to lead projects and mentor junior team members.\u200b\nPreferred Qualifications:\nIndustry Expertise: Experience serving as a domain expert on internal or customer projects within relevant industries.\u200b\nCloud Deployment: Experience deploying models and solutions in production environments using cloud infrastructure.\u200b\nContinuous Learning: Willingness to stay updated with the latest developments in data science and related technologies.\u200b\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education**: Master's or PhD degree in a quantitative field.\n* **Experience**: \n  * Minimum 2 years of experience in data science.\n  * Background in developing analytical solutions within domains such as pharma, oil and gas, manufacturing, or power & utilities.\n  * Experience serving as a domain expert on internal or customer projects within relevant industries (preferred).\n* **Technical Skills**: \n  * Proficiency in Python and its data ecosystem (pandas, numpy).\n  * Machine learning libraries (scikit-learn, keras).\n  * Experience with SQL.\n  * Experience with data visualization tools like Power BI, Grafana, Tableau, or web development frameworks such as Plotly Dash and Streamlit.\n* **Software Practices**: \n  * Strong understanding of software development practices.\n  * Experience with version control (e.g., Git).\n  * Automated testing and documentation.\n* **Domain Knowledge**: \n  * Familiarity with industrial data management concepts.\n  * Understanding of Unified Namespace (UNS), ontologies, and data product identification.\n* **Cloud**: \n  * Experience with cloud services such as GCP, Azure, or AWS (advantageous).\n  * Experience deploying models and solutions in production environments using cloud infrastructure (preferred).\n* **Soft Skills**: \n  * Excellent communication and collaboration skills.\n  * Ability to work with cross-functional teams and stakeholders.\n  * Demonstrated ability to lead projects and mentor junior team members.\n  * Willingness to stay updated with the latest developments in data science and related technologies.", "company": "Capgemini Engineering", "position": "Data Scientist- Across PAN India", "location": "Bengaluru, Karnataka, India"}, "data-scientist-at-valiance-solutions-4075570637.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-at-valiance-solutions-4075570637.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-at-valiance-solutions-4075570637?position=2&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=NtbZn8Rwu8%2FW0ZqWtZZ3cw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout Us:\nAt Valiance, we empower businesses with AI-driven insights and data analytics solutions. Specializing in demand forecasting within retail Industry very specific to \nApparel and Footwear \n domains, we leverage standardized ML models to deliver accurate forecasting outcomes to our clients. We are looking for a skilled Data Scientist who can interpret and improve these models to drive real-world business results.\nRole Overview:\nThe Data Scientist will be responsible for applying our pre-trained demand forecasting models to generate actionable insights and highly accurate forecasting outcomes. This role involves thorough data analysis, identifying trends and anomalies, interpreting results, and communicating findings effectively to a non-technical business audience. The ideal candidate is less focused on creating algorithms and more oriented towards solving business challenges and providing insights that make a tangible impact.\nKey Responsibilities:\nData Analysis:\n Conduct in-depth data analysis to identify trends, patterns, and anomalies in demand/Timeseries forecasting for Retail Industry very specific to Apparel and Footwear (must have)\nModel Utilization:\n Leverage existing pre-trained forecasting models, optimizing their performance by incorporating a nuanced understanding of data points and improving model outcomes based on data insights.\nInterpretation & Communication:\n Interpret model results and explain outcomes in simple, actionable terms for business stakeholders, ensuring clarity and relevance.\nInsights Generation:\n Develop insights that guide business decisions, aiming for highly accurate forecasting outcomes to meet business requirements.\nCollaboration:\n Work closely with cross-functional teams, including business stakeholders and analysts, to ensure forecasting outputs align with business objectives and provide real-world value.\nContinuous Improvement:\n Identify opportunities to improve model performance through better data usage and fine-tuning, rather than new model development.\nRequired Skills & Qualifications:\nExperience:\n \n3-6 years of experience\n in data science or a related field, specifically in \nDemand/Timeseries forecasting for Retail Industry very specific to Apparel and Footwear (must have)\nTechnical Proficiency:\n Strong skills in data analysis, data visualization, and working with pre-trained ML models. Proficiency in Python, and SQL is preferred.\nBusiness Focus:\n Strong orientation towards solving business problems rather than a pure focus on machine learning algorithms.\nCommunication Skills:\n Ability to clearly communicate insights and forecast results to non-technical stakeholders in simple, understandable language.\nProblem Solving:\n Demonstrated ability to interpret data, uncover actionable insights, and suggest practical solutions for business needs.\nDetail-Oriented:\n Thorough attention to detail, ensuring accuracy in forecasting and relevance of insights.\nEducational Background:\n Bachelor\u2019s or Master\u2019s degree in Data Science, Statistics, Computer Science, or a related field.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Eligible Candidates:**\n  * Experience: 3-6 years in data science or a related field, specifically in demand/time series forecasting for the retail industry, particularly in Apparel and Footwear.\n  * Education: Bachelor\u2019s or Master\u2019s degree in Data Science, Statistics, Computer Science, or a related field.\n  * Technical Skills:\n    * Strong data analysis and data visualization skills.\n    * Experience working with pre-trained ML models.\n    * Proficiency in Python and SQL (preferred).\n  * Business Focus: Oriented towards solving business problems rather than pure machine learning algorithm development.\n  * Communication: Ability to clearly explain insights and forecast results to non-technical stakeholders in simple terms.\n  * Problem-Solving: Demonstrated ability to interpret data, uncover actionable insights, and suggest practical solutions.\n  * Attention to Detail: Thorough attention to detail to ensure accuracy in forecasting and relevance of insights.", "company": "Valiance Solutions", "position": "Data Scientist", "location": "Bengaluru, Karnataka, India"}, "data-scientist-at-dexian-india-4264355859.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-at-dexian-india-4264355859.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-at-dexian-india-4264355859?position=3&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=emMCTDfAcn%2FzwK%2FlyYdyIQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWe are seeking a Data Scientist with strong experience in \ndeveloping and implementing RAG (Retrieval-Augmented Generation) ontology\n, specifically in \nAzure environments\n.\n\ud83d\udccc Key Responsibilities:\nDesign, develop, and implement RAG-based ontology inside Azure.\nReconcile and map policies, laws, and regulations using advanced tech frameworks.\nCollaborate with local junior developers (from academic institutions).\nDeliver full-time contributions aligned with \nUS working hours (first half)\n.\nOperate in an \nagile\n, fast-moving, and innovation-focused environment.\n\ud83c\udfaf Must-Haves:\nStrong technical expertise\n in RAG architecture and Azure.\nAbility to \nprovide domain-specific answers and guidance (e.g., in healthcare policy)\n without relying on AI assistance.\nComfortable taking \nrisks and iterating quickly (\"fail forward\")\n in a startup-like, agile setting.\nA \nself-starter\n who thrives with minimal supervision and drives results independently.\nClear communicator, with a focus on collaboration and problem-solving.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required:**\n  * Strong technical expertise in RAG (Retrieval-Augmented Generation) architecture\n  * Experience with Azure environment\n  * Ability to provide domain-specific answers and guidance (e.g., in healthcare policy) without AI assistance\n  * Comfortable with risk-taking and rapid iteration in an agile setting\n  * Self-motivated and able to work independently with minimal supervision\n  * Clear communication and collaboration skills\n* **Preferred/Implied:**\n  * Experience working in a startup-like, agile environment\n  * Familiarity with advanced tech frameworks for reconciling and mapping policies, laws, and regulations\n  * Experience collaborating with junior developers or academic institutions \n  * Ability to work in US working hours (first half)", "company": "Dexian India", "position": "Data Scientist", "location": "India"}, "data-scientist-risk-strategy-sme-at-blucognition-4172315084.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-risk-strategy-sme-at-blucognition-4172315084.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-risk-strategy-sme-at-blucognition-4172315084?position=4&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=Ib8x%2BW5deaaBobPBCzX9xA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout bluCognition: \nbluCognition is an AI/ML based start-up specializing in risk analytics, data conversion and data enrichment capabilities. Founded in 2017, by some very named senior professionals from the financial services industry, the company is headquartered in the US, with the delivery center based in Pune. We build all our solutions while leveraging the latest technology stack in AI, ML and NLP combined with decades of experience in risk management at some of the largest financial services firms in the world.\nOur clients are some of the biggest and the most progressive names in the financial services industry. We are entering a significant growth phase and are looking for individuals with entrepreneurial mindset who wants us to join us in this exciting journey.\nPosition: Data Scientist (Risk strategy, SME)\nAbout the role\nAs Data Scientist in the credit risk strategy team, you will leverage your creative and critical thinking skills to develop best-in-class risk management strategies that have a meaningful impact on the client\u2019s business. These strategies will support the client\u2019s credit and fraud risk, customer experience, marketing verticals and beyond.\nHaving you aboard will enable us to stay aligned with market trends by improving the turnaround time for developing and implementing risk strategies, allowing for quicker iterations and broader coverage in addressing business challenges through scientific methods. The core KPIs for this position include additional revenue generated and costs saved from releases. This role also supports compliance, documentation, and knowledge sharing in risk strategies.\nWhat you'll do\nDevelop, validate and deploy risk management strategies using a combination of sophisticated data analytics and domain expertise\nExtract and explore data, validate data integrity, perform ad hoc analysis, evaluate new data sources for usage in strategy development\nMaintain robust documentation of approach and techniques used; including objectives, assumptions, performance, weaknesses, and limitations\nBe ready to adapt to new tools/libraries/technologies/platforms\nActively partner with engineers to validate & deploy scalable solutions\nCollaborate to gather insight from partners across the organization\nFurther develop expertise in data science and engineering through self-study, project exposure and guidance of senior team members\nWhat you'll bring\nDegree in a quantitative field (e.g., computer science, data science, engineering, economics, mathematics, etc.). Advanced degree preferred\n3+ years of Data Science experience\n2+ years in financial services\nExperience building and implementing risk strategies in production\nDeep understanding of segmentation techniques such as decision trees\nExperience in banking sector with exposure to risk management analytics\nProficient with Python\nProficient with SQL\nPractical experience using Spark is a plus\nUnderstanding of statistical modeling techniques is a plus\nTechnical understanding of algorithm complexity, probability & statistics\nSelf-driven with an aptitude for independent research & problem-solving\nAbility to multi-task in a fast-paced environment is essential\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:**\n\t+ Degree in a quantitative field (e.g., computer science, data science, engineering, economics, mathematics)\n\t+ Advanced degree preferred\n* **Experience:**\n\t+ 3+ years of Data Science experience\n\t+ 2+ years in financial services\n\t+ Experience building and implementing risk strategies in production\n\t+ Experience in the banking sector with exposure to risk management analytics\n* **Skills:**\n\t+ Proficient with Python\n\t+ Proficient with SQL\n\t+ Practical experience using Spark (plus)\n\t+ Understanding of statistical modeling techniques (plus)\n\t+ Technical understanding of algorithm complexity, probability & statistics\n* **Personal Qualities:**\n\t+ Self-driven with an aptitude for independent research & problem-solving\n\t+ Ability to multi-task in a fast-paced environment\n* **Domain Knowledge:**\n\t+ Deep understanding of segmentation techniques such as decision trees\n\t+ Familiarity with risk management analytics in the financial services industry", "company": "bluCognition", "position": "Data Scientist (Risk strategy, SME)", "location": "India"}, "data-scientist-at-recro-4271310370.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-at-recro-4271310370.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-at-recro-4271310370?position=5&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=6U4R7RtSUjWEsa8qP14bjA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJob Title: Machine Learning Engineer / Data Scientist\nJob Summary:\nWe are looking for a skilled Machine Learning Engineer / Data Scientist to design and deploy end-to-end ML solutions. The ideal candidate will have a strong foundation in statistics, machine learning, Python programming, and experience working with large datasets in real-world production environments.\nKey Responsibilities:\nTranslate business problems into data science solutions.\nBuild and deploy complete ML pipelines: data ingestion, preprocessing, modeling, evaluation, and monitoring.\nApply statistical methods and core ML algorithms (regression, classification, clustering).\nWork with neural networks, including CNNs, RNNs, transformers.\nHandle large datasets using Python (NumPy, Pandas, Scikit-learn) and SQL.\nOptimize and tune models; implement clean, efficient, and scalable code.\nCollaborate with cross-functional teams and communicate findings effectively.\nRequirements:\nProficient in Python and object-oriented programming.\nStrong knowledge of statistics, ML fundamentals, and model evaluation.\nExperience with model deployment (REST APIs, batch inference) and monitoring.\nFamiliarity with data structures, algorithm design, and large-scale data processing.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education**: Not explicitly stated\n* **Technical Skills**:\n\t+ Proficient in Python and object-oriented programming\n\t+ Familiarity with:\n\t\t- NumPy\n\t\t- Pandas\n\t\t- Scikit-learn\n\t\t- SQL\n\t+ Experience with:\n\t\t- Neural networks (CNNs, RNNs, transformers)\n\t\t- Core ML algorithms (regression, classification, clustering)\n\t\t- Model deployment (REST APIs, batch inference) and monitoring\n* **Experience**:\n\t+ Experience working with large datasets in real-world production environments\n\t+ Experience with model deployment and monitoring\n* **Knowledge**:\n\t+ Strong knowledge of statistics and ML fundamentals\n\t+ Strong foundation in machine learning\n\t+ Familiarity with data structures and algorithm design\n* **Soft Skills**:\n\t+ Ability to translate business problems into data science solutions\n\t+ Ability to collaborate with cross-functional teams and communicate findings effectively\n\t+ Ability to optimize and tune models, and implement clean, efficient, and scalable code", "company": "Recro", "position": "Data Scientist", "location": "India"}, "machine-learning-engineer-at-interview-kickstart-4267255580.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\machine-learning-engineer-at-interview-kickstart-4267255580.html", "link": "https://in.linkedin.com/jobs/view/machine-learning-engineer-at-interview-kickstart-4267255580?position=6&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=Bn%2FmPfENCNnNO9auWhECdQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWho We Are:\nInterviews can be hard, especially at top tech companies like Google, Facebook, and Netflix. Many candidates fall short simply because they aren't adequately prepared. That's where we come in. Our acclaimed courses specialize in interview preparation and transitioning into high-demand tech fields such as AI, ML, and Data Science. At Interview Kickstart, current and former hiring managers have guided over 17,000 tech professionals through transformative career journeys, ensuring their success in landing coveted positions. Think of us as \"the everything store\" for career transitions and interview skill development.\nHow Do We Do That, You Ask?\nWe have a structured approach to interview success, which includes:\nCareer Accelerator Course\nComprehensive end-to-end courses and platform\nA roster of over 600+ instructors from leading Silicon Valley companies like Google, Facebook, Amazon, and Netflix\nA holistic approach that includes live classes, mock interviews, personalized coaching, resume refinement, career strategies, and invaluable referrals\nWhat's more exciting is that we are completely remote and hiring the best people we can find regardless of geography.\nRole Overview:\nAs a Machine Learning Engineer at Interview Kickstart, you will play a crucial role in developing and deploying cutting-edge AI/ML solutions that enhance our platform and improve the learning experience for our students. You will work closely with data scientists, engineers, and product managers to build and scale robust and impactful machine learning models.\nWhat will excite us:\n3.5+ years of full-time experience as an ML engineer at tier-1 product-based companies\nHands-on experience fine-tuning open-source large language models (LLMs) and successfully deploying and maintaining them in scalable production environments on cloud platforms (e.g., AWS, Azure, GCP)\nHands-on experience building statistical and machine learning models\nProven expertise in traditional machine learning methods (e.g., regression, classification, clustering, tree-based models) and deep learning techniques (e.g., neural networks, CNNs, RNNs)\nProficiency in Python\nGood to have :\nExcellent communication skills, with the ability to present insights clearly to both technical and non-technical audiences\nA deep understanding of core concepts in statistics, probability, linear algebra, and calculus\nStrong quantitative abilities, typically supported by an advanced degree (masters or PhD) in fields like Machine Learning, Statistics, or Mathematics\nContributions to open-source ML projects\nWhat will you be doing? :\nCollaborate closely with stakeholders to understand business challenges deeply and translate these challenges into well-defined machine learning problems and actionable project requirements to drive business growth and enhance learner experiences\nLeverage your expertise in statistical modeling, machine learning, and generative AI/LLMs to research and design optimal solutions for the identified machine learning problems\nWork closely with fellow developers to build and iterate optimal solutions for the identified machine learning problems\nTake ownership of deploying the developed machine learning solutions, including fine-tuned LLMs, into scalable production environments (on cloud platforms like AWS, Azure, GCP) and ensure these deployed solutions are effective\nStaying informed about recent developments in AI/ML, including key publications, best practices, evaluation methodologies, technology stacks, and relevant tools\nWhat would excite you?\nComplete ownership\nExperiment, fail and learn\nHigh pedigree, high calibre team\nContribute to every area of our business. Have a real impact on your work\nTop-of-the-line compensation\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required:**\n  * 3.5+ years of full-time experience as an ML engineer at tier-1 product-based companies\n  * Hands-on experience fine-tuning open-source large language models (LLMs) and deploying/maintaining them in scalable production environments on cloud platforms (e.g., AWS, Azure, GCP)\n  * Hands-on experience building statistical and machine learning models\n  * Proven expertise in traditional machine learning methods (e.g., regression, classification, clustering, tree-based models) and deep learning techniques (e.g., neural networks, CNNs, RNNs)\n  * Proficiency in Python\n* **Preferred:**\n  * Excellent communication skills, with the ability to present insights clearly to both technical and non-technical audiences\n  * A deep understanding of core concepts in statistics, probability, linear algebra, and calculus\n  * Strong quantitative abilities, typically supported by an advanced degree (masters or PhD) in fields like Machine Learning, Statistics, or Mathematics\n  * Contributions to open-source ML projects", "company": "Interview Kickstart", "position": "Machine Learning Engineer", "location": "India"}, "research-scientist-%E2%80%93-ai-ml-at-ascendeum-4265400511.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\research-scientist-%E2%80%93-ai-ml-at-ascendeum-4265400511.html", "link": "https://in.linkedin.com/jobs/view/research-scientist-%E2%80%93-ai-ml-at-ascendeum-4265400511?position=7&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=M9o9MXobFHbcO5VdIr9B%2Bg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAscendeum is looking for mathematicians, with extensive hands-on experience in the field of data science, who can analyze large data sets efficiently to generate actionable business intelligence that drives peak performance for our clients.\nAbout Us:\nWe provide AdTech strategy consulting to leading internet websites and apps hosting over 200 million monthly audiences worldwide. Since 2015, our consultants and engineers have consistently delivered intelligent solutions that enable enterprise-level websites and apps to maximize their digital advertising returns.\nJob Responsibilities:\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data.\nAnalyze large amounts of information to discover trends and patterns\nHelping develop reports and analysis.\nPresent information using data visualisation techniques.\nAssessing tests, implementing new or upgraded software, and assisting with strategic decisions on new systems.\nEvaluating changes and updates to source production systems.\nDevelop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks.\nProviding technical expertise in data storage structures, data mining, and data cleansing.\nPropose solutions and strategies to business challenges\nDesired Skills and Experience:\nRelevant 2+ years of experience in Data Analysis\nComplete understanding of Operations Research, Data Modelling, ML, and AI concepts.\nKnowledge of Python is mandatory, familiarity with MySQL, SQL, Scala, Java or C++ is an asset\nExperience using visualization tools (e.g. Jupyter Notebook) and data frameworks (e.g. Hadoop)\nAnalytical mind and business acumen\nStrong math skills (e.g. statistics, algebra)\nProblem-solving aptitude\nExcellent communication and presentation skills.\nBachelor\u2019s / Master's Degree in Computer Science, Engineering, Data Science or other quantitative or relevant field is preferred\nThank you for your interest in joining Ascendeum.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** \n  * Bachelor's or Master's Degree in Computer Science, Engineering, Data Science, or a quantitative/relevant field\n* **Experience:** \n  * 2+ years of experience in Data Analysis\n  * Extensive hands-on experience in the field of data science\n* **Skills:**\n  * Python (mandatory)\n  * MySQL, SQL, Scala, Java, or C++ (asset)\n  * Data visualization tools (e.g., Jupyter Notebook)\n  * Data frameworks (e.g., Hadoop)\n  * Operations Research\n  * Data Modelling\n  * Machine Learning (ML)\n  * Artificial Intelligence (AI)\n  * Statistics\n  * Algebra\n* **Personal Qualities:**\n  * Analytical mind\n  * Business acumen\n  * Problem-solving aptitude\n  * Excellent communication and presentation skills", "company": "Ascendeum", "position": "Research Scientist \u2013 AI/ML", "location": "India"}, "data-scientist-people-analytics-at-motive-4257177833.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-people-analytics-at-motive-4257177833.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-people-analytics-at-motive-4257177833?position=8&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=PXocrCgONIbAeCzvc6nQUQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWho We Are\nMotive empowers the people who run physical operations with tools to make their work safer, more productive, and more profitable. For the first time ever, safety, operations and finance teams can manage their drivers, vehicles, equipment, and fleet related spend in a single system. Combined with industry leading AI, the Motive platform gives you complete visibility and control, and significantly reduces manual workloads by automating and simplifying tasks.\nMotive serves more than 100,000 customers \u2013 from Fortune 500 enterprises to small businesses \u2013 across a wide range of industries, including transportation and logistics, construction, energy, field service, manufacturing, agriculture, food and beverage, retail, and the public sector.\nVisit gomotive.com to learn more.\nAt Motive, our People Analytics team sits at the intersection of data science and talent strategy, transforming how we understand and enhance organizational performance. As a Data Scientist on our rapidly growing team, you'll leverage advanced analytics to tackle our most pressing talent challenges and drive measurable business impact.\nRole Description\nYou'll pioneer the application of data science to human capital, building sophisticated models and research that decode organizational behavior and shape Motive's talent strategy. Your work will span critical areas including:\nPredicting and enhancing talent acquisition, development, and retention\nQuantifying and elevating employee experience\nOptimizing team performance \nMaximizing productivity\nRethinking how we measure talent\nHuman capital problems require particular attention to sample size impacts, covariance, selection bias, modeling choices, and other issues that can be the difference between highly meaningful & impactful results, and noise. In this role, you will leverage structured problem solving approaches and data science skills to identify and deliver high impact solutions, as well as develop unique data science skills and human-capital expertise.\nThe Ideal Candidate Is\nPassionate about human capital: You are excited by the value we can add to our company and our employees, and are inspired to help make a large positive impact\nInnovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.\nCreative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You\u2019re not afraid to share a new idea.\nTechnical. You\u2019re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.\nStatistically-minded. You\u2019ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with network analysis, clustering, classification, time series, and sentiment analysis.\nRequired Qualifications\nBachelor's degree in Data Science, Statistics, Economics, or related quantitative field\nBackground in organizational psychology or behavioral economics\n3+ years of experience applying advanced analytics in people analytics, HR, or workforce planning\nExpert proficiency in Python or R, and SQL\nProven track record of building and deploying machine learning models\nExperience with statistical analysis, experimental design, and causal inference\nStrong project management skills with demonstrated ability to lead complex analytical initiatives\nExcellent communication skills - ability to translate complex analyses into actionable insights for diverse stakeholders\nPreferred Qualifications\nMaster\u2019s or PhD in a quantitative field or equivalent practical experience\nExperience with Organizational Network Analysis\nExperience in visualization tools (e.g., Tableau, PowerBI)\nExperience with natural language processing and unstructured data analysis\nTrack record of publishing or presenting analytical work\nFamiliarity with HR systems and people data structures\nCreating a diverse and inclusive workplace is one of Motive's core values. We are an equal opportunity employer and welcome people of different backgrounds, experiences, abilities and perspectives. \nPlease review our Candidate Privacy Notice here .\nUK Candidate Privacy Notice here.\nThe applicant must be authorized to receive and access those commodities and technologies controlled under U.S. Export Administration Regulations. It is Motive's policy to require that employees be authorized to receive access to Motive products and technology.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:**\n  * Bachelor's degree in Data Science, Statistics, Economics, or related quantitative field (required)\n  * Master's or PhD in a quantitative field or equivalent practical experience (preferred)\n* **Background:**\n  * Background in organizational psychology or behavioral economics (required)\n* **Experience:**\n  * 3+ years of experience applying advanced analytics in people analytics, HR, or workforce planning (required)\n  * Experience with:\n    * Organizational Network Analysis (preferred)\n    * HR systems and people data structures (preferred)\n    * Publishing or presenting analytical work (preferred)\n* **Skills:**\n  * Expert proficiency in:\n    * Python or R (required)\n    * SQL (required)\n  * Experience with:\n    * Machine learning model building and deployment (required)\n    * Statistical analysis, experimental design, and causal inference (required)\n    * Natural language processing and unstructured data analysis (preferred)\n    * Visualization tools (e.g., Tableau, PowerBI) (preferred)\n  * Strong project management skills (required)\n  * Excellent communication skills (required)\n* **Technical:**\n  * Comfortable with open-source languages (required)\n  * Hands-on experience developing data science solutions using open-source tools and cloud computing platforms (required)\n  * Statistically-minded with experience in:\n    * Network analysis\n    * Clustering\n    * Classification\n    * Time series\n    * Sentiment analysis (required)", "company": "Motive", "position": "Data Scientist, People Analytics", "location": "India"}, "ai-engineer-at-idea-elan-4259182911.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\ai-engineer-at-idea-elan-4259182911.html", "link": "https://in.linkedin.com/jobs/view/ai-engineer-at-idea-elan-4259182911?position=9&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=E7fGEN%2Fau7HRI3TBoifAuw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJob Description:\n We are seeking a skilled AI Engineer with 2-4 years of experience to design, develop, and deploy AI/ML solutions, with a strong emphasis on Generative AI, NLP, Retrieval-Augmented Generation (RAG), and Time Series Forecasting. The ideal candidate will have hands-on experience with LangGraph and other Generative AI frameworks to build cutting-edge AI applications.\nKey Responsibilities\nDevelop and deploy AI/ML models with a focus on NLP, Generative AI, RAG, and Time Series Forecasting workflows.\nEngineer and refine prompts to optimize performance for large language models (LLMs) and generative AI applications.\nImplement and maintain data preprocessing pipelines, including data cleansing, feature engineering, embedding generation, and transformation for time series data.\nDevelop end-to-end solutions integrating LLMs with VectorDB (e.g., Weaviate, Pinecone, FAISS) for document retrieval, semantic search, and contextual query answering.\nUtilize LangGraph and other Generative AI frameworks to build structured workflows for LLM-based applications.\nTrain and fine-tune machine learning models, including LLMs, to optimize performance for various use cases.\nAnalyze and interpret complex datasets, including time series data, ensuring scalable and efficient AI model deployment.\nCollaborate with cross-functional teams to integrate AI/ML models into existing systems and workflows.\nEnsure models are robust, scalable, and adhere to best practices in ethical AI development.\nConduct testing, performance benchmarking, and iterative refinements of AI models and pipelines.\nStay updated with the latest advancements in AI/ML, NLP, and cloud technologies and recommend integration strategies for emerging tools and techniques.\nCreate technical documentation and presentations to effectively communicate AI concepts to stakeholders.\nRequired Skills\nKey Skills and Qualifications:\nAI/ML Expertise: Proven experience in developing, fine-tuning, and deploying AI/ML models, focusing on NLP, Generative AI, and Time Series Forecasting.\nPrompt Engineering: Proficiency in designing, testing, and optimizing prompts for LLMs.\nData Analysis: Strong ability to process and interpret large and complex datasets, including time series data, for AI model training and validation.\nProgramming: Proficiency in Python and experience with AI/ML frameworks like TensorFlow, PyTorch, and scikit-learn.\nNLP Techniques: Understanding of tokenization, embeddings, transformer-based models (e.g., BERT, GPT, LLaMA), and RAG workflows.\nVector Databases: Experience with Weaviate, Pinecone, FAISS, or similar VectorDBs for document retrieval and storage.\nLangGraph & GenAI Frameworks: Hands-on experience with LangGraph, LangChain, HuggingFace Transformers, OpenAI API, and other Generative AI tools.\nCloud Deployment: Familiarity with deploying AI solutions on AWS, GCP, or Azure.\nTime Series Forecasting: Experience with ARIMA, LSTM, Prophet, and other forecasting techniques.\nModel Training & Fine-Tuning: Ability to train and fine-tune machine learning models, including large language models (LLMs), to enhance performance and accuracy.\nProblem-Solving & Collaboration: Strong analytical, problem-solving, and teamwork skills to work effectively in a cross-functional environment.\nPreferred Skills\nExperience in implementing RAG workflows and integrating generative AI with retrieval-based systems.\nFamiliarity with ethical AI principles and compliance frameworks.\nKnowledge of additional programming languages such as JavaScript or SQL.\nProficiency in MLOps practices for automating AI/ML pipelines and lifecycle management.\nExperience in developing AI-driven applications for real-world industry use cases.\nSkills: retrieval-augmented generation (rag),neuro-linguistic programming (nlp),data analysis,collaboration,programming,forecasting,prompt engineering,pytorch,cloud deployment,generative ai frameworks,programming in python,time series forecasting,langgraph & genai frameworks,vector databases (weaviate, pinecone, faiss),problem-solving & collaboration,langgraph & genai frameworks (langchain, huggingface transformers, openai api),ai ml,gen ai,vector databases,time series forecasting (arima, lstm, prophet),model training & fine-tuning,scikit-learn,problem-solving,tensorflow,langgraph,cloud deployment (aws, gcp, azure),nlp techniques,programming (python),mlops,ai/ml expertise\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Experience:** 2-4 years of experience in AI/ML, with a focus on NLP, Generative AI, and Time Series Forecasting.\n* **Technical Skills:**\n  * Programming: Proficiency in Python.\n  * AI/ML frameworks: TensorFlow, PyTorch, scikit-learn, LangGraph, LangChain, HuggingFace Transformers, OpenAI API.\n  * NLP techniques: Tokenization, embeddings, transformer-based models (e.g., BERT, GPT, LLaMA), RAG workflows.\n  * Vector Databases: Experience with Weaviate, Pinecone, FAISS, or similar VectorDBs.\n  * Time Series Forecasting: ARIMA, LSTM, Prophet, and other forecasting techniques.\n* **Key Qualifications:**\n  * AI/ML expertise with a focus on NLP, Generative AI, and Time Series Forecasting.\n  * Prompt engineering for large language models (LLMs).\n  * Strong data analysis and interpretation skills.\n  * Experience with cloud deployment on AWS, GCP, or Azure.\n* **Preferred Qualifications:**\n  * Experience implementing RAG workflows and integrating generative AI with retrieval-based systems.\n  * Familiarity with ethical AI principles and compliance frameworks.\n  * Knowledge of additional programming languages such as JavaScript or SQL.\n  * Proficiency in MLOps practices.\n  * Experience developing AI-driven applications for real-world industry use cases.", "company": "Idea Elan", "position": "AI Engineer", "location": "India"}, "senior-data-scientist-at-recro-4271586232.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\senior-data-scientist-at-recro-4271586232.html", "link": "https://in.linkedin.com/jobs/view/senior-data-scientist-at-recro-4271586232?position=10&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=N1eyHLzK2Fs5iAW2K0%2BkSQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nRole & Responsibility:\nExperience working closely with other data scientists, data engineers software engineers, data managers and business partners.\nCan build scalable, re-usable, impactful data science products, usually containing statistical or machine learning algorithms, in collaboration with data engineers and software engineers.\nCan carry out data analyses to yield actionable business insights.\nHands-on experience \n(typically 5+ years)\n designing, planning, prototyping, productionizing, maintaining and documenting reliable and scalable data science products in complex environments.\nApplied knowledge of data science tools and approaches across all data lifecycle stages.\nThorough understanding of underlying mathematical foundations of statistics and machine learning.\nDevelopment experience in one or more object-oriented programming languages (e.g. Python, Go, Java, C++)\nAdvanced SQL knowledge.\nKnowledge of experimental design and analysis.\nCustomer-centric and pragmatic mindset. Focus on value delivery and swift execution, while maintaining attention to detail.\n \nIn addition to the above, the following skills also need to be checked:\n \nClassical ML (Supervised/Unsupervised learning things like regression, clustering, etc.)\nDeep Learning (if any area needed it's likely to be limited to fine-tuning a model, not creating one from scratch).\nOptimisation (linear, non-linear, etc.)\nLLM/RAGs\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Eligibility Criteria:**\n  * 5+ years of hands-on experience in designing, planning, prototyping, productionizing, maintaining, and documenting data science products.\n  * Experience working with cross-functional teams (data scientists, data engineers, software engineers, data managers, and business partners).\n* **Required Skills:**\n  * Applied knowledge of data science tools and approaches across all data lifecycle stages.\n  * Thorough understanding of mathematical foundations of statistics and machine learning.\n  * Development experience in one or more object-oriented programming languages (e.g., Python, Go, Java, C++).\n  * Advanced SQL knowledge.\n  * Knowledge of experimental design and analysis.\n* **Required Expertise:**\n  * Classical Machine Learning (Supervised/Unsupervised learning, e.g., regression, clustering).\n  * Optimisation techniques (linear, non-linear, etc.).\n* **Preferred/Additional Skills:**\n  * Deep Learning (fine-tuning a model, not creating one from scratch).\n  * Large Language Models (LLM) and Retrieval Augmented Generation (RAG) models.\n* **Soft Skills:**\n  * Customer-centric and pragmatic mindset.\n  * Focus on value delivery, swift execution, and attention to detail.", "company": "Recro", "position": "Senior Data Scientist", "location": "India"}, "machine-learning-engineer-5-yrs-at-orbion-infotech-4271578510.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\machine-learning-engineer-5-yrs-at-orbion-infotech-4271578510.html", "link": "https://in.linkedin.com/jobs/view/machine-learning-engineer-5-yrs-at-orbion-infotech-4271578510?position=11&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=p2EyuQ0caeKTeJ%2BaKUFu7w%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          Tips: Provide a summary of the role, what success in the position looks like, and how this role fits into the organization overall.\nResponsibilities\n[Be specific when describing each of the responsibilities. Use gender-neutral, inclusive language.]\nExample: Determine and develop user requirements for systems in production, to ensure maximum usability\nQualifications\n[Some qualifications you may want to include are Skills, Education, Experience, or Certifications.]\nExample: Excellent verbal and written communication skills\nSkills: tensorflow,statistical analysis,python,scikit-learn,data analysis,model deployment,machine learning,communication skills\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** Not specified\n* **Experience:** Not specified\n* **Skills:**\n  * Excellent verbal and written communication skills\n  * Technical skills:\n    + TensorFlow\n    + Statistical analysis\n    + Python\n    + Scikit-learn\n    + Data analysis\n    + Model deployment\n    + Machine learning\n* **Certifications:** Not specified\n* **Other qualifications:** \n  * Ability to determine and develop user requirements for systems in production \n  * Ensure maximum usability \n  * Success in the position involves understanding the role's responsibilities and how it fits into the organization overall.", "company": "Orbion Infotech", "position": "Machine Learning Engineer( 5 yrs)", "location": "India"}, "learning-support-specialist-ml-ai-data-science-and-data-engineering-at-emeritus-4259404928.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\learning-support-specialist-ml-ai-data-science-and-data-engineering-at-emeritus-4259404928.html", "link": "https://in.linkedin.com/jobs/view/learning-support-specialist-ml-ai-data-science-and-data-engineering-at-emeritus-4259404928?position=12&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=dUQmRY%2B1oHX1wo2EwOh%2FiQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout Emeritus:\nEmeritus is committed to teaching the skills of the future by making high-quality education accessible and affordable to individuals, companies, and governments around the world. It does this by collaborating with more than 50 top-tier universities across the United States, Europe, Latin America, Southeast Asia, India and China.\nEmeritus\u2019 short courses, degree programs, professional certificates, and senior executive programs help individuals learn new skills and transform their lives, companies and organizations. Its unique model of state-of-the-art technology, curriculum innovation, and hands-on instruction from senior faculty, mentors and coaches has educated more than 250,000 individuals across 80+ countries.\nFounded in 2015, Emeritus, part of Eruditus Group, has more than 2,000 employees globally and offices in Mumbai, New Delhi, Shanghai, Singapore, Palo Alto, Mexico City, New York, Boston, London, and Dubai. Following its $650 million Series E funding round in August 2021, the Company is valued at $3.2 billion, and is backed by Accel, SoftBank Vision Fund 2, the Chan Zuckerberg Initiative, Leeds Illuminate, Prosus Ventures, Sequoia Capital India, and Bertelsmann.\nAbout the Role:\nThe Learning Support Specialist is a subject matter expert and largely impacts the student experience by guiding students through their learning journey.\nCandidates must have industry experience, demonstrated knowledge of the course subject area, and strong interpersonal skills. This is a full-time, remote role.\nThe purpose of this position is to provide assistance and aid learners enrolled in programs within the fields of machine learning and AI, data engineering, data science, and data analytics. The successful candidate will have proven experience as a data engineer and/or data scientist. The candidate must have excellent time management skills and the desire to work in a fast-paced educational tech environment where supplementing the educational journey of learners is priority. We are looking for a professional who does not mind a busy schedule and wants to provide excellent internal and external customer service. \nRoles and Responsibilities:\nMonitor and respond to all student inquiries via the learning management system and learner support software, using compassion and understanding for the student learning journey within 24 hours or less of submission\nRely on industry knowledge to quickly and clearly guide students through complex assignments and questions\nProvide prompt feedback that includes pointed questions that will help guide students towards correct answers and allows them to build problem-solving skills\nWork with students who are both new to the subject matter, as well as those with experience or who are further along in their careers\nSuggest course improvements to assigned Program Delivery Manager (PDM) and Designer to ensure content is communicated clearly, accurately, and effectively in videos, assignments and collateral materials\nCommunicate and collaborate with the Emeritus team on a regular basis to enhance course delivery and to solve unexpected course challenges\nSkills and Qualifications:\n5+ years of extensive work experience in the field of data engineering, data science, or data analytics \nProfessional and/or academic experience in machine learning and artificial intelligence\nProficiency in JavaScript, Python, and the use of GitHub\nExperience using data visualization tools (i.e. Tableau)\nExperience using Microsoft Azure \nAdvanced academic background in mathematics, particularly statistics, calculus, and linear algebra\nExcellent verbal and written communication and interpersonal skills with an ability to listen effectively, respond appropriately, and maintain a mutual comfort level while working with a diverse student population\nExperience using Canvas or other related learning management system\nPreferred Qualifications:\nExperience using Slack and Teams, as communication tools\nExperience working with support/service software or ticketing system\nExperience with using bug tracking and feedback tools\nEmeritus provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\nIn press:\nhttps://www.insidehighered.com/blogs/learning-innovation/why-chan-zuckerberg-backed-113-million-investment-eruditus-big-deal\nhttps://techcrunch.com/2020/08/31/chan-zuckerberg-initiative-backs-indian-education-startup-eruditus-in-113-million-fundraise/\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required Qualifications:**\n  * 5+ years of work experience in data engineering, data science, or data analytics\n  * Industry experience and knowledge in machine learning and artificial intelligence\n  * Advanced academic background in mathematics, particularly statistics, calculus, and linear algebra\n  * Proficiency in:\n    * JavaScript\n    * Python\n    * GitHub\n  * Experience with:\n    * Data visualization tools (e.g., Tableau)\n    * Microsoft Azure\n    * Canvas or other related learning management system\n  * Excellent verbal and written communication and interpersonal skills\n\n* **Preferred Qualifications:**\n  * Experience with Slack and Teams as communication tools\n  * Experience working with support/service software or ticketing system\n  * Experience with bug tracking and feedback tools", "company": "Emeritus", "position": "Learning Support Specialist - ML&AI, Data Science and Data Engineering", "location": "India"}, "data-science-machine-learning-trainer-at-nxtwave-4269444170.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-science-machine-learning-trainer-at-nxtwave-4269444170.html", "link": "https://in.linkedin.com/jobs/view/data-science-machine-learning-trainer-at-nxtwave-4269444170?position=13&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=pp5TneFY%2BPkutRv3WLuZ9g%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout the Company\nNxtWave is one of India\u2019s fastest-growing Ed-Tech startups. NxtWave is revolutionizing the 21st-century job market by transforming youth into highly skilled tech professionals irrespective of their educational background with its CCBP 4.0 programs. NxtWave is founded by Rahul Attuluri (Ex Amazon, IIIT Hyderabad), Sashank Reddy (IIT Bombay), and Anupam Pedarla (IIT Kharagpur). The startup is backed by Orios Ventures, Better Capital, and marquee angels, including founders of some of India\u2019s unicorns. NxtWave is an official partner for NSDC, under the Ministry of Skill Development & Entrepreneurship, Govt. of India, and recognized by NASSCOM, Ministry of Commerce and Industry, Govt. of India, and Startup India. The startup has received accolades as \u2018The Greatest Brand in Education\u2019 in a research-based listing by URS Media, a leading international media house. By offering vernacular content and interactive learning, NxtWave is breaking the entry barrier for learning tech skills. Learning in their mother tongue helps learners achieve higher comprehension, deeper attention, longer retention, and greater outcomes. NxtWave now has paid subscribers from 450+ districts across India. In just 2 years, CCBP 4.0 learners have been hired by 2000+ companies including Google, Amazon, Nvidia, Goldman Sachs, Oracle, Deloitte, and more.\nKnow more about NxtWave: https://www.ccbp.in/\nAbout the Role\nWe are looking for a passionate and experienced Part-Time Instructor to lead our 8-week online DSML training program. The ideal candidate will bring a strong background in Data Science & Machine Learning and prior teaching experience, preferably with reputed edtech platforms.\nResponsibilities\nPrior teaching experience with platforms such as Scaler, Bosscoder, Coding Ninjas, Acciojob, etc.\nAbility to simplify complex DSML concepts for learners.\nQualifications\nProficient in core Data Science and Machine Learning concepts, tools, and frameworks.\nHands-on experience in real-world ML projects and data-driven problem-solving.\nRequired Skills\nExperience working at a top tech company is a plus, but not mandatory.\nStrong communication skills and a learner-first approach.\nProgram Details\nMode: Online (Live Interactive Classes)\nSchedule: Monday to Friday, 10:00 AM \u2013 1:00 PM\nDuration: 8 Weeks (Total 40 sessions)\nWhy Join Us?\nDeliver impactful training to aspiring data professionals.\nCollaborate with a dedicated team focused on high-quality tech education.\nFlexible, part-time engagement with attractive compensation.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required Qualifications and Skills:**\n  * Prior teaching experience, preferably with edtech platforms such as Scaler, Bosscoder, Coding Ninjas, Acciojob, etc.\n  * Proficient in core Data Science and Machine Learning concepts, tools, and frameworks.\n  * Hands-on experience in real-world ML projects and data-driven problem-solving.\n  * Strong communication skills and a learner-first approach.\n* **Preferred Qualifications and Skills:**\n  * Experience working at a top tech company.\n  * Experience with platforms like Scaler, Bosscoder, Coding Ninjas, Acciojob, etc. is specifically mentioned as a plus.", "company": "NxtWave", "position": "Data Science & Machine Learning Trainer", "location": "India"}, "python-developer-sde-2-at-greythr-4264074519.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-developer-sde-2-at-greythr-4264074519.html", "link": "https://in.linkedin.com/jobs/view/python-developer-sde-2-at-greythr-4264074519?position=14&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=RHc241gSclWahGjK0Qyk4w%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nResponsibilities\n\u2022 Lead the design, development, and deployment of critical backend features using Python and Django\n\u2022 Design and implement scalable and efficient database solutions using PostgreSQL\nCollaborate effectively with cross-functional teams (design, product, QA) to deliver high-quality software on time and within budget\n\u2022 Write clean, maintainable, well-documented, and testable code\n\u2022 Conduct code reviews and mentor junior engineers on best practices\n\u2022 Proactively identify and implement improvements to the codebase\n\u2022 Stay up-to-date on the latest technologies and best practices in backend development and cloud computing\n\u2022 (Plus) Leverage Google Cloud Platform (GCP) services to build, deploy, and manage scalable and reliable systems.\nQualifications\n\u2022 Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent experience)\n\u2022 3+ years of experience in software development\n\u2022 In-depth expertise in Python and Django\n\u2022 Solid understanding of object-oriented programming (OOP) concepts and design patterns\n\u2022 Proven experience with relational databases (PostgreSQL preferred)\n\u2022 Experience with building and maintaining APIs\n\u2022 Strong problem-solving and analytical skills\n\u2022 Excellent communication, collaboration, and leadership skills\n\u2022 A passion for building high-quality software and a continuous learner\nBenefits\n\u2022 Competitive salary and benefits package\n\u2022 Opportunity to work on challenging and impactful projects\n\u2022 Collaborative and supportive work environment\n\u2022 Continuous learning and development opportunities\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** \n  * Bachelor's degree in Computer Science, Information Technology, or a related field\n  * Equivalent experience (instead of a degree) is also considered\n* **Experience:** \n  * 3+ years of experience in software development\n* **Technical Skills:**\n  * In-depth expertise in Python and Django\n  * Solid understanding of object-oriented programming (OOP) concepts and design patterns\n  * Experience with relational databases (PostgreSQL preferred)\n  * Experience with building and maintaining APIs\n  * Familiarity with Google Cloud Platform (GCP) services (preferred)\n* **Soft Skills:**\n  * Strong problem-solving and analytical skills\n  * Excellent communication, collaboration, and leadership skills\n  * Passion for building high-quality software and a continuous learner", "company": "greytHR", "position": "Python Developer - SDE-2", "location": "India"}, "associate-data-scientist-at-ascendeum-4265405159.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\associate-data-scientist-at-ascendeum-4265405159.html", "link": "https://in.linkedin.com/jobs/view/associate-data-scientist-at-ascendeum-4265405159?position=15&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=IdXwkqFkevp24oy9az5brw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAscendeum is looking for mathematicians, with extensive hands-on experience in the field of data science, who can analyze large data sets efficiently to generate actionable business intelligence that drives peak performance for our clients.\nAbout Us:\nWe provide AdTech strategy consulting to leading internet websites and apps hosting over 200 million monthly audiences worldwide. Since 2015, our consultants and engineers have consistently delivered intelligent solutions that enable enterprise-level websites and apps to maximize their digital advertising returns.\nJob Responsibilities:\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data.\nAnalyze large amounts of information to discover trends and patterns\nHelping develop reports and analysis.\nPresent information using data visualisation techniques.\nAssessing tests, implementing new or upgraded software, and assisting with strategic decisions on new systems.\nEvaluating changes and updates to source production systems.\nDevelop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks.\nProviding technical expertise in data storage structures, data mining, and data cleansing.\nPropose solutions and strategies to business challenges\nDesired Skills and Experience:\nRelevant 2+ years of experience in Data Analysis\nComplete understanding of Operations Research, Data Modelling, ML, and AI concepts.\nKnowledge of Python is mandatory, familiarity with MySQL, SQL, Scala, Java or C++ is an asset\nExperience using visualization tools (e.g. Jupyter Notebook) and data frameworks (e.g. Hadoop)\nAnalytical mind and business acumen\nStrong math skills (e.g. statistics, algebra)\nProblem-solving aptitude\nExcellent communication and presentation skills.\nBachelor\u2019s / Master's Degree in Computer Science, Engineering, Data Science or other quantitative or relevant field is preferred\nThank you for your interest in joining Ascendeum.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** \n  * Bachelor's or Master's Degree in Computer Science, Engineering, Data Science, or a quantitative/relevant field\n* **Experience:** \n  * 2+ years of experience in Data Analysis\n  * Extensive hands-on experience in the field of data science\n* **Skills:**\n  * Python (mandatory)\n  * MySQL, SQL, Scala, Java, or C++ (asset)\n  * Data visualization tools (e.g., Jupyter Notebook)\n  * Data frameworks (e.g., Hadoop)\n  * Operations Research\n  * Data Modelling\n  * Machine Learning (ML)\n  * Artificial Intelligence (AI)\n  * Statistics\n  * Algebra\n* **Personal Qualities:**\n  * Analytical mind\n  * Business acumen\n  * Problem-solving aptitude\n  * Excellent communication and presentation skills", "company": "Ascendeum", "position": "Associate Data Scientist", "location": "India"}, "machine-learning-engineer-at-goml-4271473779.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\machine-learning-engineer-at-goml-4271473779.html", "link": "https://in.linkedin.com/jobs/view/machine-learning-engineer-at-goml-4271473779?position=16&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=EqK%2BUeeD0KHsbt1dwDjKfA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nLooking for a culture to thrive & build a rewarding career for yourself, join the core team of young hustlers building the next generation of Machine Learning platform & services. You will develop training and deployment pipelines for machine learning, implement model compression algorithms, and productionize machine learning research solving challenging business problems.\nKey Responsibilities:\nDesign and develop generative AI models using techniques like RAG, transformers, and other relevant approaches.\nFine-tune pre-trained LLMs for specific tasks and domains.\nConduct research on new techniques for improving the performance and capabilities of generative AI models.\nApply software engineering rigor and best practices to machine learning /Generative AI pipelines.\nEvaluate and analyse the performance of ML/generative AI models.\nStay up to date on the latest advancements in generative AI research.\nFacilitate the development and deployment of proof-of-concept Generative AI systems.\nQualifications:\nBachelor\u2019s/Master\u2019s degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n3-5 years of experience in generative AI or related fields.\nExperience in building data pipelines, deploying ML/GenAI models in production, and monitoring and maintaining their performance.\nStrong programming skills in Python.\nFamiliarity with RAG and other techniques for building generative models.\nExtensive experience with Git, Docker and a good understanding of Linux for managing servers.\nExperience with cloud-based ecosystems, especially AWS ML/GenAI services.\nExposure to ML/GenAI frameworks and tools.\nExcellent communication and collaboration skills.\nAbility to work independently and in a team-oriented environment.\nMethodical and meticulous towards work and planning.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:**\n  * Bachelor\u2019s degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n  * Master\u2019s degree in related fields is preferred.\n* **Experience:**\n  * 3-5 years of experience in generative AI or related fields.\n  * Experience in:\n    * Building data pipelines.\n    * Deploying ML/GenAI models in production.\n    * Monitoring and maintaining model performance.\n* **Technical Skills:**\n  * Strong programming skills in Python.\n  * Familiarity with:\n    * RAG (Retrieval-Augmented Generation) technique.\n    * Transformers.\n    * Other generative AI models and techniques.\n  * Extensive experience with:\n    * Git.\n    * Docker.\n    * Linux for managing servers.\n  * Experience with cloud-based ecosystems, especially AWS ML/GenAI services.\n  * Exposure to ML/GenAI frameworks and tools.\n* **Soft Skills:**\n  * Excellent communication and collaboration skills.\n  * Ability to work independently and in a team-oriented environment.\n  * Methodical and meticulous approach to work and planning.", "company": "goML", "position": "Machine Learning Engineer", "location": "India"}, "ai-developer-at-elegant-enterprise-wide-solutions-inc-4263507628.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\ai-developer-at-elegant-enterprise-wide-solutions-inc-4263507628.html", "link": "https://in.linkedin.com/jobs/view/ai-developer-at-elegant-enterprise-wide-solutions-inc-4263507628?position=17&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=wvnwUYSBc1KftjosbEoWNA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJob Title: AI Developer \u2013 Recruitment Process Automation\nLocation:\n Remote\n \nExperience:\n 2\u20134 years\n \nJob Type:\n Full-Time | Remote\nAbout Us:\n At Elegant Enterprise-Wide Solutions, we\u2019re transforming how staffing works by embracing smart automation. We're hiring an \nAI Developer\n to build intelligent tools that streamline and automate our core staffing operations.\nResponsibilities:\nDesign and implement AI/ML solutions to automate recruitment and staffing workflows.\nCollaborate with operations and HR teams to understand use cases and pain points.\nBuild and train models for resume parsing, candidate matching, and document generation.\nCreate and refine effective prompts to drive accurate outputs from generative AI tools (e.g., ChatGPT, Claude).\nEnsure integration of AI tools with internal systems like CRMs, ATS, and proposal platforms.\nContinuously improve the accuracy, speed, and reliability of all automation solutions.\nRequirements:\n2\u20134 years of experience in AI/ML development or automation projects.\nStrong Python skills with hands-on knowledge of libraries such as Scikit-learn, spaCy, or NLTK.\nExperience with natural language processing (NLP) and resume parsing.\nAbility to craft effective AI prompts for automating content-based tasks.\nFamiliarity with recruitment workflows, HR tech tools, or staffing platforms.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Experience:** 2-4 years in AI/ML development or automation projects\n* **Technical Skills:**\n  * Strong Python skills\n  * Hands-on knowledge of libraries such as Scikit-learn, spaCy, or NLTK\n  * Experience with natural language processing (NLP)\n  * Experience with resume parsing\n* **AI/ML Skills:**\n  * Ability to craft effective AI prompts for automating content-based tasks\n  * Experience with generative AI tools (e.g., ChatGPT, Claude)\n* **Domain Knowledge:**\n  * Familiarity with recruitment workflows\n  * Familiarity with HR tech tools or staffing platforms\n* **Soft Skills:** \n  * Collaboration with operations and HR teams \n  * Continuous improvement mindset", "company": "Elegant Enterprise-Wide Solutions, Inc.", "position": "AI Developer", "location": "India"}, "artificial-intelligence-engineer-at-hyqoo-4264456976.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\artificial-intelligence-engineer-at-hyqoo-4264456976.html", "link": "https://in.linkedin.com/jobs/view/artificial-intelligence-engineer-at-hyqoo-4264456976?position=18&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=XxkN%2BWAoWNsKxZ55PCF9Sw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nTitle - AI Engineer \nType - Contract \nLocation - Remote\n \nRoles and Responsibilities:\n- Design and implement AI solutions using LLMs for tasks such as summarization, question answering, and document understanding.\n- Build and optimize retrieval-augmented generation (RAG) pipelines by combining OCR and LLMs for unstructured document processing.\n- Integrate LLMs and OCR tools, such as Azure Document Intelligence and Tesseract, into scalable applications.\n- Preprocess scanned and digital documents using OCR to extract structured and semi-structured text for LLM input.\n- Perform prompt engineering and fine-tuning of LLMs to enhance accuracy and task-specific performance.\n- Evaluate and monitor LLM+OCR system outputs for quality, bias, and hallucination risks.\n- Collaborate with cross-functional teams to deliver AI solutions tailored to domain-specific needs.\n- Stay updated on the latest developments in foundation models, Agentic AI, and OCR technologies.\nQualifications\n:\n- Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, or a related field.\n- 4+ years of experience in AI/ML, with a focus on LLMs and prompt engineering.\n- Proven ability to work independently, demonstrating initiative, ownership, and accountability across all phases of solution development.\n- Practical understanding of SAFe Agile methodologies, with experience delivering AI/ML solutions in cross-functional Agile teams.\nTools and Technologies:\n- Hands-on experience with LLM frameworks such as LangChain and Semantic Kernel.\n- Strong understanding of vector search, embedding models, and semantic retrieval (e.g., FAISS, Pinecone, Azure Cognitive Search).\n- Proficiency in Python, with experience integrating APIs, function calling, regular expressions, and handling LLM outputs.\n- Deep expertise in prompt engineering, including few-shot prompting, prompt tuning, prompt chaining, and optimization techniques for task-specific accuracy and cost control.\n- Solid knowledge of RAG architectures and agent design patterns (e.g., tool use, memory, planning).\n- Experience with OCR technologies (e.g., Tesseract, Azure Document Intelligence) for document understanding and information extraction from scanned or image-based content.\n- Familiarity with LLM platforms and tools like Azure OpenAI, LLMOps.\n- Experience deploying LLM-based applications in cloud environments, with attention to performance, reliability, and scalability.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:**\n  * Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, or a related field.\n* **Experience:**\n  * 4+ years of experience in AI/ML, with a focus on LLMs and prompt engineering.\n* **Skills:**\n  * Hands-on experience with LLM frameworks such as LangChain and Semantic Kernel.\n  * Strong understanding of vector search, embedding models, and semantic retrieval (e.g., FAISS, Pinecone, Azure Cognitive Search).\n  * Proficiency in Python.\n  * Deep expertise in prompt engineering, including few-shot prompting, prompt tuning, prompt chaining, and optimization techniques.\n  * Solid knowledge of RAG architectures and agent design patterns.\n  * Experience with OCR technologies (e.g., Tesseract, Azure Document Intelligence).\n  * Familiarity with LLM platforms and tools like Azure OpenAI, LLMOps.\n* **Methodologies:**\n  * Practical understanding of SAFe Agile methodologies.\n* **Soft Skills:**\n  * Proven ability to work independently, demonstrating initiative, ownership, and accountability.\n  * Experience delivering AI/ML solutions in cross-functional Agile teams.\n* **Tools and Technologies:**\n  * Experience integrating APIs, function calling, regular expressions, and handling LLM outputs.\n  * Experience deploying LLM-based applications in cloud environments, with attention to performance, reliability, and scalability.", "company": "Hyqoo", "position": "Artificial Intelligence Engineer", "location": "India"}, "python-developer-remote-at-altraize-4177412286.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-developer-remote-at-altraize-4177412286.html", "link": "https://in.linkedin.com/jobs/view/python-developer-remote-at-altraize-4177412286?position=19&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=GmYRKdP51fTQSwuDr6Ns1Q%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          This is a permanently remote job.\nHiring Senior Python Developers to work on AI technology. This opportunity is tailored for professionals who thrive on developing innovative solutions and who aspire to be at the forefront of AI advancements.\nRequired Skills\nWrite effective Python code to tackle complex issues\nUse business sense and analytical abilities to glean valuable insights from public databases \nClearly express the reasoning and logic when writing code in Jupyter notebooks or other suitable mediums\nExtensive experience working with Python \nProficiency with the language's syntax and conventions\nPrevious experience tackling algorithmic problems\nNice to have some prior Software Quality Assurance and Test Planning experience\nExcellent spoken and written English communication skills\nRequired Skills for TWA: The ideal candidates should be able to\nClearly explain their strategies for problem-solving.\nDesign practical solutions in code.\nDevelop test cases to validate their solutions.\nDebug and refine their solutions for improvement.\nQualifications\n3+ years of professional software development with demonstrable back-end implementation skills\nEnd-to-end experience in building massively scalable & resilient cloud-native applications\nExpert in Python programming skills\nShould have atleast 2+ yrs of experience in Technical Writing\nShould have exp in API development\nShould have exp in JSON\nExposure to AWS/Azure/GCP environment is a bonus\nStrong Software development fundamentals, architecture, algorithms, and problem-solving skills\nExcellent communication, strong organizational skills and attention to detail.\nSkills: python,nosql,aiml,artificial intelligence,api,json\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Experience:**\n  * 3+ years of professional software development with back-end implementation skills\n  * 2+ years of experience in Technical Writing\n* **Technical Skills:**\n  * Extensive experience working with Python\n  * Expert in Python programming skills\n  * Proficiency with Python syntax and conventions\n  * Experience with API development\n  * Experience with JSON\n  * Familiarity with NoSQL, AI/ML, and Artificial Intelligence\n* **Cloud and Testing:**\n  * End-to-end experience in building scalable & resilient cloud-native applications (AWS/Azure/GCP experience is a bonus)\n  * Experience with Software Quality Assurance and Test Planning (nice to have)\n* **Soft Skills:**\n  * Excellent spoken and written English communication skills\n  * Strong organizational skills and attention to detail\n  * Ability to clearly explain problem-solving strategies\n  * Ability to design practical solutions in code and develop test cases\n* **Work Style:**\n  * Ability to work remotely permanently\n  * Self-motivated and able to thrive in a remote work environment (implied)", "company": "Altraize", "position": "Python Developer, Remote", "location": "India"}, "graphdb%2Bpython-developer-at-bounteous-4260864622.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\graphdb%2Bpython-developer-at-bounteous-4260864622.html", "link": "https://in.linkedin.com/jobs/view/graphdb%2Bpython-developer-at-bounteous-4260864622?position=20&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=DqZvkoXSz8QJDMbPhZhCOA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWe are looking for a skilled \nGraphDB + Python Developer\n to join our team to design, develop, and maintain graph database solutions and integrate them with Python applications. The ideal candidate will have hands-on experience working with graph databases (such as GraphDB, Neo4j, or similar RDF/triple stores) and strong Python programming skills to build scalable, efficient, and robust data-driven applications.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* Eligible candidates have:\n  * Hands-on experience with graph databases (e.g., GraphDB, Neo4j, RDF/triple stores)\n  * Strong Python programming skills\n  * Experience designing, developing, and maintaining graph database solutions\n  * Ability to integrate graph databases with Python applications\n  * Knowledge of building scalable, efficient, and robust data-driven applications (preferred)", "company": "Bounteous", "position": "GraphDB+Python Developer", "location": "India"}, "software-engineer-python-react-at-dexian-india-4273061347.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-python-react-at-dexian-india-4273061347.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-python-react-at-dexian-india-4273061347?position=21&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=czJAqnN5l4o1NFFrbJ7Y6w%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJob Description: \nSenior Full Stack Developer\nPosition Overview: We are seeking a highly skilled Full Stack Developer to join our dynamic team within Global Trading. The ideal candidate will possess a robust understanding of both front-end and back-end development, with a strong emphasis on creating and maintaining scalable, high-performance applications. This role requires a professional who can seamlessly integrate into our team, contributing to the development of innovative solutions that drive our trading operations.\nTo be eligible for this role, you must be able to demonstrate:\n\u2022 Strong communication and interpersonal skills\n\u2022 Ability to collaborate effectively with internal and external customers\n\u2022 Innovative and analytical thinking\n\u2022 Ability to manage workload under time pressure and changing priorities\n\u2022 Adaptability and willingness to learn new technologies and methodologies.\nRequired Skills and Qualifications:\n\u2022 Technical Proficiency:\n\u2022 \nExpert Front-end React Framework & Backend Python Experience\n\u2022 Proficient in front-end technologies such as HTML, CSS, Strong back-end development skills, or similar languages.\n\u2022 Proficient GIT, & CI/CD experience.\n\u2022 Develop and maintain web applications using modern frameworks and technologies\n\u2022 Help maintain code quality, organization, and automation\n\u2022 Experience with relational database management systems.\n\u2022 Familiarity with cloud services (AWS, Azure, or Google Cloud \u2013 Primarily Azure).\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Eligibility Criteria:**\n  * Strong communication and interpersonal skills\n  * Ability to collaborate with internal and external customers\n  * Innovative and analytical thinking\n  * Ability to manage workload under time pressure and changing priorities\n  * Adaptability and willingness to learn new technologies and methodologies\n\n* **Required Technical Skills:**\n  * Expert Front-end React Framework experience\n  * Expert Backend Python experience\n  * Proficient in front-end technologies such as HTML, CSS\n  * Strong back-end development skills\n  * Proficient in GIT and CI/CD\n  * Experience with relational database management systems\n  * Familiarity with cloud services (Primarily Azure, also AWS or Google Cloud)\n\n* **Preferred/Not Explicitly Stated but Implied:**\n  * Experience with modern front-end and back-end frameworks and technologies \n  * Experience in maintaining code quality, organization, and automation", "company": "Dexian India", "position": "Software Engineer (Python & React)", "location": "Pune, Maharashtra, India"}, "data-analyst-data-scientist-at-weekday-ai-yc-w21-4264836804.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-analyst-data-scientist-at-weekday-ai-yc-w21-4264836804.html", "link": "https://in.linkedin.com/jobs/view/data-analyst-data-scientist-at-weekday-ai-yc-w21-4264836804?position=22&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=ker9DSA6SmFb4RW3TZdQCQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nThis role is for one of the Weekday's clients\nSalary range: Rs 300000 - Rs 1200000 (ie INR 3-12 LPA)\nMin Experience: 1 years\nLocation: Remote (India)\nJobType: full-time\nWe're looking for a passionate and detail-oriented Data Analyst / Data Scientist to join our growing analytics team. This role is perfect for someone who thrives on solving complex problems using data, loves diving deep into datasets, and has a strong command of analytical tools and programming languages.\nAs a Data Analyst / Data Scientist, you will play a crucial role in helping teams make data-driven decisions by uncovering actionable insights from structured and unstructured data. You'll work closely with stakeholders across departments\u2014such as product, marketing, and operations\u2014to understand their challenges and deliver meaningful analysis and visualizations that guide strategy and execution.\nRequirements\nKey Responsibilities:\n Perform exploratory data analysis to identify trends, patterns, and opportunities within large datasets. \n Build and maintain dashboards and reports using Tableau to visualize KPIs, performance metrics, and other analytical outputs. \n Write efficient, well-structured SQL queries to extract, manipulate, and analyze data from various databases. \n Use Python to develop scripts and workflows for data cleaning, transformation, and predictive modeling. \n Collaborate with cross-functional teams to define data requirements and deliver insights to support business decisions. \n Interpret data and communicate results clearly and effectively to both technical and non-technical stakeholders. \n Participate in the development and improvement of data models, pipelines, and quality checks. \n Stay up-to-date with industry trends, best practices, and new technologies in analytics and data science. \nRequirements:\n Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, Engineering, or a related field. \n 1-5 years of experience in a data analyst or data scientist role, preferably in a fast-paced or startup environment. \n Strong proficiency in SQL and Python for data manipulation and analysis. \n Experience building dashboards and visualizations using Tableau (or similar tools such as Power BI or Looker). \n Solid understanding of statistical methods and ability to apply them to real-world business problems. \n Strong analytical and problem-solving skills with attention to detail and accuracy. \n Excellent communication and collaboration skills, with the ability to present findings in a clear and concise manner. \nNice to Have:\n Exposure to machine learning techniques and libraries (e.g., scikit-learn, XGBoost, etc.). \n Experience working with cloud-based data platforms (AWS, GCP, or Azure). \n Familiarity with version control tools like Git and workflow automation tools like Airflow\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** \n  * Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, Engineering, or a related field.\n* **Experience:** \n  * 1-5 years of experience in a data analyst or data scientist role.\n  * Preferably in a fast-paced or startup environment.\n  * Minimum 1 year of experience.\n* **Skills:**\n  * Strong proficiency in SQL and Python.\n  * Experience building dashboards and visualizations using Tableau, Power BI, or Looker.\n  * Solid understanding of statistical methods.\n  * Strong analytical and problem-solving skills.\n  * Excellent communication and collaboration skills.\n* **Nice to Have:**\n  * Exposure to machine learning techniques and libraries (e.g., scikit-learn, XGBoost, etc.).\n  * Experience working with cloud-based data platforms (AWS, GCP, or Azure).\n  * Familiarity with version control tools like Git and workflow automation tools like Airflow.", "company": "Weekday AI (YC W21)", "position": "Data Analyst / Data Scientist", "location": "India"}, "python-developer-at-onefin-4257193441.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-developer-at-onefin-4257193441.html", "link": "https://in.linkedin.com/jobs/view/python-developer-at-onefin-4257193441?position=23&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=8FWiDvPIgirBvoEsUF%2BIrA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nResponsibilities\nDesign and implement backend infrastructure and APIs. \nWrite high quality code that is robust, readable and scales. \nPossess the drive to dive deep. thrive and progress even in ambiguous situations. \nEncourage and support knowledge sharing within teams and external groups. \nTroubleshoot & debug applications. \nAdopt problem solving as a way of life - always go to the root cause. \nCollaborate with the team to discuss and implement ideas. \nBuild responsive, robust and optimised applications. \nRequirements\nPassionate about building backend systems. \nDesire to explore new ideas, open to other ideas as well. \nLove for writing clean, beautiful, readable and testable code. \nExperience in designing extensible DRY code. \nOur stack is based on Django, Python3 Celery, Angular and Postgres. \nWe expect you to have a good understanding of Python. It's even better if you are familiar with some of Git. Django, Celery, Redis and Unix Shell. \nSkills:- Django, Flask, Python, Amazon Web Services (AWS) and Celery\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required:**\n  * Passionate about building backend systems\n  * Experience in designing extensible DRY (Don't Repeat Yourself) code\n  * Good understanding of Python\n* **Preferred:**\n  * Familiarity with:\n    * Git\n    * Django\n    * Celery\n    * Redis\n    * Unix Shell\n  * Experience with:\n    * Flask\n    * Amazon Web Services (AWS)", "company": "OneFin", "position": "Python Developer", "location": "India"}, "executive-data-scientist-at-ascendeum-4273408579.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\executive-data-scientist-at-ascendeum-4273408579.html", "link": "https://in.linkedin.com/jobs/view/executive-data-scientist-at-ascendeum-4273408579?position=24&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=FpSJXmlv8mk%2FDvvXqda9IQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAscendeum is looking for mathematicians, with extensive hands-on experience in the field of data science, who can analyze large data sets efficiently to generate actionable business intelligence that drives peak performance for our clients.\nAbout Us:\nWe provide AdTech strategy consulting to leading internet websites and apps hosting over 200 million monthly audiences worldwide. Since 2015, our consultants and engineers have consistently delivered intelligent solutions that enable enterprise-level websites and apps to maximize their digital advertising returns.\nJob Responsibilities:\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data.\nAnalyze large amounts of information to discover trends and patterns\nHelping develop reports and analysis.\nPresent information using data visualisation techniques.\nAssessing tests, implementing new or upgraded software, and assisting with strategic decisions on new systems.\nEvaluating changes and updates to source production systems.\nDevelop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks.\nProviding technical expertise in data storage structures, data mining, and data cleansing.\nPropose solutions and strategies to business challenges\nDesired Skills and Experience:\nRelevant 4+ years of experience in Data Analysis\nComplete understanding of Operations Research, Data Modelling, ML, and AI concepts.\nKnowledge of Python is mandatory, familiarity with MySQL, SQL, Scala, Java or C++ is an asset\nExperience using visualization tools (e.g. Jupyter Notebook) and data frameworks (e.g. Hadoop)\nAnalytical mind and business acumen\nStrong math skills (e.g. statistics, algebra)\nProblem-solving aptitude\nExcellent communication and presentation skills.\nBachelor\u2019s / Master's Degree in Computer Science, Engineering, Data Science or other quantitative or relevant field is preferred\nThank you for your interest in joining Ascendeum.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** \n  * Bachelor's or Master's Degree in Computer Science, Engineering, Data Science, or a quantitative/relevant field\n* **Experience:** \n  * 4+ years of experience in Data Analysis\n  * Extensive hands-on experience in the field of data science\n* **Skills:**\n  * Strong math skills (statistics, algebra)\n  * Python (mandatory)\n  * MySQL, SQL, Scala, Java, or C++ (asset)\n  * Data visualization tools (e.g., Jupyter Notebook)\n  * Data frameworks (e.g., Hadoop)\n  * Operations Research\n  * Data Modelling\n  * Machine Learning (ML)\n  * Artificial Intelligence (AI)\n  * Data storage structures\n  * Data mining\n  * Data cleansing\n* **Personal Qualities:**\n  * Analytical mind\n  * Business acumen\n  * Problem-solving aptitude\n  * Excellent communication and presentation skills", "company": "Ascendeum", "position": "Executive Data Scientist", "location": "India"}, "python-developer-at-people-prime-worldwide-4272821999.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-developer-at-people-prime-worldwide-4272821999.html", "link": "https://in.linkedin.com/jobs/view/python-developer-at-people-prime-worldwide-4272821999?position=25&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=%2BANv8y4byT5MmeGTvclFCg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout Company:\nOur client organization's mission is to empower people to participate in global conversations through communities. They are responsible for the consumer-facing application on the Web, Android, and iOS platform. In this role, you'll work with a specific team within this organization to drive related technical & product strategy, operations, architecture, and execution for one of the largest sites in the world.\nPoster Experience specifically focuses on the user journey, which is the main source of user content for the product. We aim to make it easier, faster, and smarter to create and participate in conversations, and we drive several core product metrics for the entire ecosystem.\nThis specific role will involve migrating legacy Python microservice code to one or more existing Go microservices. Successful candidates have prior experience in these migrations at large scale (think millions of actions per day) and understand how to instrument and monitor their code for parity and consistency during rollout.\nJob Description:\nJob Title: Sr.Python Developer\nLocation: Pan India\nExperience: 6+ yrs.\nEmployment Type: Contract to hire\nWork Mode: Remote\nNotice Period: - Immediate joiners\nRoles and Responsibilities:\n7+ years of experience with practical, production-grade Python\nHands-on experience with Test Driven Development (TDD)\nProven ability to build and scale large systems at high velocity\nStrong fundamentals in database schema design and data modeling\nAble to work at a rapid pace without sacrificing clarity or correctness\n[Bonus] Familiarity with LLM function calling protocols and paradigms\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Eligibility Criteria:**\n  * 6+ years of experience in Python development\n  * Practical experience with production-grade Python\n  * Hands-on experience with Test Driven Development (TDD)\n  * Proven ability to build and scale large systems at high velocity\n  * Strong fundamentals in database schema design and data modeling\n  * Ability to work at a rapid pace without sacrificing clarity or correctness\n  * Experience in migrating legacy Python microservice code to Go microservices (specifically, large-scale migrations with millions of actions per day)\n  * Familiarity with instrumentation and monitoring of code for parity and consistency during rollout\n* **Preferred Qualifications:**\n  * Familiarity with LLM function calling protocols and paradigms\n* **Work Requirements:**\n  * Location: Pan India\n  * Work Mode: Remote\n  * Employment Type: Contract to hire\n  * Notice Period: Immediate joiners", "company": "People Prime Worldwide", "position": "Python Developer", "location": "India"}, "applied-ai-engineer-india-remote-at-wixjob-4270060681.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\applied-ai-engineer-india-remote-at-wixjob-4270060681.html", "link": "https://in.linkedin.com/jobs/view/applied-ai-engineer-india-remote-at-wixjob-4270060681?position=26&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=eOu8wSD2sd2Rl3aHR1TjSg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAs an Applied AI Engineer, you'll work at the intersection of machine learning research, product engineering, and customer success.\nAbout the Role\nYou\u2019ll be responsible for refining human datasets and transforming them into model-ready signals. You\u2019ll also translate real-world insights into product and infrastructure features that meaningfully improve the platform. In addition, you\u2019ll run tight feedback loops across the Ops and Engineering teams to ensure clients get the maximum value from Mercor by building tooling and prototypes.\nResponsibilities\nRefining human datasets and transforming them into model-ready signals.\nTranslating real-world insights into product and infrastructure features.\nRunning tight feedback loops across the Ops and Engineering teams.\nBuilding tooling and prototypes to maximize client value.\nQualifications\nPrevious founding or startup experience.\nRequired Skills\nFluency in React, Next.js, and Python.\nExperience designing schemas for SQL and NoSQL databases.\nExperience with Airflow or similar orchestration ETL tools.\nExperience deploying LLMs or other models in production, including evaluation pipelines.\nExperience with Systems Integration across recruitment systems, payments systems, CRMs, and data warehouses.\nInterest in evals, benchmarks, and annotation tooling.\nAttention to detail and eagerness to learn.\nPay range and compensation package\nBase cash comp from $40K-$100K.\nPerformance bonuses up to 40% of base comp.\n$1k referral bonuses available.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Eligible Applicants:**\n  * Founders or individuals with previous startup experience\n  * **Required Skills:**\n    + Fluency in:\n      - React\n      - Next.js\n      - Python\n    + Experience with:\n      - Designing schemas for SQL and NoSQL databases\n      - Airflow or similar ETL orchestration tools\n      - Deploying LLMs or other models in production (including evaluation pipelines)\n      - Systems Integration across:\n        - Recruitment systems\n        - Payments systems\n        - CRMs\n        - Data warehouses\n  * **Preferred Qualifications:**\n    + Interest in:\n      - Evals\n      - Benchmarks\n      - Annotation tooling\n    + Attention to detail and eagerness to learn", "company": "WixJob", "position": "Applied AI Engineer (India-Remote)", "location": "India"}, "machine-learning-researcher-at-ascendeum-4273411453.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\machine-learning-researcher-at-ascendeum-4273411453.html", "link": "https://in.linkedin.com/jobs/view/machine-learning-researcher-at-ascendeum-4273411453?position=27&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=LmZwG1fqwdl%2BR97%2FQ1TnnQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAscendeum is looking for mathematicians, with extensive hands-on experience in the field of data science, who can analyze large data sets efficiently to generate actionable business intelligence that drives peak performance for our clients.\nAbout Us:\nWe provide AdTech strategy consulting to leading internet websites and apps hosting over 200 million monthly audiences worldwide. Since 2015, our consultants and engineers have consistently delivered intelligent solutions that enable enterprise-level websites and apps to maximize their digital advertising returns.\nJob Responsibilities:\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data.\nAnalyze large amounts of information to discover trends and patterns\nHelping develop reports and analysis.\nPresent information using data visualisation techniques.\nAssessing tests, implementing new or upgraded software, and assisting with strategic decisions on new systems.\nEvaluating changes and updates to source production systems.\nDevelop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks.\nProviding technical expertise in data storage structures, data mining, and data cleansing.\nPropose solutions and strategies to business challenges\nDesired Skills and Experience:\nRelevant 2+ years of experience in Data Analysis\nComplete understanding of Operations Research, Data Modelling, ML, and AI concepts.\nKnowledge of Python is mandatory, familiarity with MySQL, SQL, Scala, Java or C++ is an asset\nExperience using visualization tools (e.g. Jupyter Notebook) and data frameworks (e.g. Hadoop)\nAnalytical mind and business acumen\nStrong math skills (e.g. statistics, algebra)\nProblem-solving aptitude\nExcellent communication and presentation skills.\nBachelor\u2019s / Master's Degree in Computer Science, Engineering, Data Science or other quantitative or relevant field is preferred\nThank you for your interest in joining Ascendeum.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** \n  * Bachelor's or Master's Degree in Computer Science, Engineering, Data Science, or a quantitative/relevant field (preferred)\n* **Experience:** \n  * 2+ years of experience in Data Analysis (required)\n  * Extensive hands-on experience in the field of data science (required)\n* **Skills:**\n  * Strong math skills (statistics, algebra)\n  * Python (mandatory)\n  * MySQL, SQL, Scala, Java, or C++ (asset)\n  * Data visualization tools (e.g., Jupyter Notebook)\n  * Data frameworks (e.g., Hadoop)\n  * Operations Research\n  * Data Modelling\n  * Machine Learning (ML)\n  * Artificial Intelligence (AI)\n  * Data storage structures\n  * Data mining\n  * Data cleansing\n* **Personal Qualities:**\n  * Analytical mind\n  * Business acumen\n  * Problem-solving aptitude\n  * Excellent communication and presentation skills", "company": "Ascendeum", "position": "Machine Learning Researcher", "location": "India"}, "python-react-developer-at-dexian-india-4272828738.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-react-developer-at-dexian-india-4272828738.html", "link": "https://in.linkedin.com/jobs/view/python-react-developer-at-dexian-india-4272828738?position=28&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=dC9CfHaY5ZgOjoOwUFHdyA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nOverview:\nDescription: Senior Full Stack Developer \nPosition Overview: We are seeking a highly skilled Full Stack Developer to join our dynamic team within Global Trading at ExxonMobil. The ideal candidate will possess a robust understanding of both front-end and back-end development, with a strong emphasis on creating and maintaining scalable, high-performance applications. This role requires a professional who can seamlessly integrate into our team, contributing to the development of innovative solutions that drive our trading operations.\nTo be eligible for this role, you must be able to demonstrate:\n \u2022 Strong communication and interpersonal skills\n \u2022 Ability to collaborate effectively with internal and external customers\n \u2022 Innovative and analytical thinking\n \u2022 Ability to manage workload under time pressure and changing priorities\n \u2022 Adaptability and willingness to learn new technologies and methodologies\n Required Skills and Qualifications:\n\u2022 Technical Proficiency:\n \u2022 Expert Front-end React Framework & Backend Python Experience\n \u2022 Proficient in front-end technologies such as HTML, CSS, Strong back-end development skills, or similar languages.\n \u2022 Proficient GIT, & CI/CD experience.\n \u2022 Develop and maintain web applications using modern frameworks and technologies\n \u2022 Help maintain code quality, organization, and automation\n \u2022 Experience with relational database management systems.\n \u2022 Familiarity with cloud services (AWS, Azure, or Google Cloud \u2013 Primarily Azure).\n \n \u2022 Industry Knowledge:\n \u2022 Experience in the oil and gas industry, particularly within trading operations, is highly desirable.\n \u2022 Understanding of market data, trading systems, and financial instruments related to oil and gas.\n \n Preferred Qualifications:\n \u2022 Certifications in relevant technologies or methodologies.\n \u2022 Proven experience in building, operating, and supporting robust and performant databases and data pipelines.\n \u2022 Experience with Databricks and Snowflake\n \u2022 Solid understanding of web performance optimization, security, and best practices\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Eligibility Criteria:**\n  * Strong communication and interpersonal skills\n  * Ability to collaborate with internal and external customers\n  * Innovative and analytical thinking\n  * Ability to manage workload under time pressure and changing priorities\n  * Adaptability and willingness to learn new technologies and methodologies\n\n* **Required Skills and Qualifications:**\n  * Expert Front-end React Framework & Backend Python Experience\n  * Proficient in front-end technologies such as HTML, CSS\n  * Strong back-end development skills\n  * Proficient in GIT and CI/CD\n  * Experience with relational database management systems\n  * Familiarity with cloud services (Primarily Azure)\n\n* **Preferred Qualifications and Skills:**\n  * Experience in the oil and gas industry, particularly within trading operations\n  * Understanding of market data, trading systems, and financial instruments related to oil and gas\n  * Certifications in relevant technologies or methodologies\n  * Experience with Databricks and Snowflake\n  * Solid understanding of web performance optimization, security, and best practices\n  * Proven experience in building, operating, and supporting robust and performant databases and data pipelines", "company": "Dexian India", "position": "Python React Developer", "location": "India"}, "python-full-stack-developer-at-altraize-4177184412.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-full-stack-developer-at-altraize-4177184412.html", "link": "https://in.linkedin.com/jobs/view/python-full-stack-developer-at-altraize-4177184412?position=29&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=LH6wtWu1DRm%2BmYCfBeg6tw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          THIS IS A FULLY REMOTE JOB\nHiring Fullstack Engineer with a strong focus on backend development to join our growing team. In this role, you will be responsible for designing, developing, and maintaining high-performance software applications. Your expertise in Python and JavaScript (JS) will be crucial in building scalable and reliable backend systems.\nRequired Skills\n3+ years of professional experience in Python\nStrong SQL expertise with hands-on experience in database design, optimization, and management.\n2+ years of experience with Nest JS or other backend frameworks.\nFamiliarity with AWS/GCP is a plus.\nAbility to work independently as well as collaboratively within a team.\nStrong problem-solving skills with a focus on delivering high-quality code.\nNice to Have :Familiarity with front-end technologies (React or Angular) is a plus.\nFamiliarity with Python for scripting data analysis is a plus.\nExcellent spoken and written English communication skills\nIdeal Candidate Profile\n3+ years of overall experience\nEager to learn and grow within the company, with a proactive approach to personal and professional development.\nReliable and consistent in delivering high-quality work.\nStrong communication skills and a collaborative mindset.\nSkills: code,python,software,communication skills,full stack development,javascript\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required:**\n  * 3+ years of professional experience in Python\n  * Strong SQL expertise with hands-on experience in database design, optimization, and management\n  * 2+ years of experience with Nest JS or other backend frameworks\n  * Ability to work independently and collaboratively\n  * Strong problem-solving skills with a focus on delivering high-quality code\n  * Excellent spoken and written English communication skills\n  * 3+ years of overall experience\n* **Preferred:**\n  * Familiarity with AWS/GCP\n  * Familiarity with front-end technologies (React or Angular)\n  * Familiarity with Python for scripting data analysis\n  * Eager to learn and grow within the company with a proactive approach to personal and professional development\n  * Reliable and consistent in delivering high-quality work\n  * Strong communication skills and a collaborative mindset", "company": "Altraize", "position": "Python Full Stack Developer", "location": "India"}, "front-end-developers-ai-training-remote-at-braintrust-4220208768.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\front-end-developers-ai-training-remote-at-braintrust-4220208768.html", "link": "https://in.linkedin.com/jobs/view/front-end-developers-ai-training-remote-at-braintrust-4220208768?position=30&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=S%2FIjr3Vv5CkgL5ojkcFj9Q%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nRequirements\n Swift, Python, Java, Go, Verilog, Javascript, C++, or C# coding experience required\nThis is a great opportunity to supplement your income while looking for longer or more full-time work, all while contributing to the development of new AI models using your domain expertise!\nOur client has hired over 1,000 Braintrust talent and intends to hire hundreds more!\nMany Braintrust coders earn over $12,000 per month!\nYou\u2019ll have the flexibility to work as much or as little as you choose - 20hrs/week is suggested, but not a limit. Start working in as little as 48 hours. Your final hourly rate will be chosen by Outlier AI and determined by your location.\nWhat to expect:\n If qualified, you\u2019ll be invited to complete a brief questionnaire that takes 3-5 minutes. If you successfully pass the questionnaire, you\u2019ll be approved and able to begin work ASAP.\nRequired qualifications:\nProficiency working one of the following languages: Swift, Python, Java, Go, Verilog, Javascript, C++, or C#\nComplete fluency in the English language is required. You should be able to describe code and abstract information in a clear way.\nPreferred qualifications:\nBachelor's and/or Master's degree in Computer Science or equivalent. Students are welcome.\nNote\n: Outlier AI is partnering with Remotasks for this opportunity\nWhat You\u2019ll Be Working On\nOur client has partnered with organizations to train AI large language models, helping cutting-edge generative AI models write better code. \nExample projects might include:\nEvaluating the quality of AI-generated code, including human-readable summaries of your rationale\nSolve coding problems, writing functional and efficient code\nOptimize code to run at maximum efficiency\nWriting robust test cases to confirm code works efficiently and effectively\nWriting human-readable summaries of coding problems\nWriting explanations of how code can solve problems and evaluate various solution approaches\nNo previous experience with AI necessary! \nYou will receive detailed instructions on what is expected of you after you complete the application and verification process.\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required qualifications:**\n  * Proficiency in one of the following programming languages: Swift, Python, Java, Go, Verilog, Javascript, C++, or C#\n  * Fluency in English, with the ability to clearly describe code and abstract information\n* **Preferred qualifications:**\n  * Bachelor's and/or Master's degree in Computer Science or equivalent\n  * Students are welcome to apply\n* **Required skills:**\n  * Coding and programming\n  * Problem-solving\n  * Code optimization\n  * Test case writing\n  * Code explanation and summarization\n* **No prior experience with AI is necessary.**", "company": "Braintrust", "position": "Front End Developers - AI Training [Remote]", "location": "India"}, "software-engineer-machine-learning-at-motive-4264402019.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-machine-learning-at-motive-4264402019.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-machine-learning-at-motive-4264402019?position=31&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=ljEeL7SqD2R%2FpK8eFBjcGQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWho We Are\nMotive empowers the people who run physical operations with tools to make their work safer, more productive, and more profitable. For the first time ever, safety, operations and finance teams can manage their drivers, vehicles, equipment, and fleet related spend in a single system. Combined with industry leading AI, the Motive platform gives you complete visibility and control, and significantly reduces manual workloads by automating and simplifying tasks.\nMotive serves more than 100,000 customers \u2013 from Fortune 500 enterprises to small businesses \u2013 across a wide range of industries, including transportation and logistics, construction, energy, field service, manufacturing, agriculture, food and beverage, retail, and the public sector.\nVisit gomotive.com to learn more.\nAbout The Role\nAs a Software engineer - Machine Learning, you will be a part of a passionate team whose mission is to bring intelligence to the world\u2019s trucks. The team is focused on building technology to understand driving behavior, identify risk factors, and intelligently suggest coachable events that not only improve the fleet safety and potentially save millions of dollars but also contribute to making the roads safer. You will have a unique opportunity to work with a high-caliber and fast-paced team which consists of experienced researchers and engineers in Computer Vision, Machine Learning, Deep Learning, and Robotics with a track record of previous products and top-tier publications.\nYou will play a critical role in building and improving a technology that will be used by millions of trucks. In this role, you will design and implement complex machine-learning systems. You will have the opportunity to build and/or improve ML/computer vision systems. Identify where models and algorithms are failing, debug issues, propose solutions, implement, and deploy them on millions of trucks. You will also get exposure to large-scale ML infra and scaling that facilitates large amounts of data to train, test, and validate computer vision systems.\nWhat You\u2019ll Do\nEvaluate and improve the performance of existing models and algorithms already in production\nPrototype and implement ML modules for complex AI features\nBuild and optimize CV/ML algorithms for real-time performance so they can run on our embedded platform, i.e., the next-gen AI dashcam\nWrite proficient Python and C++ code to build and improve CV algorithms, ML services, training, model compression, and porting pipelines\nCollaborate with cross-functional teams such as Embedded, Backend, Frontend, Hardware, QA, and the broader AI team to ensure the development of robust and sustainable AI systems\nBuild automated deployment, validation, and active learning pipelines.\nWhat We\u2019re Looking For\nBachelor\u2019s Degree in Computer Science, Electrical Engineering, or related field. A Master\u2019s degree is a plus. \n5+ years of machine learning and/or data science experience\nSolid mathematical foundation in Deep Learning, Machine Learning, and optimization approaches.\nStrong experience in Python or C++\nExperience in the following tools and technologies is a plus. AWS (SageMaker, Lambda, EC2, S3, RDS), CI/CD, Terraform, Docker, and Kubernetes.\nPrior experience with optimizing and deploying ML models on embedded devices is a strong plus\nCreating a diverse and inclusive workplace is one of Motive's core values. We are an equal opportunity employer and welcome people of different backgrounds, experiences, abilities and perspectives. \nPlease review our Candidate Privacy Notice here .\nUK Candidate Privacy Notice here.\nThe applicant must be authorized to receive and access those commodities and technologies controlled under U.S. Export Administration Regulations. It is Motive's policy to require that employees be authorized to receive access to Motive products and technology.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:**\n  * Bachelor's Degree in Computer Science, Electrical Engineering, or related field\n  * Master's degree preferred\n* **Experience:**\n  * 5+ years of machine learning and/or data science experience\n  * Experience with optimizing and deploying ML models on embedded devices is a strong plus\n* **Technical Skills:**\n  * Solid mathematical foundation in Deep Learning, Machine Learning, and optimization approaches\n  * Strong experience in Python or C++\n  * Experience with the following tools and technologies is a plus:\n    * AWS (SageMaker, Lambda, EC2, S3, RDS)\n    * CI/CD\n    * Terraform\n    * Docker\n    * Kubernetes\n* **Authorization:**\n  * Authorized to receive and access commodities and technologies controlled under U.S. Export Administration Regulations", "company": "Motive", "position": "Software Engineer, Machine Learning", "location": "India"}, "software-engineer-machine-learning-at-motive-4268347933.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-machine-learning-at-motive-4268347933.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-machine-learning-at-motive-4268347933?position=32&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=hpF5ov3WODj9fv05%2B1xabA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nWho We Are\nMotive empowers the people who run physical operations with tools to make their work safer, more productive, and more profitable. For the first time ever, safety, operations and finance teams can manage their drivers, vehicles, equipment, and fleet related spend in a single system. Combined with industry leading AI, the Motive platform gives you complete visibility and control, and significantly reduces manual workloads by automating and simplifying tasks.\nMotive serves more than 100,000 customers \u2013 from Fortune 500 enterprises to small businesses \u2013 across a wide range of industries, including transportation and logistics, construction, energy, field service, manufacturing, agriculture, food and beverage, retail, and the public sector.\nVisit gomotive.com to learn more.\nAbout The Role\nAs a Software engineer - Machine Learning, you will be a part of a passionate team whose mission is to bring intelligence to the world\u2019s trucks. The team is focused on building technology to understand driving behavior, identify risk factors, and intelligently suggest coachable events that not only improve the fleet safety and potentially save millions of dollars but also contribute to making the roads safer. You will have a unique opportunity to work with a high-caliber and fast-paced team which consists of experienced researchers and engineers in Computer Vision, Machine Learning, Deep Learning, and Robotics with a track record of previous products and top-tier publications.\nYou will play a critical role in building and improving a technology that will be used by millions of trucks. In this role, you will design and implement complex machine-learning systems. You will have the opportunity to build and/or improve ML/computer vision systems. Identify where models and algorithms are failing, debug issues, propose solutions, implement, and deploy them on millions of trucks. You will also get exposure to large-scale ML infra and scaling that facilitates large amounts of data to train, test, and validate computer vision systems.\nWhat You\u2019ll Do\nEvaluate and improve the performance of existing models and algorithms already in production\nPrototype and implement ML modules for complex AI features\nBuild and optimize CV/ML algorithms for real-time performance so they can run on our embedded platform, i.e., the next-gen AI dashcam\nWrite proficient Python and C++ code to build and improve CV algorithms, ML services, training, model compression, and porting pipelines\nCollaborate with cross-functional teams such as Embedded, Backend, Frontend, Hardware, QA, and the broader AI team to ensure the development of robust and sustainable AI systems\nBuild automated deployment, validation, and active learning pipelines.\nWhat We\u2019re Looking For\nBachelor\u2019s Degree in Computer Science, Electrical Engineering, or related field. A Master\u2019s degree is a plus. \n5+ years of machine learning and/or data science experience\nSolid mathematical foundation in Deep Learning, Machine Learning, and optimization approaches.\nStrong experience in Python or C++\nExperience in the following tools and technologies is a plus. AWS (SageMaker, Lambda, EC2, S3, RDS), CI/CD, Terraform, Docker, and Kubernetes.\nPrior experience with optimizing and deploying ML models on embedded devices is a strong plus\nCreating a diverse and inclusive workplace is one of Motive's core values. We are an equal opportunity employer and welcome people of different backgrounds, experiences, abilities and perspectives. \nPlease review our Candidate Privacy Notice here .\nUK Candidate Privacy Notice here.\nThe applicant must be authorized to receive and access those commodities and technologies controlled under U.S. Export Administration Regulations. It is Motive's policy to require that employees be authorized to receive access to Motive products and technology.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:**\n  * Bachelor's Degree in Computer Science, Electrical Engineering, or related field\n  * Master's degree preferred\n* **Experience:**\n  * 5+ years of machine learning and/or data science experience\n  * Experience with optimizing and deploying ML models on embedded devices is a strong plus\n* **Technical Skills:**\n  * Solid mathematical foundation in Deep Learning, Machine Learning, and optimization approaches\n  * Strong experience in Python or C++\n  * Experience with the following tools and technologies is a plus:\n    * AWS (SageMaker, Lambda, EC2, S3, RDS)\n    * CI/CD\n    * Terraform\n    * Docker\n    * Kubernetes\n* **Authorization:**\n  * Authorized to receive and access commodities and technologies controlled under U.S. Export Administration Regulations", "company": "Motive", "position": "Software Engineer - Machine Learning", "location": "India"}, "python-fullstack-developer-at-awign-4271810088.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\python-fullstack-developer-at-awign-4271810088.html", "link": "https://in.linkedin.com/jobs/view/python-fullstack-developer-at-awign-4271810088?position=33&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=2khJMbi2KjaJ3DZs78Vk1Q%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nTitle: React Fullstack Developer\nLocation: Bangalore, Hyderabad (Hybrid)\nTimings: Full Time (As per company timings)\nShift Timings: 5.30 AM IST to 2.30 PM IST\nNotice Period : (Immediate Joiner - Only)\nKey Responsibilities\n\u00d8  Architect and build responsive and performant UIs using ReactJS, TypeScript/JavaScript\n\u00d8  Design and implement component-based architectures using Redux, Context API, or React Query\n\u00d8  Collaborate closely with design and product teams to translate wireframes and mockups into high-quality code\n\u00d8  Implement frontend testing strategies using Jest, React Testing Library, or similar\n\u00d8  Optimize applications for speed, accessibility, and cross-browser compatibility\n\u00d8  Design, build, and maintain RESTful APIs and/or GraphQL endpoints using Django, Flask, or FastAPI\n\u00d8  Develop scalable backend services with focus on modularity, reusability, and testability\n\u00d8  Manage integrations with third-party APIs, services, and databases (PostgreSQL, MySQL, MongoDB)\n\u00d8  Implement authentication and authorization frameworks (OAuth2, JWT, etc.)\n\u00d8  Monitor and enhance application performance and scalability\n\u00d8  Contribute to sprint planning, backlog grooming, and retrospectives\n\u00d8  Maintain technical documentation for internal and external consumption\n \nRequired Qualifications\n\u00d8  6+ years of hands-on experience in full-stack development, with strong focus on ReactJS and Python\n\u00d8  Expertise in building and consuming RESTful APIs\n\u00d8  Solid experience in ReactJS, Redux/Context API, Hooks, and functional components\n\u00d8  Proficiency with Python web frameworks like Flask, FastAPI, or Django\n\u00d8  Strong understanding of relational and non-relational databases (e.g., PostgreSQL, MySQL, MongoDB)\n\u00d8  Good experience with Docker, Git, and modern CI/CD workflows\n\u00d8  Familiarity with system design, microservices, caching strategies, and asynchronous processing\n\u00d8  Excellent communication and leadership skills\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Experience:** 6+ years of hands-on experience in full-stack development\n* **Technical Skills:**\n  * ReactJS, Redux/Context API, Hooks, and functional components\n  * Python web frameworks (Flask, FastAPI, or Django)\n  * RESTful APIs\n  * Relational and non-relational databases (PostgreSQL, MySQL, MongoDB)\n  * Docker, Git, and modern CI/CD workflows\n* **Knowledge:**\n  * System design\n  * Microservices\n  * Caching strategies\n  * Asynchronous processing\n* **Soft Skills:**\n  * Excellent communication skills\n  * Leadership skills\n* **Preferred/Implicit:**\n  * Experience with TypeScript/JavaScript\n  * Familiarity with GraphQL\n  * Knowledge of authentication and authorization frameworks (OAuth2, JWT, etc.) \n  * Experience with Jest, React Testing Library, or similar testing frameworks", "company": "Awign", "position": "Python Fullstack Developer", "location": "Bangalore North Rural, Karnataka, India"}, "ai-growth-hacker-%E2%80%93-smb-client-acquisition-at-bayinfotech-4277224294.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\ai-growth-hacker-%E2%80%93-smb-client-acquisition-at-bayinfotech-4277224294.html", "link": "https://in.linkedin.com/jobs/view/ai-growth-hacker-%E2%80%93-smb-client-acquisition-at-bayinfotech-4277224294?position=34&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=nhfvzRIMJHphZ%2FklvBq3Kw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nMission\n Win a steady stream of small- and medium-sized businesses that need \nbespoke\n AI chatbots or workflow automations\u2014then turn them into long-term, high-value clients.\nWhat You\u2019ll Do\nPinpoint ideal clients\n \u2013 Identify industries and pain points where a custom bot or automation delivers quick ROI; scrape and enrich prospect lists.\nSpark interest fast\n \u2013 Run low-cost, high-impact campaigns (personalized LinkedIn DMs, quick demo videos, micro-tools on Product Hunt/AppSumo) that showcase our \nservice\n capabilities.\nConvert & onboard\n \u2013 Build one-page landing sites, targeted email sequences, and 30-minute consultation offers that move prospects to signed SOWs.\nShow value early\n \u2013 Package \u201cpilot\u201d deliverables (e.g., single FAQ bot or one automated Zap) that prove ROI in 2\u20134 weeks and open upsell doors.\nAutomate your own funnel\n \u2013 Use ChatGPT prompts, Zapier/Make, Clay, Phantombuster, and basic JS/Python snippets to research, personalize outreach, and report on results.\nTrack & optimize\n \u2013 Own dashboards for leads, conversion rates, CAC, and revenue; kill or scale experiments every sprint.\nMust-Haves\n3+ yrs driving growth or demand-gen for B2B tech or agency services\u2014especially project-based or consultative offerings.\nComfortable with SaaS/growth stack (HubSpot/Apollo/Clearbit, Webflow, GA4, LinkedIn Sales Nav).\nHands-on with no-code/low-code automation tools and can tweak basic JavaScript/Python when needed.\nPortfolio of campaigns that generated $500k+ in service revenue from SMBs.\nData-obsessed, experiment-driven, and scrappy.\nPerks\n Remote-first, performance bonuses tied to booked revenue, budget for favorite growth tools, and a front-row seat building BayInfotech\u2019s AI consultancy from the ground up.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Experience:**\n  * 3+ years in growth or demand generation for B2B tech or agency services\n  * Experience with project-based or consultative offerings\n* **Skills:**\n  * SaaS/growth stack (HubSpot/Apollo/Clearbit, Webflow, GA4, LinkedIn Sales Nav)\n  * No-code/low-code automation tools\n  * Basic JavaScript/Python\n* **Portfolio:**\n  * Proven track record with campaigns generating $500k+ in service revenue from SMBs\n* **Personal Qualities:**\n  * Data-obsessed\n  * Experiment-driven\n  * Scrappy\n* **Preferred Qualifications:**\n  * Familiarity with AI chatbots and workflow automations\n  * Experience with tools like ChatGPT, Zapier/Make, Clay, Phantombuster", "company": "BayInfotech", "position": "AI Growth Hacker \u2013 SMB Client Acquisition", "location": "India"}, "senior-machine-learning-engineer-at-goml-4273601599.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\senior-machine-learning-engineer-at-goml-4273601599.html", "link": "https://in.linkedin.com/jobs/view/senior-machine-learning-engineer-at-goml-4273601599?position=35&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=6fo8HffdUIBrh17mEiiLxw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nLooking for a culture to thrive & build a rewarding career for yourself, join the core team of young hustlers building the next generation of Machine Learning platform & services. You will develop training and deployment pipelines for machine learning, implement model compression algorithms, and productionize machine learning research solving challenging business problems.\nKey Responsibilities:\nDesign and develop generative AI models using techniques like RAG, transformers, and other relevant approaches.\nFine-tune pre-trained LLMs for specific tasks and domains.\nConduct research on new techniques for improving the performance and capabilities of generative AI models.\nApply software engineering rigor and best practices to machine learning /Generative AI pipelines.\nEvaluate and analyse the performance of ML/generative AI models.\nStay up to date on the latest advancements in generative AI research.\nFacilitate the development and deployment of proof-of-concept Generative AI systems.\nQualifications:\nBachelor\u2019s/Master\u2019s degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n5+ years of experience in generative AI or related fields.\nExperience in building data pipelines, deploying ML/GenAI models in production, and monitoring and maintaining their performance.\nStrong programming skills in Python.\nFamiliarity with RAG and other techniques for building generative models.\nExtensive experience with Git, Docker and a good understanding of Linux for managing servers.\nExperience with cloud-based ecosystems, especially AWS ML/GenAI services.\nExposure to ML/GenAI frameworks and tools.\nExcellent communication and collaboration skills.\nAbility to work independently and in a team-oriented environment.\nMethodical and meticulous towards work and planning.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** \n  * Bachelor\u2019s degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n  * Master\u2019s degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field (preferred).\n* **Experience:**\n  * 5+ years of experience in generative AI or related fields.\n  * Experience in building data pipelines, deploying ML/GenAI models in production, and monitoring and maintaining their performance.\n* **Technical Skills:**\n  * Strong programming skills in Python.\n  * Familiarity with RAG and other techniques for building generative models.\n  * Extensive experience with Git and Docker.\n  * Good understanding of Linux for managing servers.\n  * Experience with cloud-based ecosystems, especially AWS ML/GenAI services.\n  * Exposure to ML/GenAI frameworks and tools.\n* **Soft Skills:**\n  * Excellent communication and collaboration skills.\n  * Ability to work independently and in a team-oriented environment.\n  * Methodical and meticulous towards work and planning.", "company": "goML", "position": "Senior Machine Learning Engineer", "location": "India"}, "data-scientist-i-at-agco-corporation-4205966935.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-scientist-i-at-agco-corporation-4205966935.html", "link": "https://in.linkedin.com/jobs/view/data-scientist-i-at-agco-corporation-4205966935?position=36&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=wwA9emZh2gi5%2FJBrQhZe3w%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          Do you want to help solve the world's most pressing challenges? Feeding the world's growing population and slowing climate change are two of the world's greatest challenges. AGCO is a part of the solution! Join us to make your contribution.\nAGCO is looking to hire candidates for the position of Data Scientist l. This position is responsible for the development and execution of data science and analytics use cases at AGCO. The Data Scientist executes the research, modeling design, implementation, and supports the deployment of full-stack scalable AI solutions to critical business opportunities.\n\u202f\nYour Impact \nInsight Identification: Collaborate with the AI Delivery Owner and key business stakeholders to identify and prioritize actionable and impactful insights across various core business areas, driving informed decision-making. \nMethodology Selection: Determine the most appropriate AI/ML techniques for addressing different classes of business problems and assess the feasibility of analytics use cases through proof-of-concept (POC) studies. \nOpportunity Translation: Translate business opportunities, needs, or hypotheses from partners into actionable tasks, effectively converting business requirements into mathematical and computational steps to deliver insights. \nSolution Development: Develop analytics solutions that align with business goals, ensuring statistical integrity and implementing accuracy tracking and lifecycle management techniques. \nChange Advocacy: Act as a change agent by engaging with business stakeholders and the data science community to educate, raise awareness, and build support for world-class data and analytics practices. \nYour Experience And Qualifications\nBachelor\u2019s degree with 4+ years of overall IT experience \n3+ years in Advanced analytics tools (Python, R, SAS, SQL etc.) to carry out statistical and machine learning analysis. \nUse big data computing frameworks for processing of large data volumes (AWS Sagemaker, EMR, Databricks and other) \nFamiliar with cloud technologies for model development and deployment. \nYour Benefits\nGLOBAL DIVERSITY \u2013 Diversity means many things to us, different brands, cultures, nationalities, genders, generations \u2013 even variety in our roles. You make us unique!\n\u202f\nENTERPRISING SPIRIT- Every role adds value. We're committed to helping you develop and grow to realize your potential.\n\u202f\nPOSITIVE IMPACT \u2013 Make it personal and help us feed the world.\n\u202f\nINNOVATIVE TECHNOLOGIES - You can combine your love for technology with manufacturing excellence \u2013 and work alongside teams of people worldwide who share your enthusiasm.\n\u202f\nMAKE THE MOST OF YOU \u2013 Benefits include health care and wellness plans and flexible and virtual work option\u2026\u2026\u2026.\nYour Workplace\nWe value inclusion and recognize the innovation a diverse workforce delivers to our farmers. Through our recruitment efforts, we are committed to building a team that includes a variety of experiences, backgrounds, cultures and perspectives.\nJoin us as we bring agriculture into the future and apply now! \nPlease note that this job posting is not designed to cover or contain a comprehensive listing of all required activities, duties, responsibilities, or benefits and may change at any time with or without notice.\n\u202f\nAGCO is proud to be an Equal Opportunity Employer\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** Bachelor\u2019s degree\n* **Experience:**\n  * 4+ years of overall IT experience\n  * 3+ years in advanced analytics tools (Python, R, SAS, SQL, etc.)\n* **Technical Skills:**\n  * Advanced analytics tools (Python, R, SAS, SQL, etc.)\n  * Big data computing frameworks (AWS Sagemaker, EMR, Databricks, etc.)\n  * Cloud technologies for model development and deployment\n* **No specific certifications or programming languages are mentioned as requirements beyond those listed.**", "company": "AGCO Corporation", "position": "Data Scientist I", "location": "Pune, Maharashtra, India"}, "quality-assurance-automation-engineer-at-recro-4263348668.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\quality-assurance-automation-engineer-at-recro-4263348668.html", "link": "https://in.linkedin.com/jobs/view/quality-assurance-automation-engineer-at-recro-4263348668?position=37&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=0wDRY33bh8LaUK8pVVEo%2BA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \n!! FOR IMMEDIATE JOINERS AND THOSE SERVING NOTICE ONLY !! (Won't be of any use to you if you still apply.)\nLocation: Noida (Remote)\nExperience: 3+ yrs of full time\nNotice Period: IMMEDIATE JOINERS ONLY\nRequirement\n:\nWe are looking for a QA Automation Engineer with expertise and hands-on experience with \nUI Testing and API Testing.\nExpertise in \nJava, Javascript, Selenium, Rest Assured, TestNG,\n etc\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* Eligibility:\n  * Experience: 3+ years of full-time experience\n  * Technical skills:\n    * Java\n    * JavaScript\n    * Selenium\n    * Rest Assured\n    * TestNG\n  * Testing expertise:\n    * UI Testing\n    * API Testing\n  * Notice period: Immediate joiners only (or those serving notice)\n  * Location: Noida (remote work option)", "company": "Recro", "position": "Quality Assurance Automation Engineer", "location": "Noida, Uttar Pradesh, India"}, "swift-coders-ai-training-remote-at-braintrust-4233232867.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\swift-coders-ai-training-remote-at-braintrust-4233232867.html", "link": "https://in.linkedin.com/jobs/view/swift-coders-ai-training-remote-at-braintrust-4233232867?position=38&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=7UCHedH8oDZvZ0XpzXj58w%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \n* Swift, Python, Java, Go, Verilog, Typescript, Javascript, C++, or C# coding experience required\nThis is a great opportunity to supplement your income while looking for longer or more full-time work, all while contributing to the development of new AI models using your domain expertise!\nOur client has hired over 1,000 Braintrust talent and intends to hire hundreds more!\nMany Braintrust coders earn over $12,000 per month!\nYou\u2019ll have the flexibility to work as much or as little as you choose - 20hrs/week is suggested, but not a limit. Start working in as little as 48 hours. Your final hourly rate will be chosen by Outlier AI and determined by your location.\nWhat to expect:\n If qualified, you\u2019ll be invited to complete a brief questionnaire that takes 3-5 minutes. If you successfully pass the questionnaire, you\u2019ll be approved and able to begin work ASAP.\nRequired qualifications:\nProficiency working one of the following languages: Swift, Python, Java, Go, Verilog, Typescript, Javascript, C++, or C#\nComplete fluency in the English language is required. You should be able to describe code and abstract information in a clear way.\nPreferred qualifications:\nBachelor's and/or Master's degree in Computer Science or equivalent. Students are welcome.\nNote\n: Outlier AI is partnering with Remotasks for this opportunity\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required qualifications:**\n  * Proficiency in one of the following programming languages: Swift, Python, Java, Go, Verilog, Typescript, Javascript, C++, or C#\n  * Fluency in English, with the ability to clearly describe code and abstract information\n* **Preferred qualifications:**\n  * Bachelor's and/or Master's degree in Computer Science or equivalent\n  * Students are welcome to apply\n* **No specific experience or work hours required**, but 20hrs/week suggested.", "company": "Braintrust", "position": "Swift Coders - AI Training [Remote]", "location": "India"}, "backend-developer-java-python-at-weekday-ai-yc-w21-4276678579.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\backend-developer-java-python-at-weekday-ai-yc-w21-4276678579.html", "link": "https://in.linkedin.com/jobs/view/backend-developer-java-python-at-weekday-ai-yc-w21-4276678579?position=39&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=aSgxa%2BeK1i%2FlcyHQZq2IQA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nThis role is for one of the Weekday's clients\nMin Experience: 3 years\nLocation: Remote (India), Bengaluru\nJobType: full-time\nWe are seeking a talented \nBackend Developer\n with strong expertise in \nPython\n and \nJava\n to join our engineering team. This role involves developing scalable backend services, integration solutions, and AI-driven features that power intelligent applications.\nRequirements\nKey Responsibilities:\n Design, develop, and maintain robust backend systems using Java and Python. \n Build and improve integration frameworks for cloud-based and on-premise environments. \n Develop optimized RESTful APIs and backend logic to support scalable systems. \n Work collaboratively in Agile teams alongside product managers, QA engineers, and developers. \n Review code, ensure best practices, and mentor junior team members. \n Investigate and resolve production issues to maintain system reliability. \n Develop autonomous AI agents with intelligent decision-making capabilities. \n Integrate large language models (LLMs) to enhance application intelligence and user experiences. \nRequired Skills & Qualifications:\n 3 to 5 years of professional experience with Java and Python in backend development. \n Strong knowledge of object-oriented programming (OOP) and design patterns. \n Experience building RESTful APIs and working with microservices architectures. \n Familiarity with multithreading, concurrency, and system performance optimization. \n Exposure to cloud platforms such as AWS or Microsoft Azure is an advantage. \n Proficient with tools like Git, Maven, Jenkins, and Docker. \n Hands-on experience with LLM frameworks like LangChain or LangGraph is preferred. \n Strong analytical thinking and debugging skills. \n Excellent verbal and written communication skills with a collaborative mindset.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Experience:** \n  * Minimum 3 years\n  * Maximum 5 years\n* **Technical Skills:**\n  * Java\n  * Python\n  * Object-oriented programming (OOP)\n  * Design patterns\n  * RESTful APIs\n  * Microservices architectures\n  * Multithreading\n  * Concurrency\n  * System performance optimization\n  * Git\n  * Maven\n  * Jenkins\n  * Docker\n  * LLM frameworks (LangChain or LangGraph) - preferred\n* **Cloud Platforms:**\n  * AWS or Microsoft Azure - advantage\n* **Soft Skills:**\n  * Strong analytical thinking\n  * Debugging skills\n  * Excellent verbal and written communication\n  * Collaborative mindset", "company": "Weekday AI (YC W21)", "position": "Backend Developer (Java & Python)", "location": "Bengaluru, Karnataka, India"}, "swift-coders-ai-training-remote-hindi-speakers-encouraged-at-braintrust-4233242911.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\swift-coders-ai-training-remote-hindi-speakers-encouraged-at-braintrust-4233242911.html", "link": "https://in.linkedin.com/jobs/view/swift-coders-ai-training-remote-hindi-speakers-encouraged-at-braintrust-4233242911?position=40&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=2NTBdjbc7719hScMvzVSDg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \n* Swift, Python, Java, Go, Verilog, Typescript, Javascript, C++, or C# coding experience required\nThis is a great opportunity to supplement your income while looking for longer or more full-time work, all while contributing to the development of new AI models using your domain expertise!\nOur client has hired over 1,000 Braintrust talent and intends to hire hundreds more!\nMany Braintrust coders earn over $12,000 per month!\nYou\u2019ll have the flexibility to work as much or as little as you choose - 20hrs/week is suggested, but not a limit. Start working in as little as 48 hours. Your final hourly rate will be chosen by Outlier AI and determined by your location.\nWhat to expect:\n If qualified, you\u2019ll be invited to complete a brief questionnaire that takes 3-5 minutes. If you successfully pass the questionnaire, you\u2019ll be approved and able to begin work ASAP.\nRequired qualifications:\nProficiency working one of the following languages: Swift, Python, Java, Go, Verilog, Typescript, Javascript, C++, or C#\nComplete fluency in the English language is required. You should be able to describe code and abstract information in a clear way.\nPreferred qualifications:\nBachelor's and/or Master's degree in Computer Science or equivalent. Students are welcome.\nNote\n: Outlier AI is partnering with Remotasks for this opportunity\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required qualifications:**\n  * Proficiency in one of the following programming languages: Swift, Python, Java, Go, Verilog, Typescript, Javascript, C++, or C#\n  * Fluency in English, with the ability to clearly describe code and abstract information\n* **Preferred qualifications:**\n  * Bachelor's and/or Master's degree in Computer Science or equivalent\n  * Students are welcome to apply\n* **No specific experience or work hours required**, but 20hrs/week suggested.", "company": "Braintrust", "position": "Swift Coders - AI Training [Remote] (Hindi Speakers Encouraged)", "location": "India"}, "senior-python-software-engineer-voice-ai-at-checkmate-4267059360.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\senior-python-software-engineer-voice-ai-at-checkmate-4267059360.html", "link": "https://in.linkedin.com/jobs/view/senior-python-software-engineer-voice-ai-at-checkmate-4267059360?position=41&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=4RNeBAndYxa6H7ZT1Yq%2BmQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          This role offers the opportunity to create new products from the ground up, significantly influence product direction and the engineering roadmap, participate in building our voice team culture, and ultimately shape the future of restaurant technology. Your efforts will enhance customer interactions, ensuring a seamless and enjoyable experience.\nRequirements\nBackend Development: Design, implement, and maintain scalable backend systems to support real-time audio processing and streaming\nAudio Systems Engineering: Develop and optimize real-time audio pipelines for voice interaction, integrating algorithms for speech enhancement, noise reduction, and multi-channel processing\nPython Development: Write efficient, maintainable Python code for backend services, real-time audio processing tools, and system integrations\nCollaborative Problem-Solving: Work with cross-functional teams, including AI/ML engineers and product managers, to ensure seamless integration of audio and backend systems\nCode Excellence: Write clean, maintainable code, debug issues efficiently, and optimize for performance and reliability\nInnovation: Explore and implement cutting-edge technologies in audio processing and backend engineering to future-proof our systems\nBenefits\nBachelor's degree or higher in software engineering or other relevant education with 5+ years of industry experience in computer science or engineering\nExperience with real-time streaming protocols, multi-threaded programming, and performance optimization, particularly in audio applications is a plus\nExperience with implementing and optimizing DSP algorithms such as filtering, echo cancellation, voice activity detection, source separation, and noise suppression for real-time audio systems\nExperience with developing building backend systems and integrations in Python\nPassion for exploring emerging technologies and applying them to solve real-world problems\nGood problem-solving skills and ability to work independently and in a team\nStrong communication skills for explaining technical ideas to various audiences\nUnderstanding of conversational English and experience with voice programs/products\nAvailability to work during US hours at least till 5 pm ET is essential for this role\nCandidates must have their own system/work setup for remote work\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** Bachelor's degree or higher in software engineering or other relevant field (computer science or engineering)\n* **Experience:**\n  * 5+ years of industry experience in computer science or engineering\n  * Experience with:\n    * Real-time streaming protocols\n    * Multi-threaded programming\n    * Performance optimization (particularly in audio applications)\n    * Implementing and optimizing DSP algorithms (filtering, echo cancellation, voice activity detection, source separation, and noise suppression)\n    * Developing backend systems and integrations in Python\n* **Skills:**\n  * Backend development (scalable systems for real-time audio processing and streaming)\n  * Audio systems engineering (real-time audio pipelines, speech enhancement, noise reduction, multi-channel processing)\n  * Python development (efficient, maintainable code for backend services and system integrations)\n  * Collaborative problem-solving\n  * Code excellence (clean, maintainable code, debugging, optimization)\n  * Innovation (exploring and implementing cutting-edge technologies)\n* **Soft Skills:**\n  * Good problem-solving skills\n  * Ability to work independently and in a team\n  * Strong communication skills (explaining technical ideas to various audiences)\n* **Other Requirements:**\n  * Passion for exploring emerging technologies and applying them to solve real-world problems\n  * Understanding of conversational English and experience with voice programs/products\n  * Availability to work during US hours (at least till 5 pm ET)\n  * Own system/work setup for remote work", "company": "Checkmate", "position": "Senior Python Software Engineer (Voice AI)", "location": "India"}, "software-engineer-at-itco-solutions-inc-4271759645.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-at-itco-solutions-inc-4271759645.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-at-itco-solutions-inc-4271759645?position=42&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=PvyCC4OcZ3b717kGLdfR%2Bw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nSoftware Engineer \u2013 Debugging-related tools.\n100% Remote\nWho You Are:\n* Play a critical role in cutting-edge technologies in areas of debuggers, memory sanitizers and compilers at Cisco\n* Shape the company's software development methodologies and processes, as well as actively involved in the open source communities.\n* Have a genuine interest in debugging and compiler technologies, hardware, operating and networking systems, with a keen eye for detail and a passion for quality and a drive to improve Cisco software development tools and processes.\n \nMinimum Qualifications\n* BS degree, 2+ years of related experience, or MS degree in Computer Science or Computer Engineering\n* Strong Python and C/C++ coding skills in a Linux environment\n* Knowledge of WEB frontend and backend programming\n* Experience with Jenkins, MySQL, Bash, and Git/Gerrit\n* Understanding of the internals of core files.\n* Experience with build systems, linkers, debuggers, and compilers.\n* Strong problem-solving and software development/troubleshooting skills\n* Strong self-motivation for solving problems and innovating with a genuine intent to improve the customer experience\n* Ability to work independently and as part of a team in a fast-paced, dynamic environment\n \nPreferred Qualifications\n* Contributions to GDB, LLDB, or other open source debugger and build projects\n* Knowledgeable on state-of-the-art developer and productivity tools\n* Experience with machine learning frameworks\n* Knowledge of ELF object file format and DWARF debug information representation.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:**\n  * BS degree in Computer Science or Computer Engineering with 2+ years of related experience\n  * MS degree in Computer Science or Computer Engineering (no experience requirement mentioned)\n* **Technical Skills:**\n  * Strong Python and C/C++ coding skills in a Linux environment\n  * WEB frontend and backend programming\n  * Jenkins, MySQL, Bash, and Git/Gerrit\n  * Build systems, linkers, debuggers, and compilers\n  * Understanding of core files and ELF object file format and DWARF debug information representation\n* **Experience:**\n  * 2+ years of related experience (with BS degree)\n  * Experience with debuggers, memory sanitizers, and compilers\n  * Experience with machine learning frameworks (preferred)\n* **Personal Qualities:**\n  * Strong problem-solving and software development/troubleshooting skills\n  * Strong self-motivation for solving problems and innovating\n  * Ability to work independently and as part of a team in a fast-paced, dynamic environment\n* **Open Source Contributions:**\n  * Contributions to GDB, LLDB, or other open source debugger and build projects (preferred)", "company": "ITCO Solutions, Inc.", "position": "Software Engineer", "location": "India"}, "backend-developer-python-intern-at-shiryam-technologies-4257190806.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\backend-developer-python-intern-at-shiryam-technologies-4257190806.html", "link": "https://in.linkedin.com/jobs/view/backend-developer-python-intern-at-shiryam-technologies-4257190806?position=43&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=MQbCFGpGRXJyPxIS61Sb3g%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          We are looking for a Python Web Developer Intern responsible for managing the interchange of data between the server and the users. Your primary focus will be the development of all server-side logic, ensuring high performance and responsiveness to requests from the front-end.\nPerks Of Working With Us\nCompetitive stipend\nRemote option available\nCertificate and Letter of recommendation\nSlack/Asana focussed environment\nCool managers\nMeme focussed communication\nOpportunity to convert to work full-time\nSkills\nIn-depth knowledge in Python, with knowledge of at least one Python web framework \nFamiliarity with some ORM (Object Relational Mapper) libraries\nAble to integrate multiple data sources and databases into one system\nGood understanding of server-side templating languages\nBasic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3\nUnderstanding of accessibility and security compliance\nStrong analytical skills and problem solving aptitude\nAttentive to details\nAvailable for 6 months\nSkills:- Django and Flask\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education**: Not explicitly stated, but implied to be currently enrolled in a relevant program or recent graduate.\n* **Technical Skills:**\n\t+ Python (in-depth knowledge)\n\t+ Python web framework (at least one: Django, Flask)\n\t+ ORM (Object Relational Mapper) libraries\n\t+ Server-side templating languages\n\t+ Front-end technologies: JavaScript, HTML5, CSS3 (basic understanding)\n* **Soft Skills:**\n\t+ Strong analytical skills\n\t+ Problem-solving aptitude\n\t+ Attentive to details\n* **Availability:**\n\t+ Available for 6 months (required)\n\t+ Potential for conversion to full-time role\n* **Experience:**\n\t+ No specific experience required, but internship-level experience implied.", "company": "Shiryam Technologies", "position": "Backend Developer (Python Intern)", "location": "India"}, "big-data-developer-at-kresta-softech-private-limited-4272141830.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\big-data-developer-at-kresta-softech-private-limited-4272141830.html", "link": "https://in.linkedin.com/jobs/view/big-data-developer-at-kresta-softech-private-limited-4272141830?position=44&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=DqmpnNjyulfhXkByEbKg5w%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nRole Highlights:\nPosition: Big Data Engineer\nExperience:\n 4+ years\nLocation:\n All India-Remote, Hyderabad- Hybrid\nNotice Period:\n Immediate/7 days joiners mandate\nJob Overview:\nMust have skills- Big Data, Scala, AWS and Python or Java\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Experience:** 4+ years\n* **Technical Skills:**\n  * Big Data\n  * Scala\n  * AWS\n  * Python or Java\n* **Location:**\n  * All India (Remote)\n  * Hyderabad (Hybrid)\n* **Notice Period:** Immediate or 7 days\n* **Eligible Candidates:** Those with relevant experience and technical skills as specified.", "company": "Kresta Softech Private Limited", "position": "Big Data Developer", "location": "India"}, "junior-site-reliability-engineer-at-jove-4273783458.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\junior-site-reliability-engineer-at-jove-4273783458.html", "link": "https://in.linkedin.com/jobs/view/junior-site-reliability-engineer-at-jove-4273783458?position=45&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=Fck94W%2BvRk3dF3k6QhWtFA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nJoVE is the world-leading producer and provider of science video solutions with the mission to improve scientific research and education. Millions of scientists, educators and students use JoVE for their research, teaching and learning. Our institutional clients comprise over 1,000 universities, colleges, and biopharma companies, including such leaders as Harvard, MIT, Yale, and Stanford. As a rapidly growing company, with offices in the USA, UK, Australia, and India servicing clients in over 60 countries, we are seeking talented and ambitious individuals to join our company.60 countries, we are seeking talented individuals to join our company.\nThe Role\nWe are looking for a Junior Site Reliability Engineer who will be part of our centralized Site Reliability Team. You will play an integral role in leading the deployment of highly scalable systems, optimization, documentation, and support of the infrastructure components of JoVE\u2019s software products hosted on AWS. Cloud Infrastructure and Operations are critical in enabling JoVE to provide users with our technology offerings.\nResponsibilities: \nDesign, build, test, and deploy cloud-native applications and microservices using IaC tools like Terraform and Crossplane.\nMaintain availability, latency, performance, efficiency, monitoring/observability, emergency response, capacity planning, setting and maintaining SLOs, SLIs, and Error Budgets, and creating dashboards.\nPlan for automation to reduce toil and increase development velocity.\nPerform application-specific production support, incident management, change management, problem management, RCAs, and service restoration as needed.\nActively look for opportunities to improve the availability and performance of the system by applying the learnings from monitoring and observation.\nCollaborate with software development teams in the release management process to shape the future roadmap and establish strong operational readiness across teams.\nSpearhead implementation of reliability and observability tools (like Groundcover, Prometheus, Grafana, etc.)\nSupport Infrastructure squad On-call practice and participate in 24x7 on-call rotations.\nRequirements:\n2+ years of professional experience as a Software Engineer and Site Reliability Engineer (SRE).\nExtensive in-depth experience with cloud-based provisioning, monitoring, troubleshooting, and related SRE and DevOps technologies, in addition to networking knowledge.\nMUST have working experience with AWS infrastructure. \nMUST understand AWS VPC, subnets, Network ACLs, Security Groups, IAM Role, EKS.\nMUST have experience of using Crossplane\nMUST have working knowledge of GitOps, FluxCD, or ArgoCD \nExperience configuring Kubernetes RBAC Authorization, Ingress controller, ServiceAccount, and AWS role annotations.\nBasic experience with monitoring, and observability systems such as DataDog, Prometheus, Grafana, Kibana, CloudWatch.\nAbility to triage and resolve incidents and lead incident investigations.\nExperience working in a 24/7 on-call, highly transactional, or streaming production environment.\nExperience with Kubernetes Operators is a plus.\nWhy Join JoVE?\nWhen working with JoVE, you can expect compensation packages competitively placed within the local market.\nYou will make a direct impact in accelerating science research and in improving student learning in science education.\nOpportunity to work with global teams and in an environment that promotes innovation and collaboration.\nOur strong promotion from within culture draws a clear path to advance your career with us.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Eligibility Criteria:**\n  * 2+ years of professional experience as a Software Engineer and Site Reliability Engineer (SRE).\n* **Required Skills and Experience:**\n  * Extensive experience with cloud-based provisioning, monitoring, troubleshooting, and related SRE and DevOps technologies.\n  * Working experience with AWS infrastructure, including:\n    * AWS VPC\n    * Subnets\n    * Network ACLs\n    * Security Groups\n    * IAM Role\n    * EKS\n  * Experience with Crossplane.\n  * Working knowledge of GitOps, FluxCD, or ArgoCD.\n  * Experience configuring Kubernetes RBAC Authorization, Ingress controller, ServiceAccount, and AWS role annotations.\n  * Basic experience with monitoring and observability systems such as:\n    * DataDog\n    * Prometheus\n    * Grafana\n    * Kibana\n    * CloudWatch\n  * Ability to triage and resolve incidents and lead incident investigations.\n  * Experience working in a 24/7 on-call, highly transactional, or streaming production environment.\n* **Preferred Skills and Experience:**\n  * Experience with Kubernetes Operators.", "company": "JoVE", "position": "Junior Site Reliability Engineer", "location": "India"}, "software-engineer-in-test-i-at-quartic-ai-4259552527.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-in-test-i-at-quartic-ai-4259552527.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-in-test-i-at-quartic-ai-4259552527?position=46&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=3PicEWPKpdFH3g5ylaW2Ig%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout\nWe are an industrial-AI start-up in the business of accelerating the adoption of Industry 4.0. In other words, we allow manufacturers to extract more value from their legacy infrastructure and build Smart Manufacturing Factories. We do this with our Smart Industry platform which puts power directly into the hands of subject matter experts (SMEs) and solves key challenges faced by process manufacturing industries when implementing digital transformation. Using Quartic Platform, the SMEs are able to create and deploy AI and IIoT applications to significantly increase productivity and operational performance without the need for proficiency in programming or data science. The Quartic Platform is used by Fortune 100 and 500 companies in pharmaceutical, food & beverage, CPG, and other industries for process optimization, predictive maintenance, and energy optimization applications.\nResponsibilities:\nDevelop and maintain automated test scripts using a programming language, preferably \nPython\n, to ensure efficient and effective testing.\nCollaborate with developers and QA engineers to understand product requirements and design appropriate test strategies.\nUtilize \nSelenium\n or \nPlaywright\n automation frameworks to automate web-based application testing.\nPerform \nAPI testing\n using \nREST Assured\n tools to ensure the functionality and stability of backend services.\nUse \nGit\n and \nGitHub\n for version control to manage test scripts and collaborate with the team.\nUtilize JIRA for test case management, defect tracking, and project management.\nWork with \nDocker\n containers to set up and manage test environments.\nConduct testing on both \nWindows\n and \nLinux\n operating systems to ensure cross-platform compatibility.\nApply \nTDD\n (Test-Driven Development) and \nBDD\n (Behavior-Driven Development) principles to create robust and maintainable test scripts.\nKnowledge and experience with \nJenkins\n for continuous integration and deployment is a plus.\nFamiliarity with performance and security testing concepts and tools is a plus.\nUnderstanding of GraphQL technology is a plus.\nExperience with API automation is a plus.\nQualifications:\n1-3 years\n of relevant experience\nBachelor\u2019s degree in Computer Science, Engineering, or a related field.\nStrong programming skills with hands-on experience in at least one programming language, preferably Python.\nSolid understanding and experience with Playwright automation frameworks.\nProficiency in using REST Assured tools for API testing.\nFamiliarity with Git and GitHub for version control.\nExperience with JIRA for test case management.\nKnowledge of Docker and ability to work with containers.\nFamiliarity with both Windows and Linux operating systems.\nStrong understanding of TDD and BDD methodologies.\nKnowledge and experience with Jenkins is a plus.\nFamiliarity with performance and security testing concepts is a plus.\nUnderstanding of GraphQL technology is a plus.\nExperience in API automation is a plus.\nWhat you get:\nUnlimited Leaves\n: We understand the importance of work life balance. That\u2019s why we offer unlimited leaves to our employees.\nCutting Edge Technology\n: Get a chance to work on technology that is at the forefront of the fourth industrial revolution. Be a part of the future, today.\nCompetitive Compensation\n: We believe in rewarding our employees for their hard work and dedication. That\u2019s why we offer competitive compensation packages.\nFlexible Work Hours:\n We value your time and understand that everyone has their own rhythm. Enjoy the freedom of flexible work hours.\nPermanent Work From Home:\n Say goodbye to the daily commute. We offer permanent work from home options so you can work in the comfort of your own space.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** Bachelor\u2019s degree in Computer Science, Engineering, or a related field.\n* **Experience:** \n  * 1-3 years of relevant experience.\n  * Experience with API automation is a plus.\n* **Programming skills:** \n  * Strong programming skills with hands-on experience in at least one programming language, preferably Python.\n* **Technical skills:** \n  * Playwright automation frameworks.\n  * REST Assured tools for API testing.\n  * Git and GitHub for version control.\n  * JIRA for test case management.\n  * Docker and containers.\n  * Selenium (or alternative automation frameworks).\n* **Operating systems:** \n  * Familiarity with both Windows and Linux operating systems.\n* **Methodologies:** \n  * Strong understanding of TDD (Test-Driven Development) and BDD (Behavior-Driven Development) methodologies.\n* **Preferred skills:** \n  * Jenkins for continuous integration and deployment.\n  * Performance and security testing concepts and tools.\n  * GraphQL technology.", "company": "Quartic.ai", "position": "Software Engineer", "location": "Test I in India"}, "application-engineer-at-vericut-4268459061.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\application-engineer-at-vericut-4268459061.html", "link": "https://in.linkedin.com/jobs/view/application-engineer-at-vericut-4268459061?position=47&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=IDEns51w%2FQhx7On0BJixnA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nPosition Overview:\nWe are seeking a highly skilled and self-motivated Application Engineer \u2013 Vericut Solutions to provide expert technical support, training, and demonstrations for Vericut software suite, including Virtual Machine Configurations (VMCs). This role requires strong CAM and CNC machining knowledge, excellent customer-facing skills, and the ability to work closely with both customers and internal stakeholders to optimize software implementation and usage. The ideal candidate will thrive in a dynamic environment, possess strong communication skills, and be able to travel for onsite support, demos, and joint programs with partners such as Sandvik. This position will be remotely based in Pune, India.\nKey Responsibilities:\nProvide comprehensive onsite and remote support for Vericut software, including configuration of Virtual Machine Configurations (VMCs)\nConduct in-depth product demonstrations tailored to specific customer challenges, showcasing Vericut and Force as optimal solutions\nTravel independently to customer sites for demos, training, and support as required\nAssist customers in maximizing the ROI of their software investment through expert consultation and training\nEngage with customer teams including plant engineers, R&D personnel, and senior management to build long-term relationships\nProvide exceptional customer experience and insights into how Vericut fits into various manufacturing and software ecosystems.\nCollaborate proactively with internal Sandvik teams and external partners on joint initiatives, lead generation, and technical programs.\nDeliver training sessions for internal and external partners to enhance product knowledge and capabilities.\nMaintain accurate pre-sales and customer engagement records in Salesforce (CRM).\nRequirements:\nMinimum 3 years of hands-on experience operating 5-axis Vertical Machining Centers (VMCs) and Turn-Mill machines.\nProven experience with 5-axis CAM programming using tools such as Siemens NX, CATIA, Mastercam, or similar platforms.\nPractical experience in CNC part programming for controls including Siemens, Heidenhain, Mazatrol, and Fanuc.\nPrior experience with Vericut software is a strong advantage.\nStrong problem-solving, troubleshooting, and analytical skills.\nExcellent communication and interpersonal abilities.\nProactive, self-starting attitude with the ability to work both independently and as part of a collaborative team.\nSolid project management and organizational skills.\nAll hiring practices, employment terms, and conditions will be conducted in accordance with the applicable local labor laws and regulations of the specific hiring location. Any variations in employment terms, including benefits, working hours, and legal requirements, will reflect the legal standards and customary practices of the region in which the employee is hired.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Experience:**\n  * Minimum 3 years of hands-on experience operating 5-axis Vertical Machining Centers (VMCs) and Turn-Mill machines.\n  * Proven experience with 5-axis CAM programming using tools such as Siemens NX, CATIA, Mastercam, or similar platforms.\n  * Practical experience in CNC part programming for controls including Siemens, Heidenhain, Mazatrol, and Fanuc.\n  * Prior experience with Vericut software is a strong advantage.\n\n* **Skills:**\n  * Strong problem-solving, troubleshooting, and analytical skills.\n  * Excellent communication and interpersonal abilities.\n  * Solid project management and organizational skills.\n\n* **Personal Qualities:**\n  * Proactive, self-starting attitude.\n  * Ability to work both independently and as part of a collaborative team.\n\n* **Physical Requirements:**\n  * Ability to travel independently to customer sites for demos, training, and support as required.", "company": "Vericut", "position": "Application Engineer", "location": "Pune, Maharashtra, India"}, "junior-developer-at-live-connections-4270262908.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\junior-developer-at-live-connections-4270262908.html", "link": "https://in.linkedin.com/jobs/view/junior-developer-at-live-connections-4270262908?position=48&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=5GiVEDesxo9Hx7CS9uBMOg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nRole - Jr Developer\nExperience - 2 to 8 years\nWork Mode - Remote\nRequired Notice Period - Immediate Joiners\nMust Have Skills\n2 to 8 years of overall experience\nHands-on experience in the following skills \nMERN Stack - Python, Reactjs, Nodejs, Azure\nApplicants matching the above requirement can connect with Abhishek for more details by writing to us at abhishek.m@livecjobs.com or WhatsApping us on 9154908075\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* Eligibility:\n  * Experience: 2 to 8 years\n* Required skills:\n  * MERN Stack experience\n  * Python\n  * ReactJS\n  * NodeJS\n  * Azure\n* Work mode: Remote\n* Notice period: Immediate joiners", "company": "Live Connections", "position": "Junior Developer", "location": "India"}, "platform-engineer-at-niksun-4255561683.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\platform-engineer-at-niksun-4255561683.html", "link": "https://in.linkedin.com/jobs/view/platform-engineer-at-niksun-4255561683?position=49&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=qo4FYnRnMB1gjo%2FOyiBe0g%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nOS Engineer/Platform Engineer\nRemote, India \nNIKSUN is the recognized worldwide leader in making the Unknown Known, by using the next generation technology that revolutionizes the way networks and services are secured, protected, and managed. The company develops and deploys a complete range of award-winning forensics, compliance, security surveillance and performance management solutions for applications ranging from core infrastructures to edge and branch environments.\nResponsibilities\n:\nWork with other OS Engineers to design, develop, test, and maintain custom kernel and kernel modules\nKnowledge of Linux for remote machine set up & lab machine management \nDevelop portable code base: Application, libraries, tools between various *nix variants\nAutomate build and test environment\nIn-depth code Analysis, code review of in-house code and 3rd party code\nImprove software stack, tooling, processes.\nTroubleshoot incidents across infrastructure, network, storage, levels of stack.\nDocument findings, procedures for repetitive tasks and use them for automation.\nEvaluating new hardware servers, NICs\nAdd support for new hardware, NIC, Storage controllers, JBODs\nDevelop custom command Shell\nCustom ISO installer development\nRequirements:\n1-3 years of Linux device driver development experience\n1-3 years of application development experience in Linux environments\nThorough understanding of Linux kernel internals especially memory management, filesystem, irq, DMA, IOMMU, Networking etc.\nProficient coding skills in one of the C, C++\nHands-on coding skills in one of the scripting language Bash, Python, Perl\nExperience using and maintaining various build environments (auto make, CMAKE, Clang) and version control systems (GIT, CVS, SVN)\nExperience using various kernel and process debugging, profiling tools (Val grind, Gdb, kdb, perf etc.)\nRequired Skills and Traits:\nCan-do and will-do attitude\nGood written and oral communication skills\nTeamwork and collaboration\nShare knowledge and mentor team members\nNice to have Skills:\nPacket data-path acceleration framework knowledge (DPDK, netmap, PF_PACKET etc.)\nknowledge of Golang, Rust\nPCI device driver knowledge\nYou know about docker, Kubernetes, cgroups, namespace\nYou\u2019ve worked on an application that runs on virtual environment\nExtra points if have committed to Linux kernel\nProfessional Requirements:\nBachelor\u2019s degree in computer science or computer engineering\n1-3 years of experience in the fields of site reliability, platform engineering / DevSecOps\nQualified applicants will receive consideration for employment without regard to age, race, creed, color, religion, sex, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, or protected veteran status\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** Bachelor\u2019s degree in Computer Science or Computer Engineering\n* **Experience:**\n  * 1-3 years of Linux device driver development experience\n  * 1-3 years of application development experience in Linux environments\n  * 1-3 years of experience in site reliability, platform engineering / DevSecOps\n* **Technical Skills:**\n  * Linux kernel internals (memory management, filesystem, irq, DMA, IOMMU, Networking)\n  * Programming languages: C, C++, and one of the scripting languages (Bash, Python, Perl)\n  * Build environments: auto make, CMAKE, Clang\n  * Version control systems: GIT, CVS, SVN\n  * Debugging and profiling tools: Val grind, Gdb, kdb, perf\n* **Soft Skills:**\n  * Can-do and will-do attitude\n  * Good written and oral communication skills\n  * Teamwork and collaboration\n  * Willingness to share knowledge and mentor team members\n* **Preferred Skills:**\n  * Packet data-path acceleration framework (DPDK, netmap, PF_PACKET)\n  * Knowledge of Golang, Rust\n  * PCI device driver knowledge\n  * Experience with docker, Kubernetes, cgroups, namespace\n  * Experience working on an application that runs on a virtual environment\n  * Contribution to the Linux kernel", "company": "NIKSUN", "position": "Platform Engineer", "location": "India"}, "founding-engineer-at-weekday-ai-yc-w21-4266732348.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\founding-engineer-at-weekday-ai-yc-w21-4266732348.html", "link": "https://in.linkedin.com/jobs/view/founding-engineer-at-weekday-ai-yc-w21-4266732348?position=50&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=UFOF25m8bcpiMucIqruPmA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          This role is for one of Weekday's clients\nSalary range: Rs 4000000 - Rs 6500000 (ie INR 40-65 LPA)\nMin Experience: 3 years\nLocation: Remote (India)\nJobType: full-time\nRequirements\nAs a \nFounding Engineer\n you will play a pivotal role in shaping our flagship product. You will be responsible for designing and building a sandboxed coding agent capable of executing real-world automated tasks. This role emphasizes practical construction of robust systems with a strong focus on architecture, security, scalability, and product vision. You will have the opportunity to work in a collaborative, agile startup environment where your code, ideas, and product insights directly impact the development of the product.\nResponsibilities\n Develop a sandboxed coding agent that can execute shell commands, and Python/TypeScript code\n Implement file manipulation and GUI control using technologies such as xdot\n Design and integrate mechanisms for context persistence beyond token limits using file-based storage, pruning, etc\n Deploy the agent within a Docker container featuring a display server, noVNC, and Jupyter\n Orchestrate tasks through /schedule and /status endpoints operating in Firecracker VMs\n Bonus: Enhance the system by adding Kubernetes or Nomad support for horizontal scaling\nQualifications\n Strong coding skills in Python, TypeScript, and shell scripting\n Experience with containerization and Docker, including setting up and managing container environments\n Familiarity with virtualization techniques, particularly using Firecracker VMs\n Understanding of system architecture, security, and scalability principles\n Hands-on experience in building automation tools or similar real-world systems\n Self-starter mindset with the ability to build, iterate, and ship products quickly\n Product thinking and problem-solving skills to evaluate and improve system performance\n No formal degree required: We value practical skills and measurable results over academic credentials\nPreferred Skills\nKnowledge of Kubernetes or Nomad for horizontal scaling\nExperience with GUI automation tools and technologies like xdot\nFamiliarity with Jupyter environments and display server configurations\nPrevious experience with developing API endpoints for task orchestration\nExperience\nWhile specific years of experience are not mandated, candidates should have a track record of building and shipping real-world systems and demonstrate the capability to work effectively in a startup environment\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Eligibility Criteria:**\n  * Minimum 3 years of experience\n  * Strong coding skills in:\n    * Python\n    * TypeScript\n    * Shell scripting\n  * Experience with:\n    * Containerization and Docker\n    * Virtualization techniques, particularly Firecracker VMs\n    * Building automation tools or similar real-world systems\n  * Understanding of:\n    * System architecture\n    * Security\n    * Scalability principles\n  * Self-starter mindset with ability to build, iterate, and ship products quickly\n  * Product thinking and problem-solving skills\n* **Preferred Skills:**\n  * Knowledge of:\n    * Kubernetes or Nomad for horizontal scaling\n  * Experience with:\n    * GUI automation tools and technologies like xdot\n    * Jupyter environments and display server configurations\n    * Developing API endpoints for task orchestration\n* **Additional Requirements:**\n  * No formal degree required, practical skills and measurable results are valued\n  * Ability to work effectively in a startup environment\n  * Remote work location in India\n  * Full-time job type", "company": "Weekday AI (YC W21)", "position": "Founding Engineer", "location": "India"}, "data-engineer-web-scraping-at-alternative-path-4268965583.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\data-engineer-web-scraping-at-alternative-path-4268965583.html", "link": "https://in.linkedin.com/jobs/view/data-engineer-web-scraping-at-alternative-path-4268965583?position=51&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=Zuyg9NY4wt81d%2BhAogrMtg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAlternative Path is seeking skilled software developers to collaborate on client projects with an asset management firm. In this role, you will collaborate with individuals across various company departments to shape and innovate new products and features for our platform, enhancing existing ones. You will have a large degree of independence and trust, but you won't be isolated; the support of the Engineering team leads, the Product team leads, and every other technology team member is behind you. This is an opportunity to join a team-first meritocracy and help grow an entrepreneurial group inside Alternative Path. You will be asked to contribute, given ownership, and will be expected to make your voice heard.\nRole Summary:\nPerforming Web Scraping using various scraping techniques and then utilizing Python\u2019s Pandas library for data cleaning and manipulation. Then ingesting the data into a Database/Warehouse, and scheduling the scrapers using Airflow or other tools\nRole Overview\nThe Web Scraping Team at Alternative Path is seeking a creative and detail-oriented developer to contribute to client projects. The team develops essential applications, datasets, and alerts for various teams within the client's organization, supporting their daily investment decisions. The mission is to maintain operational excellence by delivering high-quality proprietary datasets, timely notifications, and exceptional service. We are seeking someone who is self-motivated, self-sufficient, with a passion for tinkering and a love for automation.\nIn your role, you will:\n\u27a2 Collaborate with analysts to understand and anticipate requirements.\n\u27a2 Design, implement, and maintain Web scrapers for a wide variety of alternative datasets.\n\u27a2 Perform Data Cleaning, Exploration, Transformation etc. of scraped data.\n\u27a2 Collaborate with cross-functional teams to understand data requirements and implement efficient data processing workflows.\n\u27a2 Author QC checks to validate data availability and integrity.\n\u27a2 Maintain alerting systems and investigate time-sensitive data incidents to ensure smooth day-to-day operations.\n\u27a2 Design and implement products and tools to enhance the Web scraping Platform.\nQualifications\nMust have\n\u27a2 Bachelor's/master\u2019s degree in computer science or in any related field\n\u27a2 2-4 years of software development experience\n\u27a2 Strong Python and SQL/Database skills\n\u27a2 Strong expertise in using the Pandas library (Python) is a must\n\u27a2 Experience with web technologies (HTML/JS, APIs, etc.)\n\u27a2 Proven work experience in working with large data sets for Data cleaning, Data transformation, Data manipulation, and Data replacements.\n\u27a2 Excellent verbal and written communication skills\n\u27a2 Aptitude for designing infrastructure, data products, and tools for Data Scientists\nPreferred\n\u27a2 Familiarity with scraping and common scraping tools (Selenium, scrapy, Fiddler, Postman, xpath) \u27a2 Experience containerizing workloads with Docker (Kubernetes a plus)\n\u27a2 Experience with build automation (Jenkins, Gitlab CI/CD) \u27a2 Experience with AWS technologies like S3, RDS, SNS, SQS, Lambda, etc.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** \n  * Bachelor's or master's degree in computer science or a related field\n* **Experience:** \n  * 2-4 years of software development experience\n  * Proven work experience with large data sets for data cleaning, transformation, manipulation, and replacement\n* **Technical Skills:**\n  * Strong Python skills\n  * Strong SQL/Database skills\n  * Strong expertise in using the Pandas library (Python)\n  * Experience with web technologies (HTML/JS, APIs, etc.)\n* **Preferred Skills:**\n  * Familiarity with scraping and common scraping tools (Selenium, scrapy, Fiddler, Postman, xpath)\n  * Experience with Docker (Kubernetes a plus)\n  * Experience with build automation (Jenkins, Gitlab CI/CD)\n  * Experience with AWS technologies like S3, RDS, SNS, SQS, Lambda, etc.\n* **Soft Skills:**\n  * Excellent verbal and written communication skills\n  * Self-motivated and self-sufficient\n  * Passion for tinkering and automation\n  * Ability to collaborate with cross-functional teams and make decisions independently", "company": "Alternative Path", "position": "Data Engineer - Web Scraping", "location": "India"}, "react-native-developer-at-vayuz-technologies-4148628204.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\react-native-developer-at-vayuz-technologies-4148628204.html", "link": "https://in.linkedin.com/jobs/view/react-native-developer-at-vayuz-technologies-4148628204?position=52&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=KQCx80b9oMs0vyMZyMyyyg%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nResponsibilities Include\n Designing, developing & deploying the product\n Work as part of a team to build React Native iOS / Android applications\n Architect, build and maintain excellent React Native applications with clean code\n Translating wireframes and PSD designs into functional responsive apps, Implement pixel perfect UI's that match designs\n Binding UI elements to JavaScript object models, work with native modules when required\n Creating RESTful services with Node.js\n Developing scalable web architectures\n Working in a cross-functional team to deliver a complete user experience\n Creating unit and integration tests to ensure the quality of code\n Being responsive to change requests and feature requests\n Writing code that is cross-platform and cross-device compatible\n Co-ordinating end-to-end implementation\n Release applications to iOS and Google Play stores\nSkills:- React Native and NodeJS (Node.js)\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required Qualifications:**\n  * Experience with React Native for iOS and Android app development\n  * Proficiency in Node.js\n* **Required Skills:**\n  * JavaScript\n  * React Native\n  * Node.js\n  * RESTful services creation\n  * Unit and integration testing\n* **Preferred or Implied Qualifications:**\n  * Experience with UI design implementation (PSD, wireframes)\n  * Knowledge of native modules\n  * Understanding of cross-platform and cross-device compatibility\n  * Experience with iOS and Google Play stores application release\n  * Team collaboration and communication skills\n  * Adaptability to change requests and feature requests", "company": "VAYUZ Technologies", "position": "React Native Developer", "location": "Noida, Uttar Pradesh, India"}, "simulation-triage-engineer-at-imerit-technology-4267949310.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\simulation-triage-engineer-at-imerit-technology-4267949310.html", "link": "https://in.linkedin.com/jobs/view/simulation-triage-engineer-at-imerit-technology-4267949310?position=53&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=A6lVyWe%2ByLe%2BWd%2FUbYSUPw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nPosition: \n & Simulation Tirage Engineer\nWork Location: \nWork from Office / Remote\nType:\n Full-time\nShift:\n Flexible to work in shifts, including night shifts on client request\nCommunication Skills Requirement: \nMinimum CEFR B2 level of English\nTechnical Skills Requirement: \nLiDAR L3\nAbout the Role (Position Summary)\nThis role requires a strong combination of technical expertise in AV sensor data (especially LiDAR and camera), meticulous attention to annotation quality, and hands-on experience in simulation data triage. The ideal candidate will work on identifying errors, inconsistencies, and gaps in annotated datasets and simulation scenes, supporting the retraining and validation cycles of autonomous vehicle (AV) systems.\nEducation Qualifications\nBachelor's degree in Engineering, Computer Applications, Data Science, or related technical discipline.\nExperience\n3\u20137 years of experience in annotation, simulation validation, or auditing roles with increasing leadership responsibility. \nStrong background in LiDAR and sensor data (2D/3D bounding boxes, polygons, cuboids, segmentation).\nExperience in simulation scenario review and tirage pipelines (e.g., triaging data for model retraining).\nPrior exposure to client interaction and cross-functional coordination (e.g., with engineering and QA teams).\nHands-on experience working in tool-based labeling pipelines and simulation-driven testing environments.\nExperience working with annotation tools and QA checklists based on project-specific SOPs.\nCapacity of data analysis towards identifying consistent gaps\nDesired Qualifications and Experience\n(if any)\nAuditor-Specific Soft Skills\nExceptional attention to detail:\n Ability to notice minute annotation errors, shape irregularities, and alignment mismatches.\nStrong visual-spatial reasoning:\n Capability to interpret 3D point clouds and assess object depth, perspective, occlusion, and context.\nCritical thinking:\n Skill in evaluating edge cases and understanding when annotations fail to represent real-world driving scenarios accurately. Strong ability of pattern recognition\nAnnotation guideline interpretation:\n Ability to deeply understand, question, and apply detailed project-specific SOPs and edge-case rules.\nBias awareness:\n Understand and flag biases in annotation or scene interpretation (e.g., object labeling errors due to weather, occlusion, or human assumptions).\nClear written communication:\n Document audit findings, feedback, and edge cases in structured and unambiguous formats.\nConsistency under repetition:\n Maintain high focus and precision while reviewing large datasets with repetitive structures.\nCuriosity and domain awareness:\n Stay engaged with AV trends, annotation standards (e.g., KITTI, nuScenes), and common model failure patterns.\nCollaboration mindset:\n Willingness to work closely with fellow auditors, QA teams, and simulation engineers to improve annotation and tirage workflows.\nTechnical Skill Requirements\nAnnotation Auditing & Data QA\nAnnotate and/or Audit 2D/3D sensor data annotations to ensure they meet the project\u2019s accuracy, completeness, and consistency requirements.\nIdentify common error types and provide actionable feedback.\nSimulation Tirage\nEvaluate simulation data for complexity, relevance, and anomalies.\nTag and classify scenes based on criticality for model training or validation pipelines.\nClear understanding of road sign and rules from a driver's perspective with capacity of (given) situation analysis\nRules of the Road Expertise: Familiarity with standard traffic behavior, signage, signaling, right-of-way principles, and vehicle interactions under typical U.S. driving conditions.\nMUTCD Knowledge: Working knowledge of the Manual on Uniform Traffic Control Devices (MUTCD), especially as it applies to lane markings, signage, and signal interpretation across varied roadway types.\nPassenger Comfort Sensitivity: Ability to assess scenarios from the perspective of a rider, identifying discomfort or unsafe behaviors that may not violate technical rules but still degrade the end-user experience.\nDriver Duty of Care Perspective: Ability to evaluate edge cases and ambiguous situations through the lens of a responsible human driver, balancing legality with caution and accountability in mixed-traffic environments.\nTool & Workflow Expertise\nOperate advanced tools such as Labelbox, Scale AI, Supervisely, CVAT, CARLA, or in-house labeling systems.\nSuggest refinements in annotation and tirage flows to reduce ambiguity and improve cycle efficiency.\nDocumentation & Reporting\nMaintain issue logs and generate structured audit reports.\nProvide detailed scene-level comments to support iterative data improvements.\nResponsibilities (not limited to)\nConduct systematic reviews of AV sensor annotations using defined QA guidelines.\nPerform simulation scene triage to identify edge-case scenarios and misclassified outcomes.\nTag errors, provide audit-level feedback, and ensure data is looped back for correction or retraining.\nCollaborate with QA reviewers, annotation operators, and simulation engineers.\nContribute to refinement of SOPs and visual reference materials based on audit insights.\nStay current with industry annotation standards and simulation evaluation protocols.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** \n  * Bachelor's degree in Engineering, Computer Applications, Data Science, or related technical discipline.\n\n* **Experience:** \n  * 3\u20137 years of experience in annotation, simulation validation, or auditing roles with increasing leadership responsibility.\n  * Strong background in LiDAR and sensor data (2D/3D bounding boxes, polygons, cuboids, segmentation).\n  * Experience in simulation scenario review and tirage pipelines.\n  * Prior exposure to client interaction and cross-functional coordination.\n\n* **Technical Skills:**\n  * LiDAR L3\n  * Annotation tools and QA checklists\n  * Tool-based labeling pipelines and simulation-driven testing environments\n  * Advanced tools such as Labelbox, Scale AI, Supervisely, CVAT, CARLA, or in-house labeling systems\n\n* **Language Skills:**\n  * Minimum CEFR B2 level of English\n\n* **Soft Skills:**\n  * Exceptional attention to detail\n  * Strong visual-spatial reasoning\n  * Critical thinking\n  * Annotation guideline interpretation\n  * Bias awareness\n  * Clear written communication\n  * Consistency under repetition\n  * Curiosity and domain awareness\n  * Collaboration mindset\n\n* **Domain Knowledge:**\n  * Rules of the Road Expertise\n  * MUTCD Knowledge\n  * Passenger Comfort Sensitivity\n  * Driver Duty of Care Perspective", "company": "iMerit Technology", "position": "Simulation Triage Engineer", "location": "India"}, "fullstack-developer-at-weekday-ai-yc-w21-4277467927.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\fullstack-developer-at-weekday-ai-yc-w21-4277467927.html", "link": "https://in.linkedin.com/jobs/view/fullstack-developer-at-weekday-ai-yc-w21-4277467927?position=54&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=v9Qd8R13JyonCFws6DG4ig%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nThis role is for one of the Weekday's clients\nSalary range: Rs 1500000 - Rs 2500000 (ie INR 15-25 LPA)\nMin Experience: 3 years\nLocation: Remote (India)\nJobType: full-time\nWe are seeking a highly skilled and motivated Fullstack Developer with 3-6 years of professional experience to join our dynamic engineering team. The ideal candidate will have hands-on expertise in Flutter for cross-platform mobile development, strong backend capabilities using NodeJS and Python, and a solid understanding of building scalable and performant web and mobile applications.\nThis is a fantastic opportunity to work on end-to-end product development, contribute to architecture discussions, and play a key role in shaping product direction and user experience.\nRequirements\nKey Responsibilities:\n Design, develop, and maintain highly responsive cross-platform mobile applications using Flutter. \n Build robust backend services and RESTful APIs using NodeJS and Python. \n Collaborate with product managers, UI/UX designers, and other developers to understand requirements and deliver high-quality features. \n Write clean, maintainable, and well-documented code following best practices and coding standards. \n Optimize performance of applications for maximum speed and scalability across devices. \n Manage and integrate databases and third-party services as needed. \n Conduct code reviews, write unit/integration tests, and ensure code quality and maintainability. \n Stay up-to-date with emerging technologies and frameworks, and apply them when appropriate. \n Troubleshoot and debug application issues in real-time and suggest improvements. \n Participate in Agile/Scrum development processes and contribute to sprint planning and retrospectives. \nKey Requirements:\n 3-6 years of experience as a Fullstack Developer or in similar roles. \n Proficiency in Flutter with at least one end-to-end mobile app deployment. \n Strong backend development skills in NodeJS and Python, including Express.js and FastAPI/Django/Flask frameworks. \n Experience working with relational and NoSQL databases (e.g., PostgreSQL, MongoDB). \n Good understanding of RESTful APIs, microservices architecture, and server-side logic. \n Strong debugging and problem-solving skills. \n Familiarity with version control systems like Git and CI/CD pipelines. \n Knowledge of software security principles, responsive design, and performance optimization. \n Ability to write clean, modular, and scalable code with proper documentation. \n Excellent communication and collaboration skills with a proactive attitude. \nPreferred Qualifications:\n Experience with cloud platforms like AWS, GCP, or Azure. \n Familiarity with Docker and containerized application development. \n Exposure to DevOps tools and practices is a plus. \n Knowledge of GraphQL, WebSockets, or real-time communication systems\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Eligibility Criteria:**\n  * Experience: 3-6 years as a Fullstack Developer or similar role\n  * Location: Remote (India)\n  * Job Type: Full-time\n* **Required Skills:**\n  * Programming languages: \n    * Flutter\n    * NodeJS\n    * Python\n  * Frameworks: \n    * Express.js\n    * FastAPI/Django/Flask\n  * Databases: \n    * Relational (e.g., PostgreSQL)\n    * NoSQL (e.g., MongoDB)\n  * APIs: \n    * RESTful APIs\n  * Development practices: \n    * Agile/Scrum\n    * Version control (e.g., Git)\n    * CI/CD pipelines\n  * Soft skills: \n    * Excellent communication and collaboration\n    * Proactive attitude\n    * Strong debugging and problem-solving skills\n* **Preferred Skills:**\n  * Cloud platforms: \n    * AWS\n    * GCP\n    * Azure\n  * Containerization: \n    * Docker\n  * DevOps tools and practices\n  * Technologies: \n    * GraphQL\n    * WebSockets\n    * Real-time communication systems", "company": "Weekday AI (YC W21)", "position": "Fullstack Developer", "location": "India"}, "software-engineer-at-schedley-com-4271146349.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-at-schedley-com-4271146349.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-at-schedley-com-4271146349?position=55&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=s1BjeTD%2BBeQG4EG71lyBXQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nThe ideal candidate will be responsible for developing high-quality applications. They will also be responsible for designing and implementing testable and scalable code. \n \nResponsibilities\nDevelop quality software and web applications\nAnalyze and maintain existing software applications\nDesign highly scalable, testable code\nDiscover and fix programming bugs\nQualifications\nBachelor's degree or equivalent experience in Computer Science or related field\nDevelopment experience with programming languages\nSQL database or relational database skills\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "\u2022 Bachelor's degree in Computer Science or a related field\n\u2022 Equivalent experience to a Bachelor's degree in Computer Science or a related field\n\u2022 Experience in software development with programming languages\n\u2022 SQL database or relational database skills\n\u2022 Experience with developing software and web applications\n\u2022 Experience with analyzing and maintaining existing software applications\n\u2022 Ability to design scalable and testable code\n\u2022 Ability to identify and fix programming bugs", "company": "Schedley.com", "position": "Software Engineer", "location": "India"}, "software-engineering-specialist-human-data-at-xai-4262541457.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineering-specialist-human-data-at-xai-4262541457.html", "link": "https://in.linkedin.com/jobs/view/software-engineering-specialist-human-data-at-xai-4262541457?position=56&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=GNKRhXlp8j%2B1UWgSMZ8SxQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout xAI\nxAI's mission is to create AI systems that can accurately understand the universe and aid humanity in its pursuit of knowledge.\nOur team is small, highly motivated, and focused on engineering excellence. This organization is for individuals who appreciate challenging themselves and thrive on curiosity.\nWe operate with a flat organizational structure. All employees are expected to be hands-on and to contribute directly to the company's mission. Leadership is given to those who show initiative and consistently deliver excellence. Work ethic and strong prioritization skills are important.\nAll engineers and researchers are expected to have strong communication skills. They should be able to concisely and accurately share knowledge with their teammates.\nAbout the Role\nAs a Software Engineering Specialist on the Human Data team, you will be responsible for creating cutting-edge data to facilitate the training of large language models. Collaborating closely with technical staff, you will contribute to datasets for model training, benchmarking, and overall advancement.\nThe Software Engineering Specialist - Human Data\n role is a full-time remote position. Part-time may be offered on a case-by-case basis but full-time is strongly preferred (please see the bottom of this job description for more details).\nResponsibilities\nAI model training initiatives by curating code examples, offering precise solutions, and meticulous corrections in Python, JavaScript (including ReactJS), C/C++, and Java.\nEvaluate and refine AI-generated code, ensuring it adheres to industry standards for efficiency, scalability, and reliability.\nCollaborate with cross-functional teams to enhance AI-driven coding solutions, ensuring they meet enterprise-level quality and performance benchmarks.\nKey Qualifications\nAdvanced proficiency in English, both verbal and written.\nStrong experience in either Python or JavaScript, with a solid foundation in software development practices. Please note that for those with experience in only JavaScript, experience with ReactJS is preferred but not required. Knowledge of other languages is a strong plus.Strong grasp of computer science fundamentals like data structures, algorithms, and debugging skills.\nA minimum of 2 years of hands-on industry experience with a proven track record in software development and/or public proof of work (such as on GitHub).\nExtensive experience with a wide array of tools and systems such as Databases, SQL, Kubernetes, Spark, Kafka, gRPC, and AWS.\nPreferred Qualifications\nThe ideal candidate for this role is adaptable, possesses strong logical reasoning skills, is detail-oriented, and thrives in a fast-paced work environment.\nEvidence of meaningful contributions to open source projects or high reputation on platforms like Stack Overflow or evidence of strong performance in programming competitions.\nEnthusiasm to collaboratively build the best truth-seeking AI out there!\nAdditional Requirements\nDemonstrates a strong capacity to quickly adapt by learning new skills and unlearning outdated ones, thriving in dynamic and changing environments.\nFor those who will be working from a personal device, please note your computer must be capable of running Windows 10 or macOS BigSur 11.0 or later.\nLocation, Hourly, and Other Expectations\n \nThis position is fully remote.\nWe are unable to provide visa sponsorship.\nIf you are based in the US, please note we are unable to hire in the states of Wyoming and Illinois at this time.\nYou must own and have reliable access to a smartphone.\nPlease indicate your interest in either full-time, part-time, or either in the application. Note that:\nFull-Time (40 hours per week): Full-time schedules are 9-5:30pm in your local time zone. The first week will be 9-5:30pm PST for onboarding.\nPart-Time (20-29 hours per week): While hours are flexible around your schedule, you must be committed to working at least 20 hours per week (with at least 10 of these hours worked on weekdays) and no more than 29 hours per week.\nCompensation and Benefits\nThe pay for this role may range from $55/hour - $65/hour. \nYour actual pay will be determined on a case-by-case basis and may vary based on the following considerations: job-related knowledge and skills, education, and experience.\nFor full-time roles, specific benefits vary by country, depending on your country of residence you may have access to medical benefits. We do not offer benefits for part-time roles.\nxAI is an equal opportunity employer and does not unlawfully discriminate based on race, color, religion, ethnicity, ancestry, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, age, disability, medical conditions, genetic information, marital status, military or veteran status, or any other applicable legally protected characteristics. \nQualified applicants with arrest or conviction records will be considered for employment in accordance with all applicable federal, state, and local laws, including the San Francisco Fair Chance Ordinance, Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. \nFor Los Angeles County (unincorporated) Candidates:\nxAI reasonably believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: \nAccess to information technology systems and confidential information, including proprietary and trade secret information, and/or user data;\nInteracting with internal and/or external clients and colleagues; and\nExercising sound judgment.\nCalifornia Consumer Privacy Act (CCPA) Notice\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Language skills:**\n  * Advanced proficiency in English (verbal and written)\n* **Technical skills:**\n  * Strong experience in either Python or JavaScript\n  * Knowledge of other languages (C/C++, Java) is a strong plus\n  * Experience with ReactJS (for JavaScript developers) is preferred but not required\n  * Strong grasp of computer science fundamentals (data structures, algorithms, debugging skills)\n  * Extensive experience with a wide array of tools and systems (Databases, SQL, Kubernetes, Spark, Kafka, gRPC, AWS)\n* **Experience:**\n  * Minimum 2 years of hands-on industry experience in software development and/or public proof of work (e.g., on GitHub)\n* **Preferred qualifications:**\n  * Evidence of meaningful contributions to open source projects or high reputation on platforms like Stack Overflow\n  * Evidence of strong performance in programming competitions\n  * Adaptability, strong logical reasoning skills, attention to detail, and ability to thrive in a fast-paced work environment\n* **Soft skills:**\n  * Strong communication skills (ability to concisely and accurately share knowledge with teammates)\n  * Ability to quickly adapt and learn new skills\n  * Strong prioritization skills and work ethic\n* **Logistical requirements:**\n  * Reliable access to a smartphone\n  * Computer capable of running Windows 10 or macOS Big Sur 11.0 or later (for remote work)\n  * Full-time schedule preferred (40 hours/week), but part-time (20-29 hours/week) may be considered\n  * Availability to work in a remote setting with flexible hours (for part-time) or 9-5:30 pm in local time zone (for full-time)", "company": "xAI", "position": "Software Engineering Specialist - Human Data", "location": "Telangana, India"}, "mel-specialist-remote-8-lpa-at-job-express-4258644795.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\mel-specialist-remote-8-lpa-at-job-express-4258644795.html", "link": "https://in.linkedin.com/jobs/view/mel-specialist-remote-8-lpa-at-job-express-4258644795?position=57&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=zPWzh5WKyEAfWvZm90ZHnA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nRole Description\nThe MEL Specialist will design, implement, and manage monitoring, evaluation, and learning systems to track program performance, outcomes, and impact. This role will provide data-driven insights to inform program decisions, improve effectiveness, and ensure accountability.\nKey Responsibilities\nMonitoring and Evaluation\nDesign and implement monitoring frameworks, including indicators, data collection tools, and reporting templates.\nDevelop and manage databases to track program progress and outcomes.\nConduct evaluations, including baseline studies, mid-term evaluations, and final evaluations.\nData Analysis and Reporting\nAnalyze data to identify trends, patterns, and insights.\nPrepare reports, including progress reports, evaluation reports, and technical reports.\nDevelop data visualizations and dashboards to communicate findings.\nLearning and Capacity Building\nFacilitate learning events, workshops, and meetings to share findings and insights.\nBuild capacity of staff and partners on MEL concepts, tools, and methodologies.\nDevelop and implement learning plans to improve program effectiveness.\nQualifications\nEducation\nMaster's degree in a relevant field, such as social sciences, evaluation, or statistics.\nRelevant certifications in MEL, evaluation, or research methods.\nSkills\nStrong analytical and problem-solving skills.\nExcellent data analysis, reporting, and communication skills.\nExperience with MEL frameworks, tools, and methodologies.\nAbility to work independently and collaboratively.\nExperience\nMinimum 3-5 years of experience in MEL, evaluation, research, or a related field.\nExperience in designing and implementing MEL systems.\nGrowth Opportunities\nProfessional development opportunities.\nCareer growth and advancement possibilities.\nSkills: collaboration,data visualization,monitoring and evaluation,data analysis,analytical skills,mel frameworks,communication skills,problem-solving skills,ms excel,reporting,learning\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:**\n  * Master's degree in a relevant field (social sciences, evaluation, statistics, etc.)\n  * Relevant certifications in MEL, evaluation, or research methods\n* **Experience:**\n  * Minimum 3-5 years in MEL, evaluation, research, or a related field\n  * Experience in designing and implementing MEL systems\n* **Skills:**\n  * Strong analytical and problem-solving skills\n  * Excellent data analysis, reporting, and communication skills\n  * Experience with MEL frameworks, tools, and methodologies\n  * Data visualization\n  * MS Excel\n  * Collaboration and ability to work independently and collaboratively", "company": "Job express", "position": "MEL Specialist - Remote - 8 LPA", "location": "India"}, "software-engineer-backend-development-at-smallcase-4267667521.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-engineer-backend-development-at-smallcase-4267667521.html", "link": "https://in.linkedin.com/jobs/view/software-engineer-backend-development-at-smallcase-4267667521?position=58&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=UAwO8jaeLQ7j6b%2BH%2Bog7qQ%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          \nAbout The Role\nYou\u2019ll work with world-class engineers, designers, and finance experts to create intuitive and scalable investment platforms. As a Software Development Engineer, you\u2019ll contribute to high-impact projects, write clean and efficient code, and learn what it takes to deliver a delightful investing experience to millions.\nWhat You\u2019ll Do\nDesign and develop databases for real-time, high availability financial data \nWill be working with MongoDB, Redis, Javascript, Node.js \nArchitect and build the backend for corresponding web service (Nodejs and related frameworks) \nCreate microservices and tools, manage servers (AWS), create reports etc. \nWe\u2019re Looking for\nMust to have 1 -3 years of Software Development experience \nStrong systems, architecture and database fundamentals \nPrior experience with Javascript (Node.js), MongoDB \nWeb development concepts - basics of REST APIs, server architecture \nInterest in building things from scratch and be a decision maker here \nEligibility\nLooking for hands-on backend experience in a real product environment \nAbout Smallcase\nAt smallcase, we are changing how India invests. smallcase is a leading provider of investment products & platforms to over 10 million Indians. We're a young, driven team of 250+ headquartered in Bangalore. smallcase was founded in July 2015 by three IIT Kharagpur graduates, Vasanth Kamath, Anugrah Shrivastava and Rohan Gupta.\nsmallcase has been focused on offering innovative investing experiences & technology. Our platforms are used by over 300 of India's largest financial brands and most respected institutions. We are backed by world-class investors including top-tier funds, institutions and operators from the capital markets space who believe in our mission of enabling better financial futures for every Indian.\nLife at smallcase\nWe are not just building a business, we are making a long-lasting impact both in the wealth & assets landscape with our unique technology & expanding ecosystem. Over the last 9 years, our team, products, and platforms have grown and so have our ambitions.\nInnovation remains at the heart of what we do. Our other core values are transparency, integrity & long-term thinking. Our key asset has always been our people, and we empower individuals to build and do some of the best work in their lifetimes at smallcase. Flexibility, ownership and constant feedback loops are some of the ways we keep evolving the working environment.\nSkills: node.js,redis,mongodb,architecture,building,software,rest apis,restapi,software development,aws,javascript,microservices\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required:**\n  * 1-3 years of software development experience\n  * Strong systems, architecture, and database fundamentals\n  * Prior experience with:\n    * Javascript (Node.js)\n    * MongoDB\n  * Basics of:\n    * REST APIs\n    * Server architecture\n* **Preferred:**\n  * Hands-on backend experience in a real product environment\n  * Experience with:\n    * Redis\n    * AWS\n    * Microservices\n  * Interest in building things from scratch and being a decision-maker", "company": "smallcase", "position": "Software Engineer - Backend Development", "location": "India"}, "sde-3-backend-engineer-at-weekday-ai-yc-w21-4270632427.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\sde-3-backend-engineer-at-weekday-ai-yc-w21-4270632427.html", "link": "https://in.linkedin.com/jobs/view/sde-3-backend-engineer-at-weekday-ai-yc-w21-4270632427?position=59&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=TkyZCUaf7eCHinRMrZvphA%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          This role is for one of Weekday's clients\nMin Experience: 4 years\nJobType: full-time\nRequirements\nWe are looking for a highly skilled and experienced \nSDE 3 - Backend Engineer\n with deep expertise in \nPython\n and \nFastAPI\n to join our high-performing engineering team. As an SDE 3, you will play a key role in designing, developing, and scaling backend systems that are core to our product infrastructure. This is an opportunity to work on mission-critical backend services with a strong focus on performance, reliability, and clean API design.\nYou should be passionate about building modern, scalable, and maintainable backend services and love solving complex architectural and performance challenges.\nKey Responsibilities:\n System Design & Architecture: Lead the design and development of scalable backend systems, ensuring low latency, high availability, and fault tolerance. \n API Development: Build and maintain RESTful APIs using FastAPI, with a strong emphasis on clean code practices and security. \n Code Ownership: Write clean, maintainable, and well-tested code. Take ownership of end-to-end backend components from design to production. \n Performance Optimization: Identify bottlenecks in application performance and implement solutions to enhance speed and scalability. \n Mentorship: Guide and mentor junior developers and collaborate with cross-functional teams including product, frontend, and DevOps. \n Testing & Quality: Ensure best practices in unit, integration, and end-to-end testing. Drive CI/CD practices in collaboration with the DevOps team. \n Documentation: Maintain comprehensive documentation for APIs, workflows, and architecture to promote clarity and maintainability. \nKey Skills & Requirements:\n Strong Programming Skills: \n Deep experience in Python with a strong understanding of object-oriented and asynchronous programming paradigms. \n Proficiency in writing modular, scalable, and testable code. \n Web Framework Expertise: \n Expertise in FastAPI is a must. Familiarity with other Python web frameworks (e.g., Flask, Django) is a plus. \n Database Knowledge: \n Proficiency in working with SQL (PostgreSQL/MySQL) and NoSQL (MongoDB/Redis) databases. \n Experience with schema design, indexing, and query optimization. \n API Design: \n Strong knowledge of RESTful API best practices, request validation, authentication, and rate-limiting. \n DevOps & Tooling: \n Experience working in CI/CD environments. Familiarity with Docker, Git, and logging/monitoring tools is a plus. \n Cloud & Deployment: \n Experience deploying applications on cloud platforms like AWS, GCP, or Azure is preferred. \n Soft Skills: \n Strong communication and collaboration skills. \n Ability to work independently and handle ownership of complex modules. \nEducational Background:\n Bachelor's or Master's degree in Computer Science, Engineering, or a related technical field.\n\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Education:** Bachelor's or Master's degree in Computer Science, Engineering, or a related technical field.\n* **Experience:** \n  * Minimum 4 years of experience.\n  * Experience as a backend engineer, preferably at a senior level (SDE3).\n* **Technical Skills:**\n  * Strong programming skills in Python, with object-oriented and asynchronous programming paradigms.\n  * Expertise in FastAPI; familiarity with other Python web frameworks (e.g., Flask, Django) is a plus.\n  * Proficiency in SQL (PostgreSQL/MySQL) and NoSQL (MongoDB/Redis) databases, schema design, indexing, and query optimization.\n  * Experience with RESTful API best practices, request validation, authentication, and rate-limiting.\n  * Familiarity with CI/CD environments, Docker, Git, and logging/monitoring tools.\n* **Soft Skills:**\n  * Strong communication and collaboration skills.\n  * Ability to work independently and handle ownership of complex modules.\n* **Preferred Qualifications:**\n  * Experience deploying applications on cloud platforms like AWS, GCP, or Azure.", "company": "Weekday AI (YC W21)", "position": "SDE 3 - Backend Engineer", "location": "Bengaluru, Karnataka, India"}, "software-developer-at-bu-consultants-4273066388.html": {"path": "E:\\study\\GitHub\\RESUME-BUILDER-WITH-AI\\job_data\\software-developer-at-bu-consultants-4273066388.html", "link": "https://in.linkedin.com/jobs/view/software-developer-at-bu-consultants-4273066388?position=60&pageNum=0&refId=X5mxesijinZ7v4lG73gcBQ%3D%3D&trackingId=4YDjRxAqb8CdDw3XZ79lXw%3D%3D", "description": "\n        \n    \n    \n    \n\n    \n\n        \n\n          Role & Responsibilities\nDesign, develop, and maintain scalable web applications using advanced TypeScript frameworks.\nCollaborate with cross-functional teams including product managers, designers, and other developers to define and implement innovative solutions.\nImplement best practices in software architecture, code quality, testing, and performance optimization.\nParticipate in code reviews and contribute to an agile development environment to ensure continuous improvement.\nTroubleshoot, debug, and upgrade existing systems to meet evolving business requirements.\nMaintain effective communication in a fully remote setup, ensuring project alignment, and meeting tight deadlines.\nSkills & Qualifications\nMust-Have\nProven experience as a Software Development Engineer with a strong focus on TypeScript development.\nSolid understanding of front-end and back-end integration, with hands-on experience in Node.js and popular frameworks.\nStrong expertise in design patterns, code refactoring, and test-driven development practices.\nGood to have Java should know how to write tests, JUNIT\nExperience working in agile teams and managing projects in a remote work environment.\nExcellent problem-solving skills and ability to adapt quickly to evolving business needs.\nPreferred\nFamiliarity with AWS cloud services and CI/CD pipelines to support robust development workflows.\nExperience with additional technologies such as React and modern JavaScript libraries.\nPrevious exposure working with distributed systems and scalable microservices architectures.\nBenefits & Culture Highlights\nEmbrace a flexible and fully remote work environment that values work-life balance.\nCompetitive compensation with comprehensive benefits aligned to industry standards.\nCollaborative culture that encourages innovation, continuous learning, and professional growth.\nThis role is designed for high-intent candidates who are passionate about leveraging TypeScript to build world-class applications in a remote setting. If you thrive in a dynamic environment that values proactive problem-solvers and dedicated team players, we would love to connect with you for this exciting opportunity.\nInterested Candidates can share their applications on below mail id with subject line- SDE-1Front End Typescript on bala@buconsultants.co\nSkills: node.js,react,typescript,java,data structures,ci/cd,leetcode,problem-solving,aws,junit,agile\n        \n\n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show more\n          \n\n          \n\n    \n\n  \n\n        \n\n    \n    \n    \n\n    \n\n\n\n        \n            Show less\n          \n\n          \n\n    \n\n  \n\n    \n\n  \n      ", "description_summary": "* **Required:**\n  * Proven experience as a Software Development Engineer with a strong focus on TypeScript development\n  * Solid understanding of front-end and back-end integration with hands-on experience in Node.js and popular frameworks\n  * Strong expertise in design patterns, code refactoring, and test-driven development practices\n  * Experience working in agile teams and managing projects in a remote work environment\n  * Excellent problem-solving skills and ability to adapt quickly to evolving business needs\n* **Preferred:**\n  * Familiarity with AWS cloud services and CI/CD pipelines\n  * Experience with additional technologies such as React and modern JavaScript libraries\n  * Previous exposure working with distributed systems and scalable microservices architectures\n  * Java experience with JUNIT testing knowledge", "company": "BU Consultants", "position": "Software Developer", "location": "India"}}